# HTTP的实体数据

## 数据类型与编码

在 TCP/IP 协议栈里，传输数据基本上都是“header+body”的格式。但 TCP、UDP 因为是传输层的协议，它们不会关心 body 数据是什么，只要把数据发送到对方就算是完成了任务。

而 HTTP 协议则不同，它是应用层的协议，数据到达之后还必须要告诉上层应用这是什么数据。假如 HTTP 没有告知数据类型的功能，服务器把“一大坨”数据发给了浏览器，浏览器看到的是一个“黑盒子”，这时候该怎么办呢？当然，它可以“猜”。因为很多数据都是有固定格式的，所以通过检查数据的前几个字节也许就能知道这是个 GIF 图片、或者是个 MP3 音乐文件，但这种方式十分低效，而且有很大几率会检查不出来文件类型。

在 HTTP 协议诞生之前，在电子邮件系统里的，让电子邮件可以发送 ASCII 码以外的任意数据，叫做“多用途互联网邮件扩展”（Multipurpose Internet Mail Extensions），简称为 **MIME**。

MIME 是一个很大的标准规范，HTTP 只取了其中的一部分，用来标记 body 的数据类型，这就是“**MIME type**”。**MIME 把数据分成了八大类，每个大类下再细分出多个子类，形式是“type/subtype”的字符串**。

**text**：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。

**image**：即图像文件，有 image/gif、image/jpeg、image/png 等。

**audio/video**：音频和视频数据，例如 audio/mpeg、video/mp4 等。

application：数据格式不固定，**可能是文本也可能是二进制**，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，就会是 application/octet-stream，即不透明的二进制数据。

仅有 MIME type 还不够，HTTP 在传输时为了节约带宽，有时候还会压缩数据，为了不要让浏览器继续“猜”，还需要有一个“**Encoding type**”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。

Encoding type 常用的有下面三种：

**gzip**：GNU zip 压缩格式，也是互联网上最流行的压缩格式；

**deflate**：zlib（deflate）压缩格式，流行程度仅次于 gzip；

**br**：一种**专门为 HTTP 优化的新压缩算法（Brotli）**。

## 数据类型使用的头字段

有了 MIME type 和 Encoding type，无论是浏览器还是服务器就都可以轻松识别出 body 的类型，也就能够正确处理数据了。**HTTP 协议为此定义了两个 Accept 请求头字段和两个 Content 实体头字段，用于客户端和服务器进行“内容协商”**。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5gnkhk0loj31jk0v514h.jpg)

**Accept** 字段标记的是**客户端**可理解的 MIME type，可以用“,”做分隔符列出多个类型，让服务器有更多的选择余地，例如下面的这个头：

```
Accept: text/html,application/xml,image/webp,image/png
```

这就是告诉服务器：“我能够看懂 HTML、XML 的文本，还有 webp 和 png 的图片，请给我这四类格式的数据”。

相应的，**服务器**会在响应报文里用头字段 **Content-Type** 告诉实体数据的真实类型：

```
Content-Type: text/htmlContent-Type: image/png
```

这样浏览器看到报文里的类型是“text/html”就知道是 HTML 文件，会调用排版引擎渲染出页面，看到“image/png”就知道是一个看到“image/png”就知道是一个 PNG 文件，就会在页面上显示出图像。

**Accept-Encoding** 字段标记的是**客户端**支持的压缩格式，可以用“,”列出多个，服务器可以选择其中一种来压缩数据，**实际使用的压缩格式放在响应头字段 Content-Encoding 里**。

**如果请求报文里没有 Accept-Encoding 字段，就表示客户端不支持压缩数据；如果响应报文里没有 Content-Encoding 字段，就表示响应数据没有被压缩**。

## 语言类型与编码

不同国家不同地区的人使用了很多不同的语言，虽然都是 text/html，但如何让浏览器显示出每个人都可理解可阅读的语言文字呢？HTTP 采用了与数据类型相似的解决方案，又引入了两个概念：**语言类型与字符集**。“语言类型”就是人类使用的自然语言，例如英语、汉语、日语等，而这些自然语言可能还有下属的地区性方言。

在需要明确区分的时候也要使用“**type-subtype**”的形式，不过这里的格式与数据类型不同，**分隔符不是“/”，而是“-”**。

例子：en 表示**任意的英语**，en-US 表示美式英语，en-GB 表示英式英语，而 zh-CN 就表示我们最常使用的汉语。

关于自然语言的计算机处理还有一个更麻烦的东西叫做“**字符集**”。在计算机发展的早期，各个国家和地区的人们“各自为政”，发明了许多字符编码方式来处理文字，比如英语世界用的 ASCII、汉语世界用的 GBK、BIG5，日语世界用的 Shift_JIS 等。同样的一段文字，用一种编码显示正常，换另一种编码后可能就会变得一团糟。

Unicode 和 UTF-8 把世界上所有的语言都容纳在一种编码方案里，遵循 UTF-8 **字符编码方式**的 Unicode **字符集**也成为了互联网上的标准字符集。

## 语言类型使用的头字段

同样的，HTTP 协议也使用 Accept 请求头字段和 Content 实体头字段，用于客户端和服务器就语言与编码进行“内容协商”。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5gnw04j2zj31jk0v5qes.jpg)

**Accept-Language** 字段标记了客户端可理解的自然语言，也允许用“,”做分隔符列出多个类型，例如：

```
Accept-Language: zh-CN, zh, en
```

这个请求头会告诉服务器：“最好给我 zh-CN 的汉语文字，如果没有就用其他的汉语方言，如果还没有就给英文”。

相应的，服务器应该在响应报文里用头字段 **Content-Language** 告诉客户端实体数据使用的实际语言类型：

```
Content-Language: zh-CN
```

字符集在 HTTP 里使用的请求头字段是 **Accept-Charset**，但却没有对应的响应头，**而是在 Content-Type 字段的数据类型后面用“charset=xxx”来表示**。

例如，浏览器请求 GBK 或 UTF-8 的字符集，然后服务器返回的是 UTF-8 编码，就是下面这样：

```
Accept-Charset: gbk, utf-8
Content-Type: text/html; charset=utf-8
```

不过现在的浏览器都支持多种字符集，通常不会发送 Accept-Charset，而服务器也不会发送 Content-Language，因为**使用的语言完全可以由字符集推断出来**，**所以在请求头里一般只会有 Accept-Language 字段，响应头里只会有 Content-Type 字段**。

## 内容协商的质量值

在 HTTP 协议里用 Accept、Accept-Encoding、Accept-Language 等请求头字段进行内容协商的时候，可以用一种特殊的“q”参数表示权重来设定优先级，这里的“q”是“quality factor”的意思。

权重的最大值是 1，最小值是 0.01，默认值是 1，如果值是 0 就表示拒绝。

具体的形式是在数据类型或语言代码后面加一个“;”，然后是“q=value”。这里要提醒的是“;”的用法，在大多数编程语言里“;”的断句语气要强于“,”，而在 HTTP 的内容协商里“;”的意义是小于“,”的。例如下面的 Accept 字段：

```
Accept: text/html,application/xml;q=0.9,*/*;q=0.8
```

它表示浏览器最希望使用的是 HTML 文件，权重是 1，其次是 XML 文件，权重是 0.9，**最后是任意数据类型**，权重是 0.8。服务器收到请求头后，就会计算权重，再根据自己的实际情况优先输出 HTML 或者 XML。

## 内容协商的结果

内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。但有的时候，服务器会在**响应头**里多加一个 **Vary** 字段，**记录服务器在内容协商时参考的请求头字段，给出一点信息**，例如：

```
Vary: Accept-Encoding,User-Agent,Accept
```

这个 Vary 字段表示服务器依据了 Accept-Encoding、User-Agent 和 Accept 这三个头字段，**然后决定了发回的响应报文**。Vary 字段可以认为是响应报文的一个特殊的“版本标记”。**每当 Accept 等请求头变化时，Vary 也会随着响应报文一起变化**。也就是说，**同一个 URI 可能会有多个不同的“版本”，主要用在传输链路中间的代理服务器实现缓存服务**。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5gpjl471ij31jk0s1n63.jpg)

## 小结

- **数据类型**表示实体数据的**内容是什么**，使用的是 MIME type，相关的头字段是 Accept 和 Content-Type；

- **数据编码**表示实体数据的**压缩方式**，相关的头字段是 Accept-Encoding 和 Content-Encoding；

- **语言类型**表示实体数据的**自然语言**，相关的头字段是 Accept-Language 和 Content-Language；

- **字符集**表示实体数据的编码方式，相关的头字段是 Accept-Charset 和 Content-Type；

- 客户端需要在请求头里使用 Accept 等头字段与服务器进行“内容协商”，要求服务器返回最合适的数据；

- Accept 等头字段可以用“,”顺序列出多个可能的选项，还可以用“;q=”参数来精确指定权重。

##  Q&A

- content-type是实体字段，所以请求和响应里都可以用，作用是指明body数据的类型。比如：上传图片时候客户端需要设置content-type:"image/jpg"。不然如果使用上传的js-sdk设置的默认类型：content-type:"octet-stream"，那么浏览器就不认识这个图片了，转而会下载这个文件(图片)。
- 每一个并发连接，都需要新建tcp三次握手吗？还是一次tcp握手后，可以并发多个连接？
  -  每建立一个连接就需要tcp握手，对同一个ip地址+端口，浏览器通常最多建立6个并发连接（rfc 的规定）。
- 现在很多小文件，比如 图片 都往云存上放了，千万指定正确content-type，一旦指定错，批量修改太麻烦，而且会影响终端的解析。
- post和get时都可以使用Accept-Language，表示客户端可以理解的语言，要求服务器按照指示返回数据。 Content-Language表示的是body数据的语言，因为post带有body，所以要用Content-Language来告诉服务器，报文的body是什么。 如果get报文也有body，那么它也可以使用Content-Language。`Content-`表示提供的具体信息，由于客户端与服务端都可以提供信息，所以`Content-`是可以在两端都可以用的。
- Accept-Language是请求头字段，只要是发请求就可以带。 Content-Language是实体头字段，只要是有body就可以带。
- 文件上传的大小限制都是有哪些限制或控制？发现有些框架默认只能是2g
  - http协议对大小没有限制，这些应该都是网站服务器做的限制，比如Nginx就可以设置client body的大小。
- charset不能同时使用两种编码。

# HTTP传输大文件

## 数据压缩

gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小（甚至还有可能会增大一点），所以它就失效了。

不过数据压缩在处理文本的时候效果还是很好的，所以各大网站的服务器都会使用这个手段作为“保底”。例如，在 Nginx 里就会使用“gzip on”指令，启用对“text/html”的压缩。

## 分块传输

分块传输的思路在 HTTP 协议里就是“chunked”分块传输编码，在 **响应报文** 里用头字段 “**Transfer-Encoding: chunked**” 来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。

分块传输也可以用于“流式数据”，例如由数据库动态生成的表单页面，这种情况下 body 数据的长度是未知的，无法在头字段“Content-Length”里给出确切的长度，所以也只能用 chunked 方式分块发送。

“Transfer-Encoding: chunked” 和 “Content-Length” 这两个字段是互斥的，响应报文里这两个字段不能同时出现。

分块传输的编码规则同样采用了明文的方式，很类似响应头。**每个分块包含两个部分，长度头和数据块；长度头是以 CRLF（回车换行，即\r\n）结尾的一行明文，用 16 进制数字表示长度；数据块紧跟在长度头后，最后也用 CRLF 结尾，但数据不包含 CRLF**；最后用一个长度为 0 的块表示结束，即“0\r\n\r\n”。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5gqd6l291j32bc1ap4ar.jpg)

浏览器在收到分块传输的数据后会自动按照规则去掉分块编码，重新组装出内容，想要看到服务器发出的原始报文形态得用 Telnet 手工发送请求（或者用 Wireshark 抓包）

## 范围请求

比如，你在看当下正热播的某穿越剧，想跳过片头，直接看正片，或者有段剧情很无聊，想拖动进度条快进几分钟，这实际上是想获取一个大文件其中的片段数据。

HTTP 协议为了满足这样的需求，提出了“范围请求”（range requests）的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分。

范围请求不是 Web 服务器必备的功能，可以实现也可以不实现，所以**服务器必须在响应头里使用字段“Accept-Ranges: bytes”明确告知客户端”**，如果不支持的话服务器可以发送“Accept-Ranges: none”，或者干脆不发送“Accept-Ranges”字段，这样客户端就认为服务器没有实现范围请求功能。

请求头 Range 是 HTTP 范围请求的专用字段，格式是“bytes=x-y”，其中的 x 和 y 是以**字节**为单位的数据范围。要注意 x、y 表示的是“**偏移量**”，**范围必须从 0 计数**。起点 x 和终点 y 可以省略：“0-”表示从文档起点到文档终点；“10-”是从第 10 个字节开始到文档末尾；“-1”是文档的最后一个字节；“-10”是从文档末尾倒数 10 个字节。

服务器收到 Range 字段后，需要做四件事：

第一，它必须检查范围是否合法，如果范围越界了。服务器就会返回状态码 **416**。

第二，如果范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码“**206 Partial Content**”，表示 body 只是原数据的一部分。

第三，服务器要添加一个响应头字段 Content-Range，告诉片段的实际偏移量和资源的总大小，格式是“bytes x-y/length”，与 Range 头区别在没有“=”，范围后多了总长度。例如，对于“0-10”的范围请求，值就是“bytes 0-10/100”。

第四，发送数据，直接把片段用 TCP 发给客户端，一个范围请求就算是处理完了。

有了范围请求之后，HTTP 处理大文件就更加轻松了，看视频时可以根据时间点计算出文件的 Range，不用下载整个文件，直接精确获取片段所在的数据内容。不仅看视频的拖拽进度需要范围请求，常用的下载工具里的多段下载、断点续传也是基于它实现的，要点是：

- 先发个 HEAD，看服务器是否支持范围请求，同时获取文件的大小；
- 开 N 个线程，每个线程使用 Range 字段划分出各自负责下载的片段，发请求传输数据；
- 下载意外中断也不怕，不必重头再来一遍，只要根据上次的下载记录，用 Range 请求剩下的那一部分就可以了。

## 多段数据

还可以在 Range 头里使用多个“x-y”，一次性获取多个片段数据。

这种情况需要使用一种**特殊的 MIME 类型：“multipart/byteranges”**，表示报文的 body 是由多段字节序列组成的，**用一个参数“boundary=xxx”给出段之间的分隔标记**。多段数据的格式与分块传输也比较类似，但它需要用分隔标记 boundary 来区分不同的片段。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5gr38hr21j32bc1apqld.jpg)

**每一个分段必须以“- -boundary”开始**（前面加两个“-”），之后要用“Content-Type”和“Content-Range”标记这段数据的类型和所在范围，然后就像普通的响应头一样以回车换行结束，再加上分段数据，**最后用一个“- -boundary- -”**（前后各有两个“-”）表示所有的分段结束。

例如：

```
GET /16-2 HTTP/1.1
Host: www.chrono.com
Range: bytes=0-9, 20-29
```

```
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=00000000001
Content-Length: 189
Connection: keep-alive
Accept-Ranges: bytes

--00000000001
Content-Type: text/plain
Content-Range: bytes 0-9/96

// this is
--00000000001
Content-Type: text/plain
Content-Range: bytes 20-29/96

ext json d
--00000000001--
```

报文里的“- -00000000001”就是多段的分隔符。

## 小结

- 压缩 HTML 等文本文件是传输大文件最基本的方法；分块传输可以流式收发数据，节约内存和带宽，使用**响应头字段“Transfer-Encoding: chunked“**来表示，**分块的格式是 16 进制长度头 + 数据块**；
- 范围请求可以只获取部分数据，即“分块请求”，实现视频拖拽或者断点续传，使用**请求头字段“Range”**和**响应头字段“Content-Range”**，响应状态码必须是 **206**；
- 也可以一次请求多个范围，这时候**响应报文的数据类型是“multipart/byteranges”**，body 里的多个部分会用 boundary 字符串分隔。
- 这四种方法不是互斥的，而是可以混合起来使用，例如**压缩后再分块传输**，或者**分段后再分块**。
- gzip 的压缩率通常能够超过60%，**br算法是专为HTML设计的**，压缩效率和性能比 gzip还要好，能够再提高20%的压缩密度。
- Nginx的“gzip on”指令很智能，只会压缩文本数据，不会压缩图片、音频、视频。
- Transfer-Encoding字段最常见的值是chunked，但也可以用gzip、deflate 等，表示传输时使用了压缩编码。**Transfer-Encoding在传输后会被自动解码还原出原始数据，而 Content-Encoding 则必须由应用自行解码。**
- 分块传输在末尾还允许有“拖尾数据”，由**响应头字段”Trailer“**指定。
- 与Range有关的还有一个If-Range，即条件范围请求，与缓存有关。

## Q&A

- 分块传输数据的时候，如果数据里含有回车换行（\r\n）是否会影响分块的处理呢？
  - 不影响分块处理，因为分块前有数据长度说明。
- 如果对一个被 gzip 的文件执行范围请求，比如“Range: bytes=10-19”，那么这个范围是应用于原文件还是压缩后的文件呢？
  - 分情况，看原文件是什么形式。如果原来的文件是gzip的，那就应用于压缩后的文件。如果原文件是文本，而在传输过程中被压缩，那么就应用于压缩前的数据。
- chunk只是在传输过程中分块，最后到客户端会是一个完整的文件。

- 分块传输，客户端只需要发一次请求，还是发多次请求呢？使用分块传输时，客户端与服务器是怎样工作的？
  - http传输永远是一个请求一个响应的工作模式，一个http请求必定是在一个tcp连接里收发的。 虽然是分块，但也是用一个tcp。只是响应是chunked分块，body数据不是一次性发过来的，而是分批分块发送，**但仍然是在一个报文里**。 客户端发送请求后等待响应，服务器组织数据，分块发送，最后一个分块是结束标志。客户端依次接收分块，**收到结束标志后就把数据拼成完整的报文**。
- 客户端上传的时候也可以用chunked、gzip，但不能用range。
- 分块：http把客户端需要的东西切分成1、2、3到n块，然后将1块发给tcp，tcp将块1再次切分后发给客户端，客户端接受后在tcp组装成块1发给http层。然后服务器与客户端用同样的方式发送块2、块3到块n。客户端的http在接收完所有块后组装成一个完整的响应。整个过程使用同一个tcp连接，块1到块n如上是挨个发送的。**如果是http2，则基于多路复用技术块1到块n可以同时发送**。**所以分块抓包http只能抓到一个包，如果抓tcp的包，分不分块，都会抓到很多包。**
- 如果Content-Length是0，报文里也可以有body，但因为头里指定长度为0，所以服务器就会忽略body，也不能算是错误报文。
- 如果不显式设置Content-Length，有的框架会自动填写这个字段，或者就变成了chunked格式。
- HTTP 没有校验功能，只使用偏移量来拼接块。
- 处理chunked数据其实就是处理字符串，因为chunked格式很清晰，可以正则。
- 在一个TCP连接中，①大文件分片后，对多个文件片进行并发上传（在一个TCP连接中多个http是排队处理的），与②对一个大文件上传，①②速度上有区别吗？
  - **在http/1.1里是不能并发上传的，只能串行。 1/2两种情况速度上没区别，但整个大文件传输会占用很多内存**。
- 使用chunk分段后还能压缩吗？或者说chunk分段分的是压缩后还是压缩前的文件呢？
  - 可以的，先压缩再分块。
- 使用了chunk，为什么内存、带宽会节省呢？总的数据大小不变吧？内存的话，分段后，前面的数据到达浏览器客户端后，是存在内存还是磁盘呢？如何节省内存呢?
  -  分块的好处是每次只处理一小部分数据，比如一次只从磁盘读取10k，而不用把1G的文件都读进内存，发的时候也可以慢慢发，所以就节省了内存、带宽，对方收到数据肯定是先在内存里，之后可以用各种策略，比如达到一定的大小（比如1M）就落盘存。
- web客户端可以分批上传一个大文件的功能吗？类似于云盘中的上传功能。
  - 上传就要用chunked功能，流式发送数据，服务器流式接收数据。 **range功能只能是下载用，不能上传**。

# HTTP的连接管理

## 短连接

HTTP 协议最初（0.9/1.0）通信过程采用了简单的“请求 - 应答”方式。

它底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接，称为“**短连接**”（short-lived connections）。早期的 HTTP 协议也被称为是“**无连接**”的协议。

短连接的缺点相当严重，因为在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。TCP 建立连接要有“三次握手”，发送 3 个数据包，需要 **1 个 RTT**；关闭连接是“四次挥手”，4 个数据包需要 2 个 RTT。

## 长连接

针对短连接暴露出的缺点，HTTP 协议就提出了“长连接”的通信方式，也叫“持久连接”（persistent connections）、“连接保活”（keep alive）、“连接复用”（connection reuse）。

## 连接相关的头字段

在 HTTP/1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接。

也可以在请求头里明确地要求使用长连接机制，使用字段“Connection: keep-alive”。不过不管客户端是否显式要求长连接，如果服务器支持长连接，它总会在响应报文里放一个“Connection: keep-alive”字段，告诉客户端：“我是支持长连接的，接下来就用这个 TCP 一直收发数据吧”。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5gu9pfjbgj30vq0bvn0u.jpg)

不过长连接也有一些小缺点。因为 TCP 连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务。

所以，长连接也需要在恰当的时间关闭，不能永远保持与服务器的连接，这在客户端或者服务器都可以做到。

在客户端，可以在请求头里加上“Connection: close”字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接。

服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 Nginx 来举例，它有两种方式：使用“keepalive_timeout”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。使用“keepalive_requests”指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。

另外，客户端和服务器都可以在报文里附加通用头字段“Keep-Alive: timeout=value”，限定长连接的超时时间。但这个字段的约束力并不强，通信的双方可能并不会遵守，所以不太常见。

## 队头阻塞（Head-of-line blocking，也叫“队首阻塞”）

“队头阻塞”与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。

因为 HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本。

性能优化因为“请求 - 应答”模型不能变，所以“队头阻塞”问题在 HTTP/1.1 里无法解决，只能缓解，也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。但这种方式也存在缺陷。如果每个客户端都想自己快，建立很多个连接，用户数×并发数 就会是个天文数字。服务器的资源根本就扛不住，或者被服务器认为是恶意攻击，反而会造成“拒绝服务”。所以，HTTP 协议建议客户端使用并发，但不能“滥用”并发。RFC2616 里明确限制每个客户端最多并发 2 个连接。不过实践证明这个数字实在是太小了，众多浏览器都“无视”标准，把这个上限提高到了 6~8。

“域名分片”（domain sharding）技术，还是用数量来解决质量的思路。HTTP 协议和浏览器限制并发连接数量吗。那就多开几个域名，比 shard1.chrono.com、shard2.chrono.com，而这些域名都指向同一台服务器 `www.chrono.com`。

## 小结

- HTTP/1.1 默认启用长连接，在一个连接上收发多个请求响应；
- 服务器会发送“Connection: keep-alive”字段表示启用了长连接；
- 报文头里如果有“Connection: close”就意味着长连接即将关闭；
- 过多的长连接会占用服务器资源，所以服务器会用一些策略有选择地关闭长连接；
- “队头阻塞”问题会导致性能下降，可以用“并发连接”和“域名分片”技术缓解。
- 因为TCP协议还有“慢启动”“拥塞窗口”等特性，通常新建立的“冷连接”会比打开了一段时间的“热连接”要慢一些，所以长连接比短连接还多了这一层的优势。
- 在长连接中的一个重要问题是如何正确地区分多个报文的开始和结束，所以最好总使用"Content-Length”头明确响应实体的长度，正确标记报文结束。如果是流式传输,body长度不能立即确定，就必须用分块传输编码。
- Connection字段还有一个取值:"Connection: Upgrade”，配合状态码101表示协议升级，例如从HTTP切换到WebSocket。
- 一般使用长连接，除非明确知道只会发送一个请求，比如游戏内连接兑换码服务进行礼包兑换。 
  - 服务器端设置keepalive＿timeout表示多长时间没有数据则关闭连接。 
  - 服务器端设置keepalive_requests，表示该连接上处理多少个请求后关闭连接。 
  - 服务器端设置最大连接数，当连接达到上限之后拒绝连接，也可以采用限流措施等。 
  - 客户端设置keepalive_requests，表示该连接上发送多少个连接后关闭连接。 
  - 客户端设置keepalive_timeout，表示多长时间没有数据发送则关闭连接。 
  - 客户端设置响应超时后重试次数，当次数达到上限后关闭连接。

## Q&A

- 域名分片解决的是客户端并发的问题，可以创建更多的连接。
- HTTP的连接管理还有第三种方式 pipeline(管道，或者叫流水线)，它在长连接的基础上又进了一步，可以批量发送请求批量接收响应，但因为存在一些问题，Chrome、Firefox等浏览器都没有实现它，已经被事实上“废弃”了。
- 服务器或者客户端是怎么是判断一个连接的呢？
  - http里的连接通常就是tcp连接，也就是调用socket api打开的一个套接字，可以理解成一个流式文件的句柄，可读可写，但数据都是在网络上。

# HTTP的重定向和跳转

点击页面“链接”时的跳转是怎样的呢？具体一点，比如在 Nginx 的主页上点了一下“download”链接，会发生什么呢？

结合之前的课程，稍微思考一下你就能得到答案：浏览器首先要解析链接文字里的 URI。`http://nginx.org/en/download.html`，再用这个 URI 发起一个新的 HTTP 请求，获取响应报文后就会切换显示内容，渲染出新 URI 指向的页面。

这样的跳转动作是由浏览器的使用者主动发起的，可以称为“**主动跳转**”，但还有一类跳转是由服务器来发起的，浏览器使用者无法控制，相对地就可以称为“**被动跳转**”，这在 HTTP 协议里有个专门的名词，叫做“**重定向**”（Redirection）。

## 重定向的过程

301 是“永久重定向”，302 是“临时重定向”，浏览器收到这两个状态码就会跳转到新的 URI。例如：一次“重定向”实际上发送了两次 HTTP 请求，第一个请求返回了 302，然后第二个请求就被重定向到了“/index.html”。但如果不用开发者工具的话，你是完全看不到这个跳转过程的，也就是说，重定向是“用户无感知”的。

我们再来看看第一个请求返回的响应报文：

![](https://tva1.sinaimg.cn/large/006DIypxly1h5hpkvgktuj31gs0kjagt.jpg)

这里出现了一个新的头字段“Location: /index.html”。“Location”字段属于响应字段，必须出现在响应报文里。但只有配合 301/302 状态码才有意义，它标记了服务器要求重定向的 URI，这里就是要求浏览器跳转到“index.html”。

浏览器收到 301/302 报文，会检查响应头里有没有“Location”。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求，相当于自动替我们点击了这个链接。在“Location”里的 URI 既可以使用绝对 URI，也可以使用相对 URI。

所谓“绝对 URI”，就是完整形式的 URI，包括 scheme、host:port、path 等。

所谓“相对 URI”，就是省略了 scheme 和 host:port，只有 path 和 query 部分，是不完整的，但可以从请求上下文里计算得到。例如，“Location: /index.html”用的就是相对 URI。

在重定向时如果只是在站内跳转，你可以放心地使用相对 URI。但如果要跳转到站外，就必须用绝对 URI。例如，如果想跳转到 Nginx 官网，就必须在“nginx.org”前把“http://”都写出来，否则浏览器会按照相对 URI 去理解，得到的就会是一个不存在的 URI。

## 重定向状态码

最常见的重定向状态码就是 301 和 302，另外还有几个不太常见的，例如 303、307、308 等。它们最终的效果都差不多，让浏览器跳转到新的 URI，但语义上有一些细微的差别，使用的时候要特别注意。

301 俗称“永久重定向”（Moved Permanently），意思是原 URI 已经“永久”性地不存在了，今后的所有请求都必须改用新的 URI。浏览器看到 301，就知道原来的 URI“过时”了，就会做适当的优化。比如历史记录、更新书签，下次可能就会直接用新的 URI 访问，省去了再次跳转的成本。搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI。

302 俗称“临时重定向”（“Moved Temporarily”），意思是原 URI 处于“临时维护”状态，新的 URI 是起“顶包”作用的“临时工”。浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，所以只会执行简单的跳转页面，不记录新的 URI，也不会有其他的多余动作，下次访问还是用原 URI。

303 See Other：类似 302，但要求重定向后的请求改为 GET 方法，访问一个结果页面，避免 POST/PUT 重复操作。

307 Temporary Redirect：类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确。

308 Permanent Redirect：类似 307，不允许重定向后的请求变动，但它是 301“永久重定向”的含义。

后面三个状态码有的浏览器和服务器可能不支持，开发时应测试确认。

## 重定向的应用场景

重定向可以让服务器端拥有主动权，控制浏览器的行为。

一个最常见的原因就是“资源不可用”，需要用另一个新的 URI 来代替。例如域名变更、服务器变更、网站改版、系统维护，这些都会导致原 URI 指向的资源无法访问，为了避免出现 404，就需要用重定向跳转到新的 URI。

另一个原因就是“避免重复”，让多个网址都跳转到一个 URI，增加访问入口的同时还不会增加额外的工作量。例如，有的网站都会申请多个名称类似的域名，然后把它们再重定向到主站上。

301 的含义是“永久”的。如果域名、服务器、网站架构发生了大幅度的改变，比如启用了新域名、服务器切换到了新机房、网站目录层次重构，这些都算是“永久性”的改变。原来的 URI 已经不能用了，必须用 301“永久重定向”，通知浏览器和搜索引擎更新到新地址，这也是搜索引擎优化（SEO）要考虑的因素之一。

302 的含义是“临时”的。原来的 URI 在将来的某个时间点还会恢复正常，常见的应用场景就是系统维护，把网站重定向到一个通知页面，告诉用户过一会儿再来访问。另一种用法就是“服务降级”，比如在双十一促销的时候，把订单查询、领积分等不重要的功能入口暂时关闭，保证核心服务能够正常运行。

## 重定向的相关问题

第一个问题是“性能损耗”。很明显，重定向的机制决定了一个跳转会有两次请求 - 应答，比正常的访问多了一次。虽然 301/302 报文很小，但大量的跳转对服务器的影响也是不可忽视的。站内重定向还好说，可以长连接复用，站外重定向就要开两个连接，如果网络连接质量差，那成本可就高多了，会严重影响用户的体验。所以重定向应当适度使用，决不能滥用。

第二个问题是“循环跳转”。如果重定向的策略设置欠考虑，可能会出现“A=>B=>C=>A”的无限循环，不停地在这个链路里转圈圈，后果可想而知。所以 HTTP 协议特别规定，浏览器必须具有检测“循环跳转”的能力，在发现这种情况时应当停止发送请求并给出错误提示。

## 小结

- 重定向是**服务器发起的**跳转，要求客户端改用新的 URI 重新发送请求，通常会自动进行，用户是无感知的；
- 301/302 分别是“永久重定向”和“临时重定向”；
- 响应头字段 Location 指示了要跳转的 URI，可以用绝对或相对的形式；
- 重定向可以把一个 URI 指向另一个 URI，也可以把多个 URI 指向同一个 URI，用途很多；
- 使用重定向时需要当心性能损耗，还要避免出现循环跳转。
- 重定向报文里还可以用Refresh字段，实现延时重定向，例如“Refresh: 5; url=xxx”告诉浏览器5秒钟后再跳转。
- 与跳转有关的还有一个 “Referer” 和 "Referrer-Policy” (注意前者是个拼写错误，但已经“将错就错”)，表示浏览器跳转的来源(即引用地址)，可用于统计分析和防盗链。

## Q&A

- 网页的“入链接”和“出链接”也是标记网页重要性的关键指标，最著名的就是Google发明的PageRank。
- “300 Multiple Choices”也是一个特殊的重定向状态码，它会返回一个有多个链接选项的页面，由用户自行选择要跳转的链接，用的较少。
- 301/302重定向是由浏览器执行的，对于服务器来说可以称为“外部重定向”，相应的也就有服务器的“内部重定向”，直接在服务器内部跳转URl，因为不会发出HTTP请求，所以没有额外的性能损失。

# HTTP的Cookie机制

HTTP 是“无状态”的，这既是优点也是缺点。优点是服务器没有状态差异，可以很容易地组成集群，而缺点就是无法支持需要记录状态的事务操作。好在 HTTP 协议是可扩展的，后来发明的 Cookie 技术，给 HTTP 增加了“记忆能力”。

## 什么是 Cookie？

HTTP 里“无状态”的 Web 服务器连一分钟的记忆也保存不了，请求处理完立刻就忘得一干二净。如果 Web 服务器只是用来管理静态文件还好说，对方是谁并不重要，把文件从磁盘读出来发走就可以了。但随着 HTTP 应用领域的不断扩大，对“记忆能力”的需求也越来越强烈。比如网上论坛、电商购物，都需要“看客下菜”，只有记住用户的身份才能执行发帖子、下订单等一系列会话事务。

HTTP 的 Cookie 机制是既然服务器记不住，那就在外部想办法记住。相当于是服务器给每个客户端都贴上一张小纸条，上面写了一些只有服务器才能理解的数据，需要的时候客户端把这些信息发给服务器，服务器看到 Cookie，就能够认出对方是谁了。

## Cookie 的工作过程

Cookie 这张小纸条是怎么传递的呢？

这要用到两个字段：响应头字段 **Set-Cookie** 和请求头字段 **Cookie**。

当用户通过浏览器第一次访问服务器的时候，服务器肯定是不知道他的身份的。所以，就要创建一个独特的身份标识数据，格式是“**key=value**”，然后放进 **Set-Cookie** 字段里，**随着响应报文一同发给浏览器**。

浏览器收到响应报文，看到里面有 **Set-Cookie**，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进 **Cookie** 字段里发给服务器。

因为第二次请求里面有了 **Cookie** 字段，服务器就知道这个用户不是新人，之前来过，就可以拿出 Cookie 里的值，识别出用户的身份，然后提供个性化的服务。

不过因为服务器的“记忆能力”实在是太差，一张小纸条经常不够用。所以，服务器有时会在响应头里添加多个 Set-Cookie，存储多个“key=value”。但浏览器这边发送时不需要用多个 Cookie 字段，只要在一行里用“;”隔开就行。

我画了一张图来描述这个过程，你看过就能理解了。

![img](https://tva1.sinaimg.cn/large/006DIypxly1h5htsh63t3j31mc0plwpi.jpg)

从这张图中我们也能够看到，**Cookie 是由浏览器负责存储的，而不是操作系统。**所以，它是“浏览器绑定”的，**只能在本浏览器内生效**。

## Cookie 的属性

首先，我们应该**设置 Cookie 的生存周期**，也就是它的有效期，让它只能在一段时间内可用，就像是食品的“保鲜期”，一旦超过这个期限浏览器就认为是 Cookie 失效，在存储里删除，也不会发送给服务器。

Cookie 的有效期可以使用 **Expires** 和 **Max-Age** 两个属性来设置。

“**Expires**”俗称“过期时间”，用的是绝对时间点，可以理解为“截止日期”（deadline）。“**Max-Age**”用的是相对时间，单位是秒，浏览器用收到报文的时间点再加上 Max-Age，就可以得到失效的绝对时间。

Expires 和 Max-Age 可以同时出现，两者的失效时间可以一致，也可以不一致，**浏览器会优先采用 Max-Age 计算失效期**。

其次，我们需要**设置 Cookie 的作用域**，让浏览器仅发送给特定的服务器和 URI，避免被其他网站盗用。

“**Domain**”和“**Path**”指定了 Cookie 所属的域名和路径，浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie。

使用这两个属性可以为不同的域名和路径分别设置各自的 Cookie，比如“/19-1”用一个 Cookie，“/19-2”再用另外一个 Cookie，两者互不干扰。不过现实中为了省事，通常 Path 就用一个“/”或者直接省略，表示域名下的任意路径都允许使用 Cookie，让服务器自己去挑。

最后要考虑的就是 **Cookie 的安全性**了，尽量不要让服务器以外的人看到。在 JS 脚本里可以用 document.cookie 来读写 Cookie 数据，这就带来了安全隐患，有可能会导致“跨站脚本”（XSS）攻击窃取数据。

属性“**HttpOnly**”会告诉浏览器，此 Cookie 只能通过浏览器 HTTP 协议传输，禁止其他方式访问，**浏览器的 JS 引擎就会禁用 document.cookie 等一切相关的 API**，脚本攻击也就无从谈起了。

另一个属性“**SameSite**”可以防范“跨站请求伪造”（XSRF）攻击，**设置成“SameSite=Strict”可以严格限定 Cookie 不能随着跳转链接跨站发送**，而“SameSite=Lax”则略宽松一点，允许 GET/HEAD 等安全方法，**但禁止 POST 跨站发送**。

还有一个属性叫“**Secure**”，表示这个 Cookie 仅能用 HTTPS 协议加密传输，明文的 HTTP 协议会禁止发送。**但 Cookie 本身不是加密的，浏览器里还是以明文的形式存在**。

## Cookie 的应用

Cookie 最基本的一个用途就是**身份识别**，保存用户的登录信息，实现会话事务。

比如，你用账号和密码登录某电商，登录成功后网站服务器就会发给浏览器一个 Cookie，内容大概是“name=yourid”，这样就成功地把身份标签贴在了你身上。

之后你在网站里随便访问哪件商品的页面，浏览器都会自动把身份 Cookie 发给服务器，所以服务器总会知道你的身份，一方面免去了重复登录的麻烦，另一方面也能够自动记录你的浏览记录和购物下单（在后台数据库或者也用 Cookie），实现了“状态保持”。

Cookie 的另一个常见用途是**广告跟踪**。

你上网的时候肯定看过很多的广告图片，这些图片背后都是广告商网站（例如 Google），它会“偷偷地”给你贴上 Cookie 小纸条，这样你上其他的网站，别的广告就能用 Cookie 读出你的身份，然后做行为分析，再推给你广告。

这种 Cookie 不是由访问的主站存储的，所以又叫“第三方 Cookie”（third-party cookie）。如果广告商势力很大，广告到处都是，那么就比较“恐怖”了，无论你走到哪里它都会通过 Cookie 认出你来，实现广告“精准打击”。

为了防止滥用 Cookie 搜集用户隐私，互联网组织相继提出了 DNT（Do Not Track）和 P3P（Platform for Privacy Preferences Project），但实际作用不大。

## 小结

- Cookie 是服务器委托浏览器存储的一些数据，让服务器有了“记忆能力”；
- 响应报文使用 Set-Cookie 字段发送“key=value”形式的 Cookie 值；
- 请求报文里用 Cookie 字段发送多个 Cookie 值；
- 为了保护 Cookie，还要给它设置有效期、作用域等属性，常用的有 Max-Age、Expires、Domain、HttpOnly 等；
- Cookie 最基本的用途是身份识别，实现有状态的会话事务。
- Cookie 并不属于 HTTP 标准（RFC6265，而不是 RFC2616/7230），所以语法上与其他字段不太一致，使用的分隔符是“;”，与 Accept 等字段的“,”不同。

## Q&A

- 如果 Cookie 的 Max-Age 属性设置为 0，会有什么效果呢？ 
  - 设置为0，服务器0秒就让Cookie失效，即立即失效，服务器不存Cookie。
  - Max-Age=0是指不能缓存，但在会话期间是可用的，浏览器会话关闭之前可以用cookie记录用户的信息。
- 早期Cookie直接就是磁盘上的一些小文本文件，现在基本上都是以数据库记录的形式存放的(通常使用的是 Sqlite)。浏览器对Cookie的数量和大小也都有限制，不允许无限存储，—般总大小不能超过4K。
- 如果不指定Expires 或 Max-Age 属性，那么Cookie仅在浏览器运行时有效，一旦浏览器关闭就会失效，这被称为会话Cookie (sessioncookie)或内存Cookie (in-memory cookie)，在Chrome里过期时间会显示为“Session”或"N/A”。
- cookie和session的区别？
  - Cookie是存在客户端的，session是存在服务器的，都是用来保存用户的会话信息。 Cookie属于http协议的规定，而session不是协议规定，只是服务器的一种实现方式。
- Cookie中Domain可以设置为另外一个一级域名吗，比如当前请求是A.com，Domain可以设置为B.com，这样发送请求给B.com，也会带上这个cookie？
  - 谷歌浏览器会有检验，并不会发送cookie给B.com，也就是跨一级域名是不能设置cookie成功的。但是，如果设置成一级域名，是可以在不同的二级域名下共享cookie的。

# HTTP的缓存控制

缓存（Cache）是计算机领域里的一个重要概念，是优化系统性能的利器。

由于链路漫长，网络时延不可控，浏览器使用 HTTP 获取资源的成本较高。所以，非常有必要把“来之不易”的数据缓存起来，下次再请求的时候尽可能地复用。这样，就可以避免多次请求 - 应答的通信成本，节约网络带宽，也可以加快响应速度。

试想一下，如果有几十 K 甚至几十 M 的数据，不是从网络而是从本地磁盘获取，那将是多么大的一笔节省，免去多少等待的时间。

HTTP 传输的每一个环节基本上都会有缓存。基于“请求 - 应答”模式的特点，可以大致分为客户端缓存和服务器端缓存，**服务器端缓存经常与代理服务“混搭”在一起**。

## 服务器的缓存控制

整个流程 HTTP 就是：

浏览器发现缓存无数据，于是发送请求，向服务器获取资源；

服务器响应请求，返回资源，同时标记资源的有效期；

浏览器缓存资源，等待下次重用。

服务器标记资源有效期使用的头字段是“**Cache-Control**”，里面的值“**max-age=30**”就是资源的有效时间，相当于告诉浏览器，“这个页面只能缓存 30 秒，之后就算是过期，不能用。”

“Cache-Control”字段里的“max-age”和上一讲里 Cookie 有点像，都是标记资源的有效期。

注意，这里的 max-age 是“**生存时间**”（又叫“新鲜度”“缓存寿命”，类似 TTL，Time-To-Live），**时间的计算起点是响应报文的创建时刻（即 Date 字段，也就是离开服务器的时刻），而不是客户端收到报文的时刻**，也就是说包含了在链路传输过程中所有节点所停留的时间。

比如，服务器设定“max-age=5”，但因为网络质量很糟糕，等浏览器收到响应报文已经过去了 4 秒，那么这个资源在客户端就最多能够再存 1 秒钟，之后就会失效。

“max-age”是 HTTP 缓存控制最常用的属性，此外在响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存：

no-store：**不允许缓存**，用于某些变化非常频繁的数据，例如秒杀页面；

no-cache：**可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本**；

must-revalidate：如果过期了如果还想用就必须去服务器验证。

## 客户端的缓存控制

不止服务器可以发“Cache-Control”头，浏览器也可以发“Cache-Control”，也就是说请求 - 应答的双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略。

当你点“刷新”按钮的时候，浏览器会在请求头里加一个“**Cache-Control: max-age=0**”。因为 max-age 是“**生存时间**”，max-age=0 的意思就是“我要一个最最新鲜的西瓜”，而本地缓存里的数据至少保存了几秒钟，所以浏览器就不会使用缓存，而是向服务器发请求。服务器看到 max-age=0，也就会用一个最新生成的报文回应浏览器。

Ctrl+F5 的“强制刷新” 是因为请求头里的 If-Modified-Since 和 If-None-Match 会被清空所以会返回最新数据。

那么，浏览器的缓存究竟什么时候才能生效呢？

试着点一下浏览器的“前进”“后退”按钮，再看开发者工具，你就会惊喜地发现“from disk cache”的字样，意思是没有发送网络请求，而是读取的磁盘上的缓存。

如果用重定向跳转功能，也可以发现浏览器使用了缓存：

![](https://tva1.sinaimg.cn/large/006DIypxly1h5hxmlgvvrj31m20lpwon.jpg)

这几个操作与刷新有什么区别呢？

其实也很简单，**在“前进”“后退”“跳转”这些重定向动作中浏览器不会“夹带私货”，只用最基本的请求头，没有“Cache-Control”，所以就会检查缓存**，直接利用之前的资源，不再进行网络通信。

这个过程你也可以用 Wireshark 抓包，看看是否真的没有向服务器发请求。

## 条件请求

浏览器用“Cache-Control”做缓存控制只能是刷新数据，不能很好地利用缓存数据，又因为缓存会失效，使用前还必须要去服务器验证是否是最新版。

那么该怎么做呢？

浏览器可以用两个连续的请求组成“验证动作”：先是一个 HEAD，获取资源的修改时间等元信息，然后与缓存数据比较，如果没有改动就使用缓存，节省网络流量，否则就再发一个 GET 请求，获取最新的版本。

但这样的两个请求网络成本太高了，所以 HTTP 协议就定义了一系列 “**If**” 开头的 “**条件请求**” 字段，专门用来检查验证资源是否过期，把两个请求才能完成的工作合并在一个请求里做。而且，验证的责任也交给服务器，浏览器只需“坐享其成”。

条件请求一共有 5 个头字段，我们最常用的是 “**if-Modified-Since**” 和 “**If-None-Match**” 这两个。需要第一次的响应报文预先提供 “**Last-modified**” 和 “**ETag**” ，然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的。

如果资源没有变，服务器就回应一个“**304 Not Modified**”，表示缓存依然有效，浏览器就可以更新一下有效期，然后放心大胆地使用缓存了。

“Last-modified”很好理解，就是文件的最后修改时间。ETag 是什么呢？

ETag 是“实体标签”（Entity Tag）的缩写，**是资源的一个唯一标识**，主要是用来解决修改时间无法准确区分文件变化的问题。

比如，一个文件在一秒内修改了多次，但因为修改时间是秒级，所以这一秒内的新版本无法区分。

再比如，一个文件定期更新，但有时会是同样的内容，实际上没有变化，用修改时间就会误以为发生了变化，传送给浏览器就会浪费带宽。

使用 ETag 就可以精确地识别资源的变动情况，让浏览器能够更有效地利用缓存。

ETag 还有“强”“弱”之分。

强 ETag 要求资源在字节级别必须完全相符，弱 ETag 在值前有个“W/”标记，只要求资源在语义上没有变化，但内部可能会有部分发生了改变（例如 HTML 里的标签顺序调整，或者多了几个空格）。

条件请求里其他的三个头字段是 “If-Unmodified-Since”，“If-Match” 和 “If-Range”，其实只要你掌握了“if-Modified-Since”和“If-None-Match”，可以轻易地“举一反三”。

## 小结

- 服务器使用“Cache-Control”设置缓存策略，常用的是“max-age”，表示资源的有效期；
- 浏览器收到数据就会存入缓存，如果没过期就可以直接使用，过期就要去服务器验证是否仍然可用；
- 验证资源是否失效需要使用“条件请求”，常用的是“if-Modified-Since”和“If-None-Match”，收到 304 就可以复用缓存里的资源；
- 验证资源是否被修改的条件有两个：“Last-modified”和“ETag”，需要服务器预先在响应报文里设置，搭配条件请求使用；
- 浏览器也可以发送“Cache-Control”字段，使用“max-age=0”或“no_cache”刷新数据。

- 除了“Cache-Control”，服务器也可以用“Expires”字段来标记资源的有效期，它的形式和Cookie的差不多，同样属于“过时”的属性，优先级低于“Cache-Control”。
- 如果响应报文里提供了“Last-modified”，但没有“Cache-Control”或“Expires”，浏览器会使用“启发”(Heuristic)算法计算一个缓存时间，在RFC里的建议是:(Date - Last-modified) *10%。
- 每个Web服务器对ETag的计算方法都不一样，只要保证数据变化后值不一样就好，但复杂的计算会增加服务器的负担。Nginx的算法是“修改时间＋长度”，实际上和Last-modified基本等价。

## Q&A

- Cache 和 Cookie 的相同点？
  - 相同点：都会保存到浏览器中，并可以设置过期时间。 
- Cache 和 Cookie 的不同点？
  - Cookie 会随请求报文发送到服务器，而 Cache 不会，但可能会携带 if-Modified-Since（保存资源的最后修改时间）和 If-None-Match（保存资源唯一标识） 字段来验证资源是否过期。 
  - Cookie 在浏览器可以通过脚本获取（如果 cookie 没有设置 HttpOnly），Cache 则无法在浏览器中获取（出于安全原因）。
  - Cookie 通过响应报文的 Set-Cookie 字段获得，Cache 则是位于 body 中。
  - 用途不同。Cookie 常用于身份识别，Cache 则是由浏览器管理，用于节省带宽和加快响应速度。
  - Cookie 的 max-age 是从浏览器拿到响应报文时开始计算的，而 Cache 的 max-age 是从响应报文的生成时间（Date 头字段）开始计算。

# HTTP的代理服务

在前面讲 HTTP 协议的时候，我们严格遵循了 HTTP 的“请求 - 应答”模型，协议中只有两个互相通信的角色，分别是“请求方”浏览器（客户端）和“应答方”服务器。

今天，我们要在这个模型里引入一个新的角色，那就是HTTP 代理。

链条的起点还是客户端（也就是浏览器），中间的角色被称为代理服务器（proxy server），链条的终点被称为源服务器（origin server），意思是数据的“源头”“起源”。

## 代理服务

“代理”就是在客户端和服务器原本的通信链路中插入的一个中间环节，**也是一台服务器，但提供的是“代理服务”**。

所谓的“代理服务”就是指服务本身不生产内容，而是处于中间位置转发上下游的请求和响应，具有双重身份：面向下游的用户时，表现为服务器，代表源服务器响应客户端的请求；而面向上游的源服务器时，又表现为客户端，代表客户端发送请求。

代理有很多的种类，例如匿名代理、透明代理、正向代理和反向代理。

实际工作中最常见的**反向代理，它在传输链路中更靠近源服务器，为源服务器提供代理服务**。

## 代理的作用

代理处在 HTTP 通信过程的中间位置，相应地就对上屏蔽了真实客户端，对下屏蔽了真实服务器，简单的说就是“**欺上瞒下**”。在这个中间层里就可以做很多的事情，为 HTTP 协议增加更多的灵活性，实现客户端和服务器的“双赢”。

代理最基本的一个功能是**负载均衡**。因为在面向客户端时屏蔽了源服务器，客户端看到的只是代理服务器，源服务器究竟有多少台、是哪些 IP 地址都不知道。于是代理服务器就可以掌握请求分发的“大权”，决定由后面的哪台服务器来响应请求。

代理中常用的负载均衡算法比如轮询、一致性哈希等等。

在负载均衡的同时，代理服务还可以执行更多的功能，比如：

**健康检查**：使用“心跳”等机制监控后端服务器，发现有故障就及时“踢出”集群，保证服务高可用；

**安全防护**：保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载；

**加密卸载**：对外网使用 SSL/TLS 加密通信认证，而在安全的内网不加密，消除加解密成本；

**数据过滤**：拦截上下行的数据，任意指定策略修改请求或者响应；

**内容缓存**：暂存、复用服务器响应，我们稍后再说。

## 代理相关头字段

代理隐藏了真实客户端和服务器，如果双方想要获得这些“丢失”的原始信息，该怎么办呢？

首先，代理服务器需要用字段“**Via**”标明代理的身份。

Via 是一个通用字段，请求头或响应头里都可以出现。每当报文经过一个代理节点，代理服务器就会把自身的信息追加到字段的末尾，就像是经手人盖了一个章。

如果通信链路中有很多中间代理，就会在 Via 里形成一个链表，这样就可以知道报文究竟走过了多少个环节才到达了目的地。

例如下图中有两个代理：proxy1 和 proxy2，客户端发送请求会经过这两个代理，依次添加就是“Via:  proxy1, proxy2”，等到服务器返回响应报文的时候就要反过来走，头字段就是“Via:  proxy2,  proxy1”。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5hzef61w1j31jk0j3wmt.jpg)

Via 字段只解决了客户端和源服务器判断是否存在代理的问题，还不能知道对方的真实信息。

但服务器的 IP 地址应该是保密的，关系到企业的内网安全，所以一般不会让客户端知道。不过反过来，通常服务器需要知道客户端的真实 IP 地址，方便做访问控制、用户画像、统计分析。

可惜的是 HTTP 标准里并没有为此定义头字段，但已经出现了很多“事实上的标准”，最常用的两个头字段是“**X-Forwarded-For**”和“**X-Real-IP**”。

“X-Forwarded-For”的字面意思是“为谁而转发”，形式上和“Via”差不多，也是每经过一个代理节点就会在字段里追加一个信息。但“Via”追加的是代理主机名（或者域名），而**“X-Forwarded-For”追加的是请求方的 IP 地址。所以，在字段里最左边的 IP 地址就是客户端的地址。**

“X-Real-IP”是另一种获取客户端真实 IP 的手段，它的作用很简单，就是**记录客户端 IP 地址**，没有中间的代理信息，相当于是“X-Forwarded-For”的简化版。如果客户端和源服务器之间只有一个代理，那么这两个字段的值就是相同的。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5hzjz554vj31mo100hdt.jpg)

从抓包里就可以清晰地看出代理与客户端、源服务器的通信过程：

客户端 55061 先用三次握手连接到代理的 80 端口，然后发送 GET 请求；

代理不直接生产内容，所以就代表客户端，**用 55063 端口连接到源服务器**，也是三次握手；

代理成功连接源服务器后，发出了一个 HTTP/1.0 的 GET 请求；

因为 HTTP/1.0 默认是短连接，所以源服务器发送响应报文后立即用四次挥手关闭连接；

代理拿到响应报文后再发回给客户端，完成了一次代理服务。

在这个实验中，你可以看到除了“X-Forwarded-For”和“X-Real-IP”，还出现了两个字段：“X-Forwarded-Host”和“X-Forwarded-Proto”，它们的作用与“X-Real-IP”类似，**只记录客户端的信息，分别是客户端请求的原始域名和原始协议名**。

## 代理协议

有了“X-Forwarded-For”等头字段，源服务器就可以拿到准确的客户端信息了。但对于代理服务器来说它并不是一个最佳的解决方案。

因为通过“X-Forwarded-For”操作代理信息必须要解析 HTTP 报文头，这**对于代理来说成本比较高**，原本只需要简单地转发消息就好，而现在却必须要费力解析数据再修改数据，会降低代理的转发性能。

另一个问题是“X-Forwarded-For”等头必须要修改原始报文，而有些情况下是不允许甚至不可能的（比如使用 HTTPS 通信被加密）。

所以就出现了一个专门的“代理协议”（The PROXY protocol），它由知名的代理软件 HAProxy 所定义，也是一个“事实标准”，被广泛采用（注意并不是 RFC）。

“代理协议”有 v1 和 v2 两个版本，v1 和 HTTP 差不多，也是明文，而 v2 是二进制格式。今天只介绍比较好理解的 v1，它在 HTTP 报文前增加了一行 ASCII 码文本，相当于又多了一个头。

这一行文本其实非常简单，**开头必须是“PROXY”五个大写字母，然后是“TCP4”或者“TCP6”，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行（\r\n）结束**。

例如下面的这个例子，在 GET 请求行前多出了 PROXY 信息行，客户端的真实 IP 地址是“1.1.1.1”，端口号是 55555。

```
PROXY TCP4 1.1.1.1 2.2.2.2 55555 80\r\n
GET / HTTP/1.1\r\n
Host: www.xxx.com\r\n
\r\n
```

服务器看到这样的报文，只要解析第一行就可以拿到客户端地址，不需要再去理会后面的 HTTP 数据，省了很多事情。

不过代理协议并不支持“X-Forwarded-For”的链式地址形式，所以拿到客户端地址后再如何处理就需要代理服务器与后端自行约定。

## 小结

- HTTP 代理就是客户端和服务器通信链路中的一个中间环节，为两端提供“代理服务”；
- 代理处于中间层，为 HTTP 处理增加了更多的灵活性，可以实现负载均衡、安全防护、数据过滤等功能；
- 代理服务器需要使用字段“Via”标记自己的身份，多个代理会形成一个列表；
- 如果想要知道客户端的真实 IP 地址，可以使用字段“X-Forwarded-For”和“X-Real-IP”；
- 专门的“代理协议”可以在不改动原始报文的情况下传递客户端的真实 IP。

## Q&A

- 知名的代理软件有HAProxy、Squid、Varnish等，而 Nginx虽然是Web 服务器，但也可以作为代理服务器，而且功能毫不逊色。
- "Via”是HTTP协议里规定的标准头字段，但有的服务器返回的响应报文里会使用“X-Via”,含义是相同的。
- 因为HTTP是明文传输,请求头很容易被窜改，所以“X-Forwarded-For”也不是完全可信的。
- RFC7239定义了字段“Forwarded”，它可以代替“X-Forwarded-For”“×-Forwarded-Host”等字段，但应用得不多。
- 代理有什么缺点？实际应用时如何避免？
  - 
- 反向代理中使用的负载均衡算法？它们有什么优缺点？
  - 1.随机 2.轮询 3.一致性hash 4.最近最少使用 5.链接最少
  - 1.根据服务端的情况做负载均衡 round-robin, weighted-round-robin, LRU, least connecetion。2.根据客户端的一些feature做负载均衡 ip, cookie, other features。
- 微服务里的网关算不算一个增强版的代理服务器？
  - 是的，可以算是一种微型的反向代理。
- 代理协议的那一行是代理服务器加的，客户端不需要参与。 代理协议的优势是简单，比http头好解析好处理，这对于代理服务器来说就能够提高转发效率。

# HTTP的缓存代理

但 HTTP 传输链路上，不只是客户端有缓存，服务器上的缓存也是非常有价值的，可以让请求不必走完整个后续处理流程，“就近”获得响应结果。

特别是对于那些“读多写少”的数据，例如突发热点新闻、爆款商品的详情页，一秒钟内可能有成千上万次的请求。即使仅仅缓存数秒钟，也能够把巨大的访问流量挡在外面，让 RPS（request per second）降低好几个数量级，减轻应用服务器的并发压力，对性能的改善是非常显著的。

**HTTP 的服务器缓存功能主要由代理服务器来实现（即缓存代理）**，源服务器系统内部虽然也经常有各种缓存（如 Memcache、Redis、Varnish 等），但与 HTTP 没有太多关系，所以这里暂且不说。

## 缓存代理服务

在没有缓存的时候，代理服务器每次都是直接转发客户端和服务器的报文，中间不会存储任何数据，只有最简单的中转功能。

加入了缓存后，代理服务收到源服务器发来的响应数据后需要做两件事。第一个当然是把报文转发给客户端，而第二个就是把报文存入自己的 Cache 里。

下一次再有相同的请求，**代理服务器就可以直接发送 304 或者缓存数据，不必再从源服务器那里获取**。这样就降低了客户端的等待时间，同时节约了源服务器的网络带宽。

## 源服务器的缓存控制

4 种服务器端的“Cache-Control”属性：max-age、no-store、no-cache 和 must-revalidate 可以约束客户端，也可以约束代理。

但客户端和代理是不一样的，客户端的缓存只是用户自己使用，而代理的缓存可能会为非常多的客户端提供服务。所以，需要对它的缓存再多一些限制条件。

首先，我们要区分客户端上的缓存和代理上的缓存，可以使用两个新属性“**private**”和“**public**”。

“private”表示缓存只能在客户端保存，是用户“私有”的，不能放在代理上与别人共享。而“public”的意思就是缓存完全开放，谁都可以存，谁都可以用。

其次，缓存失效后的重新验证也要区分开（即使用条件请求“Last-modified”和“ETag”），“**must-revalidate**”是只要过期就必须回源服务器验证，而新的“**proxy-revalidate**”只要求代理的缓存过期后必须验证，客户端不必回源，只验证到代理这个环节就行了。

再次，缓存的生存时间可以使用新的“**s-maxage**”（s 是 share 的意思，注意 maxage 中间没有“-”），只限定在代理上能够存多久，而客户端仍然使用“**max-age**”。

还有一个代理专用的属性“**no-transform**”。代理有时候会对缓存下来的数据做一些优化，比如把图片生成 png、webp 等几种格式，方便今后的请求处理，而“no-transform”就会禁止这样做，不许“偷偷摸摸搞小动作”。

源服务器在设置完“Cache-Control”后必须要为报文加上“Last-modified”或“ETag”字段。否则，客户端和代理后面就无法使用条件请求来验证缓存是否有效，也就不会有 304 缓存重定向。

## 客户端的缓存控制

max-age、no-store、no-cache 也是同样作用于代理和源服务器。

关于缓存的生存时间，多了两个新属性“**max-stale**”和“**min-fresh**”。

“max-stale”的意思是如果代理上的缓存过期了也可以接受，但不能过期太多，超过 x 秒也会不要。“min-fresh”的意思是缓存必须有效，而且必须在 x 秒后依然有效。

有的时候客户端还会发出一个特别的“**only-if-cached**”属性，表示只接受代理缓存的数据，不接受源服务器的响应。如果代理上没有缓存或者缓存过期，就应该给客户端返回一个 504（Gateway Timeout）。

## 其他问题

缓存代理的知识就快讲完了，下面再简单说两个相关的问题。

第一个是“**Vary**”字段，在第 15 讲曾经说过，它是内容协商的结果，相当于报文的一个版本标记。

同一个请求，经过内容协商后可能会有不同的字符集、编码、浏览器等版本。比如，“Vary: Accept-Encoding”“Vary: User-Agent”，缓存代理必须要存储这些不同的版本。

当再收到相同的请求时，代理就读取缓存里的“Vary”，对比请求头里相应的“ Accept-Encoding”“User-Agent”等字段，如果和上一个请求的完全匹配，比如都是“gzip”“Chrome”，就表示版本一致，可以返回缓存的数据。

另一个问题是“**Purge**”，也就是“缓存清理”，它对于代理也是非常重要的功能，例如：

过期的数据应该及时淘汰，避免占用空间；

源站的资源有更新，需要删除旧版本，主动换成最新版（即刷新）；

有时候会缓存了一些本不该存储的信息，例如网络谣言或者危险链接，必须尽快把它们删除。

清理缓存的方法有很多，比较常用的一种做法是使用自定义请求方法“PURGE”，发给代理服务器，要求删除 URI 对应的缓存数据。

## 小结

- “Cache-Control”字段也可以控制缓存代理，常用的有“private”“s-maxage”“no-transform”等，同样必须配合“Last-modified”“ETag”等字段才能使用；
- 缓存代理有时候也会带来负面影响，缓存不良数据，需要及时刷新或删除。

## 课下作业

加入了代理后 HTTP 的缓存复杂了很多，试着用自己的语言把这些知识再整理一下，画出有缓存代理时浏览器的工作流程图，加深理解。

缓存的时间策略很重要，太大太小都不好，你觉得应该如何设置呢？
