# 第1章 数据库集簇、数据库和数据表

第1章和第2章会简单介绍一些PostgreSQL的基础知识。本章包括以下几个主题：

● **数据库集簇的逻辑结构**

● **数据库集簇的物理结构**

● **堆表文件的内部布局**

● **从表中读写数据的方式**

> 译者注：本书中的database cluster与PostgreSQL中文文档统一，译为数据库集簇。与高可用数据库集群不同，这里的集簇表示多个逻辑的数据库在同一个数据库实例中。

## 1.1 数据库集簇的逻辑结构

数据库集簇（database cluster）是一组数据库（database）的集合，由一个PostgreSQL服务器管理。读者第一次听到这个定义也许会产生疑惑，其实PostgreSQL中的术语“数据库集簇”，并非意味着“一组数据库服务器”。一个 PostgreSQL服务器只会在单机上运行并管理单个数据库集簇。

图 1.1 展 示 了 一 个 数 据 库 集 簇 的 逻 辑 结 构 。 数 据 库 是 数 据 库 对 象（database object）的集合。在关系型数据库理论中，数据库对象用于存储或引用数据的数据结构。（堆）表就是一个典型的例子，还有更多对象，例如索引、序列、视图、函数等。在PostgreSQL中，数据库本身也是数据库对象，并在逻辑上彼此分离。所有其他的数据库对象（例如表、索引等）都归属于各自相应的数据库。



图1.1 数据库集簇的逻辑结构

在 PostgreSQL 内 部 ， 所 有 的 数 据 库 对 象 都 通 过 相 应 的 对 象 标 识 符（object identifier,oid）进行管理，这些标识符是无符号的4字节整型。数据库对象与相应oid 之间的关系存储在对应的系统目录中，依具体的对象类型而异。例如数据库和堆表对象的 oid 分别存储在pg_database和pg_class中，因此，当你希望找出oid时，可以执行以下查询：



1.2 数据库集簇的物理结构

数据库集簇在本质上就是一个文件目录，即基础目录，包含着一系列子目录与文件。执行initdb 命令会在指定目录下创建基础目录，从而初始化一个新的数据库集簇。通常基础目录的路径会被配置到环境变量PGDATA中，但这并不是必要的。图1.2展示了一个PostgreSQL数据库集簇的例子。base子目录中的每一个子目录都对应一个数据库，数据库中的每个表和索引都至少在相应子目录下存储为一个文件；还有几个包含特定数据的子目录，以及配置文件。虽然PostgreSQL支持表空间，但是该术语的含义与其他关系型 数 据 库 管 理 系 统 （ Relational Database Management System,RDBMS）不同。PostgreSQL中的表空间对应一个包含基础目录之外数据的目录。





图1.2 数据库集簇示例

后续小节将描述数据库集簇的布局、数据库布局、表和索引相关文件

的布局，以及PostgreSQL中表空间的布局。

1.2.1 数据库集簇的布局

官方文档描述了数据库集簇的布局。表1.1中列出了主要的文件与子目

录：

表1.1 基本目录下的数据库文件和子目录的布局（参见官方文档）



续表





注：若无特殊说明，本书提及的版本号都是PostgreSQL版本号。

1.2.2 数据库布局

一个数据库与 base 子目录下的一个子目录对应，且该子目录的名称

与相应数据库的 oid相同。例如，当数据库sampledb的oid为16384

时，它对应的子目录名称就是16384。

1.2.3 表和索引相关文件的布局

每个小于1GB的表或索引都在相应的数据库目录中存储为单个文件。在

数据库内部，表和索引作为数据库对象是通过oid来管理的，而这些数

据文件由变量relfilenode管理。表和索引的relfilenode值通常与其

oid一致，但也有例外，下面将详细展开。

让我们看一看表sampletbl的oid和relfilenode：

从上面的结果中可以看出，oid和relfilenode的值相等，表sampletbl 的数据文件路径是base/16384/18740。





表和索引的relfilenode值会被一些命令（例如TRUNCATE、REINDEX、

CLUSTER ） 所 改 变 。 例 如 对 表 sampletbl 执 行 TRUNCATE 命 令 ，

PostgreSQL会为表分配一个新的relfilenode（18812），删除旧的数

据文件（18740），并创建一个新的数据文件（18812）。

在9.0或更高版本中，内建函数pg_relation_filepath 能够根据oid 或名称返回关系对应的文件路径，非常实用。

当表和索引的文件大小超过1GB时，PostgreSQL会创建并使用一个名为

relfilenode.1的新文件。如果新文件也填满了，则会创建下一个名为





relfilenode.2的新文件，以此类推。

译者注：数据库系统中的表与关系代数中的关系之间的联系紧密但又

不尽相同。在PostgreSQL中，表、索引、TOAST表都归类为关系。

在构建PostgreSQL时，可以使用配置选项--with-segsize更改表和索

引的最大文件大小。

仔细观察数据库子目录就会发现，每个表都有两个与之关联的文件，

后缀分别为_fsm和_vm。这些实际上是空闲空间映射和可见性映射文

件，分别存储了表文件每个页面上的空闲空间信息与可见性信息（更

多细节见第5.3.4节和第6.2节）。索引没有可见性映射文件，只有空

闲空间映射文件。

一个具体的示例如下所示：

在数据库系统内部，这些文件（主体数据文件、空闲空间映射文件、

可见性映射文件等）也被称为相应关系的分支（fork）；空闲空间映

射是表/索引数据文件的第一个分支（分支编号为1），可见性映射表





是数据文件的第二个分支（分支编号为2），数据文件的分支编号为

0。

译者注：每个关系（relation）可能会有4种分支，分支编号分别为

0、1、2、3,0号分支main为关系数据文件本体，1号分支fsm保存了

main分支中空闲空间的信息，2号分支vm保存了main分支中可见性的信

息 ， 3 号 分 支 init 是 很 少 见 的 特 殊 分 支 ， 通 常 表 示 不 被 日 志 记 录

（unlogged）的表与索引。

每个分支都会被存储为磁盘上的一或多个文件：PostgreSQL会将过大

的分支文件切分为若干个段，以免文件的尺寸超过某些特定文件系统

允许的大小，也便于一些归档工具进行并发复制，默认的段大小为

1GB。

1.2.4 PostgreSQL中表空间的布局

PostgreSQL中的表空间是基础目录之外的附加数据区域。8.0版本中引

入了该功能。

图1.3展示了表空间的内部布局，以及表空间与主数据区域的关系。





图1.3 数据库集簇的表空间及其与主数据区域的关系

执行 CREATE TABLESPACE语句会在指定的目录下创建表空间。在该目

录下还会创建版本特定的子目录（例如PG_9.4_201409291）。版本特

定的命名方式为：

举 个 例 子 ， 如 果 在 /home/postgres/tblspc 中 创 建 一 个 表 空 间

new_tblspc ， 其 oid 为 16386 ， 则 会 在 表 空 间 下 创 建 一 个 名 如

PG_9.4_201409291的子目录。

表空间目录通过pg_tblspc子目录中的符号链接寻址，链接名称与表空

间的oid值相同。

如果在该表空间下创建新的数据库（oid为16387），则会在版本特定

的子目录下创建相应的目录。

如果在该表空间内创建一个新表，但新表所属的数据库却创建在基础

目录下，那么 PG 会首先在版本特定的子目录下创建名称与现有数据





库oid相同的新目录，然后将新表文件放置在刚创建的目录下。

1.3 堆表文件的内部布局

数据文件（堆表、索引，也包括空闲空间映射和可见性映射）内部被

划分为固定长度的页，或者叫区块，大小默认为8192B（8KB）。每个

文件中的页从0开始按顺序编号，这些数字称为区块号。如果文件已填

满，PostgreSQL就通过在文件末尾追加一个新的空页来增加文件长

度。

页面内部的布局取决于数据文件的类型。本节会描述表的页面布局，

因为理解接下来的几章内容需要用到这些知识。图1.4就是堆表文件的

页面布局。



图1.4 堆表文件的页面布局

表的页面包含了三种类型的数据：

1.堆元组——即数据记录本身。它们从页面底部开始依序堆叠。第5.2

节与第9章会描述元组的内部结构，这一知识对于理解PostgreSQL并发

控制与WAL机制是必备的。

2.行指针——每个行指针占4B，保存着指向堆元组的指针。它们也被

称为项目指针。行指针形成一个简单的数组，扮演了元组索引的角

色。每个索引项从1开始依次编号，称为偏移号。当向页面中添加新元

组时，一个相应的新行指针也会被放入数组中，并指向新添加的元

组。

3.首部数据——页面的起始位置分配了由结构PageHeaderData 定义的

首部数据。它的大小为24B，包含关于页面的元数据。该结构的主要成

员变量如下。

● pd_lsn——本页面最近一次变更所写入的XLOG记录对应的LSN。它

是一个8B无符号整数，与WAL机制相关，第9章将详细展开介绍。

● pd_checksum——本页面的校验和值。（注意，只有在9.3或更高版

本中才有此变量，早期版本中该字段用于存储页面的时间线标识。）

● pd_lower、pd_upper——pd_lower 指向行指针的末尾，pd_upper 指向最新堆元组的起始位置。

● pd_special——在索引页中会用到该字段，在堆表页中它指向页

尾。（在索引页中它指向特殊空间的起始位置，特殊空间是仅由索引

使用的特殊数据区域，包含特定的数据，具体内容依索引的类型而

定，如B树、GiST、GiN等。）





行指针的末尾与最新元组起始位置之间的空余空间称为空闲空间或空

洞。

为 了 识 别 表 中 的 元 组 ， 数 据 库 内 部 会 使 用 元 组 标 识 符 （ tuple identifier,TID）。TID由一对值组成，分别是元组所属页面的区块号

和指向元组的行指针的偏移号。TID 的一种典型用途是索引，更多细

节参见第1.4.2节。

结构体PageHeaderData定义于src/include/storage/bufpage.h中。

此外，大小超过约2KB（8KB的四分之一）的堆元组会使用一种称为

TOAST（The OversizedAttribute Storage Technique，超大属性存储

技术）的方法来存储与管理。详情请参阅官方文档。

1.4 读写元组的方式

最后本章将描述写入与读取堆元组的方式。

1.4.1 写入堆元组

假设有一个表仅由一个页面组成，且该页面只包含一个堆元组。此页

面的pd_lower指向第一个行指针，而该行指针和pd_upper都指向第一

个堆元组，如图1.5（1）所示。

当写入第二个元组时，它会被放在第一个元组之后。第二个行指针写

入到第一个行指针的后面，并指向第二个元组。pd_lower 更改为指向

第二个行指针，pd_upper 更改为指向第二个堆元组，如图1.5（2）所

示。页面内的首部数据（例如pd_lsn、pg_checksum和pg_flag）也会

被改写为适当的值，具体细节将在第5.3节和第9章中描述。





图1.5 堆元组的写入

1.4.2 读取堆元组

这里简述两种典型的访问方式：顺序扫描与B树索引扫描。

● 顺序扫描——通过扫描每一页中的行指针，依序读取所有页面中的

所有元组，如图1.6（1）所示。

● B树索引扫描——索引文件包含索引元组，索引元组由一个键值对

组成，键为被索引的列值，值为目标堆元组的 TID。进行索引查询

时，首先使用键进行查找，如果找到了对应的索引元组，PostgreSQL

就会根据相应值中的TID来读取对应的堆元组。使用B树索引找到索引

元组的方法请参考相关资料，这一部分属于数据库系统的通用知识，

限于篇幅不再详细展开。例如在图1.6（2）中，对于所获索引元组中

TID的值，区块号 = 7，偏移号 = 2，这意味着目标堆元组是表中第7

页的第2个元组，因而PostgreSQL可以直接读取所需的堆元组，以避免

对页面进行不必要的扫描。





图1.6 顺序扫描和B树索引扫描

PostgreSQL还支持TID扫描、位图扫描和仅索引扫描。

TID扫描是一种通过使用所需元组的TID直接访问元组的方法。例如要

在表中找到第0个页面中的第1个元组，可以执行以下查询：





仅索引扫描将在第7章中详细介绍。

# 第2章 进程和内存架构

本章会总结PostgreSQL中进程与内存的架构。

## 2.1 进程架构

PostgreSQL是一个**客户端/服务器**风格的关系型数据库管理系统，**采用多进程架构，运行在单台主机上**。我们通常所说的**“PostgreSQL 服务器（PostgreSQL Server）”，实际上是一系列协同工作的进程集合**，其中包含下列进程：

● **Postgres服务器进程（postgres server process）**是所有数据库集簇管理进程的**父进程**。

● **每个后端进程（backend process）**负责处理客户端发出的查询和语句。

● **各种后台进程（background process）**负责执行各种**数据库管理任务（例如清理过程与存档过程）**。

● **各种复制相关进程（replication associated process）**负责**流复制**。

● **后台工作进程（background worker process）**在9.3版本中被引入，它能**执行任意由用户实现的处理逻辑**。

以下几小节将详细描述前三种进程。

图2.1展示了PostgreSQL服务器包含的postgres服务器进程、2个后端进程、7个后台进程及2个客户端进程。也画出了数据库集簇、**共享内**

**存**及2个客户端。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5bv7ckezij30sw0cpgo0.jpg)

**图2.1 PostgreSQL的进程架构示例**

### 2.1.1 Postgres服务器进程

如上所述，postgres服务器进程是 PostgreSQL服务器中所有进程的父进程，在早期版本中被称为“postmaster”。带start参数执行pg_ctl实用程序会启动一个postgres服务器进程。**它会在内存中分配共享内存区域，启动各种后台进程**，如有必要还会启动复制相关进程与后台工作进程，并等待来自客户端的连接请求。**每当接收到来自客户端的连接请求时，它都会启动一个后端进程**，然后由启动的后端进程处理该客户端发出的所有查询。

一个postgres服务器进程只会监听一个网络端口，默认端口为5432。如果要在同一台主机上运行多个PostgreSQL服务器，则应为每个服务器配置不同的监听端口，如5432、5433等。

### 2.1.2 后端进程

每个后端进程（backend process，也称为“postgres”）由 postgres 服务器进程启动，并处理连接另一侧的客户端发出的所有查询。**它通过单条TCP连接与客户端通信**，并在客户端断开连接时终止。因为一条连接只允许操作一个数据库，所以必须在连接到PostgreSQL服务器时显式地指定要连接的数据库。PostgreSQL允许多个客户端同时连接，配置参数max_connections用于控制最大客户端连接数（默认为100）。

**因为 PostgreSQL 没有原生的连接池功能，所以如果许多客户端频繁地重复与 PostgreSQL服务器建立断开连接（譬如 Web 应用），则会导致建立连接与创建后端进程的开销变大。这种情况对数据库服务器的性能有负面影响，通常可以使用池化中间件（pgbouncer或pgpool-II）来避免该问题。**

### 2.1.3 后台进程

表2.1是后台进程（background process）的列表。比起postgres服务器和后端进程，后台进程的种类要多很多。这些功能具有依赖PostgreSQL的内部机制与特定的独立特性，依赖于各个特定的特性以及PostgreSQL的内部机制。在本章中仅做简要介绍，更多细节将在后续章节中描述。

**表2.1 后台进程**

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5bvu8t0gmj30wj0ean2a.jpg)

这里展示了PostgreSQL服务器包含的实际进程。在以下示例中有1个postgres 服 务 器 进 程 （ pid 为 9687 ） 、 2 个 后 端 进 程 （ pid 为 9697 和 9717）及表2.1中列出的几个后台进程正在运行，详见图2.1。

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5bvzg3othj30m00bp43o.jpg)

## 2.2 内存架构

PostgreSQL的内存架构可以分为两个部分：

● **本地内存区域**——由每个后端进程分配，供自己使用。

● **共享内存区域**——供PostgreSQL服务器的所有进程使用。

下面将简要介绍这两部分架构。图2.2是 PostgreSQL的内存架构。

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5bvzyad1tj30dj0ahmxy.jpg)

**图2.2 PostgreSQL的内存架构**

### 2.2.1 本地内存区域

**每个后端进程都会分配一块本地内存区域用于查询处理。该区域会分为几个子区域**——子区域的大小有的固定，有的可变。表2.2列出了主要的子区域。

**表2.2 本地内存区域**

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5bw249ncqj30xf06x0uv.jpg)

### 2.2.2 共享内存区域

**PostgreSQL服务器启动时会分配共享内存区域**，该区域分为几个**固定大小**的子区域。表2.3列出了主要的子区域。

**表2.3 共享内存区域**

![](https://tva1.sinaimg.cn/large/006DIypxly1h5bw4w6f3zj30xg09g77n.jpg)

除了上面这些，PostgreSQL还分配了以下几个区域：

● 用于访问**控制机制**的子区域（例如信号量、轻量级锁、共享和排他锁等）。

● 各种后台进程使用的子区域，例如checkpointer和autovacuum。

● 用于**事务处理**的子区域，例如保存点与两阶段提交（2PC）。

# 第3章 查询处理

查询处理是 PostgreSQL中最为复杂的子系统。如 PostgreSQL官方文档所述，PostgreSQL支持SQL2011标准中的大多数特性，查询处理子系统能够高效地处理这些SQL。**本章概述了查询处理的流程，特别关注了查询优化的部分**。

本章包括下列三个部分：

● 第一部分：第3.1节，这一部分会简单介绍PostgreSQL中**查询处理的流程**。

● 第二部分：第3.2~3.4节，这一部分会描述**获取单表查询上最优执行计划的步骤**。第3.2节讨论**代价估计**的过程，第3.3节描述**创建计划树**的过程，第3.4节将简要介绍**执行器**的工作过程。

● 第三部分：第3.5~3.6节，这一部分会描述**获取多表查询上最优执行计划的步骤**。第3.5节介绍了三种连接算法，分别是**嵌套循环连接**、**归并连接**和**散列连接**。第3.6节将介绍为**多表查询创建计划树**的过程。

PostgreSQL 支持三种技术上很有趣也很实用的功能，分别是**外部数据包装（Foreign Data Wrapper,FDW）**、**并行查询**及版本11.0即将支持的 **JIT编译**。前两者将在第4章中描述，JIT编译超出本书的范围，更多内容见官方文档。

## 3.1 概览

尽管PostgreSQL在9.6版本后有了基于多个后台工作进程的并行查询，但大体上来讲，还是每个连接对应一个后端进程。后端进程由以下5个子系统组成：

1. **解析器**，根据SQL语句生成一棵语法解析树（parse tree）。
2. **分析器**，对语法解析树进行语义分析，生成一棵查询树（query tree）。
3. **重写器**，按照规则系统中存在的规则对查询树进行改写。

4. **计划器** ，基于查询树生成一棵执行效率最高的计划树（plan tree）。

5. **执行器**，按照计划树中的顺序访问表和索引，执行相应查询。

图3.1是查询处理的大概流程：

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5bwjs3eddj30b90e2gme.jpg)

**图3.1 查询处理**

本节将概述这些子系统。计划器和执行器很复杂，后面的章节会对这些函数的细节进行描述。

### 3.1.1 解析器

解析器基于SQL语句的文本，生成一棵后续子系统可以理解的语法解析树。下面是一个具体的例子。

考虑以下查询：

```sql
> SELECT id, data FROM tbl_a WHERE id < 300 ORDER BY data;
```

语法解析树的根节点是一个定义在parsenodes.h中的**SelectStmt数据结构**。

```c
typedef struct SelectStmt {
    NodeTag          type;            /＊ 这些字段只会在SelectStmts“叶节点”中使用 ＊/
	List        *distinctClause;      /＊ NULL, DISTINCT ON表达式列表 ＊/            
	IntoClause ＊intoClause;          /＊ SELECT INTO 的目标 ＊/            
	List        ＊targetList;          /＊ 结果目标列表 (ResTarget) ＊/            
	List        ＊fromClause;          /＊ FROM 子句 ＊/            
	Node        ＊whereClause;         /＊ WHERE 限定条件 ＊/            	List        ＊groupClause;         /＊ GROUP BY 子句 ＊/            Node        ＊havingClause;        /＊ HAVING 条件表达式 ＊/            List        ＊windowClause;        /＊ WINDOW window_name AS (...), ... ＊/            /＊ 在一个表示值列表的叶节点中，上面的字段全都为空，而这个字段会被设置            ＊ 注意，这个子列表中的元素都没有ResTarget的修饰的表达式类型。            ＊还需要注意，无论值列表的上下文是什么，列表元素都可能为DEFAULT (表示一个 SetToDefault 节点)            ＊ 由分析阶段决定是否合法并拒绝      ＊/            List        ＊valuesLists;         /＊ 未转换的表达式列表 ＊/            /＊ 这些字段会同时在SelectStmts叶节点与SelectStmts上层节点中使用 ＊/            List        ＊sortClause;          /＊ 排序子句 (排序依据的列表) ＊/            Node        ＊limitOffset;         /＊ 需要跳过的元组数目 ＊/            Node        ＊limitCount;          /＊ 需要返回的元组数目 ＊/            List        ＊lockingClause;       /＊ FOR UPDATE (锁子句的列表) ＊/            WithClause ＊withClause;          /＊ WITH 子句 ＊/            /＊ 这些字段只会在上层的 SelectStmts 中出现 ＊/            SetOperation op;                  /＊ set 操作的类型 ＊/            bool              all;              /＊ 是否指明了 ALL 选项 ＊/            struct SelectStmt ＊larg;         /＊ 左子节点 ＊/            struct SelectStmt ＊rarg;         /＊ 右子节点 ＊/    } SelectStmt;
```



![](https://tva1.sinaimg.cn/large/006DIypxly1h5bwoc9opzj30lw0lsaf4.jpg)

图3.2（1）展示了一个查询，图3.2（2）则是该查询对应的语法解析树。

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5bwn66g82j30ty0c9acn.jpg)

**图3.2 语法解析树的例子**

SELECT 查询中的元素 和 语法解析树中的元素 有着对应关系。比如，（1）是目标列表中的一个元素，与目标表的’id’列相对应，（4）是一个WHERE子句，诸如此类。

**解析器生成语法分析树时只会检查语法**，只有当查询中出现语法错误时才会返回错误。**解析器并不会检查输入查询的语义，举个例子，如果查询中包含一个不存在的表名，解析器并不会报错，那么语义检查由分析器负责**。

### 3.1.2 分析器

分析器对解析器产出的语法解析树进行语义分析，并产出一棵查询树。

查询树的根节点是parsenode.h中定义的Query数据结构，这个结构包含着对应查询的元数据，比如命令的类型（SELECT/INSERT等），还包括一些叶子节点，叶子节点由列表或树组成，包含了与特定子句相对应的数据。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5bx1tyknej30nj285nn1.jpg)

图3.3是查询树的例子。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5bwy6f2iuj30ti0d5775.jpg)

**图3.3 查询树**

接下来对图3.3的查询树进行简要介绍：

● targetlist 是查询结果中列的列表。在本例中该列表包含id和data 两列。如果在输入的查询树中使用了*（星号），分析器就会将其显式替换为所有具体的列。

● 范围表rtable是该查询所用到关系的列表。本例中该变量包含了表tbl_a的信息，如该表的表名与oid。

● 连接树jointree存储着与FROM和WHERE子句相关的信息。

● 排序子句sortClause是SortGroupClause结构体的列表。

### 3.1.3 重写器

PostgreSQL的规则系统正是基于重写器实现的。当需要时，重写器会根据存储在pg_rules中的规则对查询树进行转换。规则系统本身也是一个很有趣的系统，不过本章略去了关于规则系统和重写器的描述，以免内容过于冗长。

**视图**

在PostgreSQL中，视图是基于规则系统实现的。当使用CREATE VIEW命令定义一个视图时，PostgreSQL就会创建相应的规则，并存储到系统目录中。

假设下面的视图已经被定义，而pg_rule中也存储了相应的规则。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5c5kuvkb8j30vp03p755.jpg)

当执行一个包含该视图的查询时，解析器会创建一棵语法解析树。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5c5lr6hofj30dw01it8p.jpg)

在该阶段，重写器会基于pg_rule中存储的视图规则将rangetable节点重写为一棵查询子树，与子查询相对应。

![](https://tva1.sinaimg.cn/large/006DIypxly1h5c5jxkl3oj30vm0bpad1.jpg)

**图3.4 重写阶段**

因为PostgreSQL使用这种机制实现视图，所以直到9.2版本，视图都是不能更新的。虽然9.3及更高版本可以对视图进行更新，但对视图的更新仍然存在很多限制，具体细节请参考官方文档。

### 3.1.4 计划器与执行器

计划器从重写器获取一棵查询树，基于查询树生成一棵能被执行器高效执行的（查询）计划树。在PostgreSQL中，计划器是完全基于代价估计的，它不支持基于规则的优化与提示。计划器是RDBMS中最复杂的部分。

**pg_hint_plan**

PostgreSQL不支持 SQL中的提示（hint），并且永远也不会去支持。如果你想在查询中使用提示，可以考虑使用pg_hint_plan扩展，具体细节请参考官方文档。

与其他RDBMS类似，PostgreSQL中的EXPLAIN命令会显示命令的计划树。下面给出了一个具体的例子。

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5c7lbaq6dj30wu08ktar.jpg)

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5c7lw9s1ij30ws0a0dim.jpg)

图3.5 一棵简单的计划树及其与EXPLAIN命令的关系

计划树由被许多称为计划节点的元素组成，这些节点挂在 **PlannedStmt** 结构对应的计划树上。这些元素的定义在plannodes.h 中，第3.3.3节与第3.5.4.2节会解释相关细节。

每个计划节点都包含着执行器进行处理所需要的信息，在单表查询的场景中，执行器会按照从终端节点往根节点的顺序依次处理这些节点。

比如图3.5中的计划树就是一个列表，包含一个排序节点和一个顺序扫描节点，因而执行器会首先对表tbl_a执行顺序扫描，并对获取的结果进行排序。

执行器会通过将在第8章介绍的缓冲区管理器来访问数据库集簇的表和索引。当处理一个查询时，执行器会使用预先分配的内存空间，比如temp_buffers和work_mem，必要时还会创建临时文件。

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5c7orxpvcj30f50c10tp.jpg)

图3.6 执行器、缓冲管理器和临时文件之间的关系

除此之外，当访问元组的时候，PostgreSQL还会使用并发控制机制来维护运行中事务的一致性和隔离性。第5章将介绍并发控制机制。

## 3.2 单表查询的代价估计

PostgreSQL的查询优化是基于代价的。代价是一个无量纲的值，它不是一种绝对的性能指标，但可以作为比较各种操作代价时的相对性能指标。

costsize.c 中的函数用于估算各种操作的代价。所有被执行器执行的操作都有着相应的代价函数 。 例如 ， 函数 cost_seqscan() 和cost_index()分别用于估算顺序扫描和索引扫描的代价。

在PostgreSQL中有三种代价，分别是**启动代价、运行代价和总代价**。总代价是启动代价和运行代价的和，因此只有启动代价和运行代价是单独估计的。

1. **启动代价**：在读取到第一条元组前花费的代价，比如索引扫描节点的启动代价就是读取目标表的索引页，获取到第一个元组的代价。
2. **运行代价**：获取全部元组的代价。

3. 总代价：前两者之和。

EXPLAIN命令显示了每个操作的启动代价和总代价，下面是一个简单的例子：

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5c7rp1xh1j30ms06mq4h.jpg)

第4行显示了顺序扫描的相关信息。代价部分包含了0.00和145.00两个值。在本例中，启动代价和总代价分别为0.00和145.00。

在本节中，我们将详细介绍顺序扫描，索引扫描和排序操作的代价是如何估算的。

在接下来的内容中，我们使用下面这个表及其索引作为例子。

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5c7sen1o8j30w90d70w0.jpg)

### 3.2.1 顺序扫描

顺序扫描的代价是通过函数cost_seqscan()估计的。本节将研究顺序扫描代价是如何估计的，以下面的查询为例：

```sql
> SELECT * FROM tbl WHERE id < 8000;
```

在顺序扫描中，启动代价等于0，而运行代价由以下公式定义：

run_cost=cpu_run_cost+disk_run_cost=(cpu_tuple_cost+cpu_operator_cost)×N~tuple~+ seq_page_cost × N~page~，

其 中 seq_page_cost 、 cpu_tuple_cost 和 cpu_operator_cost 是 在postgresql.conf中配置的参数，默认值分别为1.0、0.01和0.0025。N~tuple~和N~page~分别是表中的元组总数与页面总数，这两个值可以使用以下查询获取。

![](https://tva1.sinaimg.cn/large/006DIypxgy1h5c82is4xsj30mn06h75k.jpg)

因此：run_cost=(0.01+0.0025)×10000+1.0 × 45=170.0

作为验证，下面是该查询的EXPLAIN结果：

![](https://tva1.sinaimg.cn/large/006DIypxly1h5c844zphbj30mo06n0us.jpg)

在第4行中可以看到，启动代价和总代价分别是0.00和170.0，且预计全表扫描返回行数为8000条（元组）。

第5行显示了一个顺序扫描的过滤器Filter:(id < 8000)。更精确地说，它是一个表级过滤谓词。注意，这种类型的过滤器只会在读取所有元组的时候使用，它并不会减少需要扫描的表页面数量。

从优化运行代价的角度来看，PostgreSQL假设所有的物理页都是从存储介质中获取的，即PostgreSQL不会考虑扫描的页面是否来自共享缓冲区。

### 3.2.2 索引扫描

尽管PostgreSQL支持很多索引方法，比如B树、GiST、GIN和BRIN，但是索引扫描的代价估计是使用一个共用的代价函数：cost_index()。

本节将研究索引扫描的代价是如何估计的，以下列查询为例。

在估计该查询的代价之前，下面的查询能获取N和N的index,pageindex,tuple值：

N

=10000（3）

index,tuple

N

=30（4）

index,page

3.2.2.1 启动代价

索引扫描的启动代价就是读取索引页以访问目标表的第一条元组的代

价，由下面的公式定义：

start-up_cost={ceil(log (N

))+(H

+1)×50}

2

index,tuple

index

×cpu_operator_cost

其中H

是索引树的高度。

index

在 本 例 中 ， 套 用 公 式 （ 3 ） ,N

是 10000;H

是

index,tuple

index

1;cpu_operator_cost是0.0025（默认值）。因此：

start-up_cost={ceil}(log (10000))+(1+1)×50}×0.0025 =

2

0.285（5）

3.2.2.2 运行代价

索引扫描的运行代价是表和索引的CPU代价与I/O代价之和。

run_cost=(index_cpu_cost+table_cpu_cost)+

(index_io_cost+table_io_cost)

如果使用仅索引扫描，则不会估计table_cpu_cost与table_io_cost，

仅索引扫描将在第7章中介绍。

前三个代价（即index_cpu_cost、table_cpu_cost和index_io_cost）

如下所示：

index_cpu_cost=Selectivity×N

index,tuple

×(cpu_index_tuple_cost+qual_op_cost) table_cpu_cost=Selectivity×N

×cpu_tuple_cost

tuple

index_io_cost=ceil(Selectivity×N

index,page

)×random_page_cost

以 上 公 式 中 的 cpu_index_tuple_cost 和 random_page_cost 在

postgresql.conf中配置（默认值分别为0.005和4.0）。qual_op_cost 粗略来说就是索引求值的代价，默认值是0.0025，这里不再展开。选

择率是一个0到1之间的浮点数，代表查询指定的WHERE子句在索引中搜

索范围的比例。举个例子，（Selectivity×N

）就需要读取表元

tuple

组数量，（Selectivity×N

）就需要读取索引元组数量，诸如

index,page

此类。

选择率

查询谓词的选择率是通过直方图界值与高频值估计的，这些信息都存

储在系统目录pg_statistics中，并可通过pg_stats视图查询。这里通

过一个具体的例子来简要介绍选择率的计算方法，具体细节可以参考

官方文档。

表 中 每 一 列 的 高 频 值 都 在 pg_stats 视 图 的 most_common_vals 和

most_common_freqs中成对存储。

● 高频值：该列上最常出现的取值列表

● 高频值频率：高频值相应出现频率的列表

下面是一个简单的例子。表 countries有两列：country列存储国家

名，continent列存储该国所属大洲。





考虑下面的查询，该查询带有WHERE条件continent = 'Asia'。





这时候，计划器使用 continent 列上的高频值来估计索引扫描的代

价，列上的most_common_vals与 most_common_freqs如下所示：

与 most_common_vals 中 Asia 值 对 应 的 most_common_freqs 为

0.227979，因此0.227979会在估算中被用作选择率。

如果高频值不可用，就会使用目标列上的直方图界值来估计代价。

直方图值是一系列值，这些值将列上的取值划分为数量大致相同的若

干个组。

下面是一个具体的例子。这是表tbl中data列上的直方图界值。





默认情况下，直方图界值会将列上的取值划分入100个桶。图3.7展示

了这些桶及其对应的直方图界值。桶从0开始编号，每个桶保存了（大

致）相同数量的元组。直方图界值就是相应桶的边界。比如，直方图

界值的第0个值是1，意即这是bucket_0中的最小值；第1个值是100，

意即bucket_1中的最小值是100；等等。

图3.7 桶和直方图界值



本节例子中选择率计算如下所示。假设查询带有WHERE子句data < 240，而值240落在第二个桶中。在本例中可以通过线性插值推算出相

应的选择率。因此查询中data列的选择率可以套用下面的公式计算：

因此，根据公式（1）、（2）、（4）和（6），有

index_cpu_cost = 0.024×10000×(0.005+0.0025) = 1.8（7）

table_cpu_cost = 0.024×10000×0.01 = 2.4（8）

index_io_cost = ceil(0.024×30)×4.0 = 4.0（9）

table_io_cost由下面的公式定义：

table_io_cost = max_io_cost+indexCorerelation 2

×（min_io_cost-max_io_cost）

max_io_cost_io_cost 是最差情况下的 I/O代价，即随机扫描所有数

据页的代价。这个代价由以下公式定义：

max_io_cost = N

×random_page_cost

page

在本例中，由（2）,N

=45，得

page

max_io_cost = 45×4.0=180.0（10）

min_io_cost是最优情况下的I/O代价，即顺序扫描选定的数据页。这

个代价由以下公式定义：

min_io_cost=1×random_page_cost +(ceil(Selectivity× N page

)-1)×seq_page_cost

在本例中，

min_io_cost= 1 × 4.0 +(ceil (0.024 × 45)-1)×1.0=5.0（11）

下文将详细介绍indexCorrelation，在本例中，

indexCorrelation =1.0（12）

由（10）、（11）和（12），得

table_io_cost = 180.0+1.0 2 × (5.0-180.0) =5.0（13）

综上，由（7）、（8）、（9）和（13）得

run_cost = (1.8+2.4) + (4.0+5.0) =13.2（14）

索引相关性

索引相关性是列值在物理上的顺序和逻辑上的顺序的统计相关性（引

自官方文档）。索引相关性的取值范围从 1到+1。下面的例子有助于

理解索引扫描和索引相关性的关系。

表 tbl_corr有5列，其中2列为文本类型，3列为整数类型。这3个整数

列保存着从1到12的数字。在物理上，表tbl_corr包含3个页，每页有4

条元组。每个数字列有一个名如index_col_asc的索引。





这些列的索引相关性如下：

当执行下列查询时，由于所有的目标元组都在第一页中，PostgreSQL

只会读取第一页，如图3.8（1）所示。





执 行 下 列 查 询 时 则 不 然 ， PostgreSQL 需 要 读 取 所 有 的 页 ， 如 图

3.8（2）所示。

图3.8 索引相关性

由此可知，索引相关性是一种统计上的相关性。在索引扫描代价估计

中，索引相关性体现了索引顺序和物理元组顺序扭曲程度给随机访问

性能造成的影响大小。

3.2.2.3 整体代价

由（3）和（14）可得

total_cost=0.285 + 13.2 = 13.485（15）

作为确认，上述SELECT查询的EXPLAIN结果如下所示：





在第4行可以看到启动代价和总代价分别是0.29和13.49，预估有240条

元组被扫描。

在第5行显示了一个索引条件Index Cond:(data < 240)。更准确地

说，这个条件叫作访问谓词，它表达了索引扫描的开始条件与结束条

件。

seq_page_cost和random_page_cost

seq_page_cost和random_page_cost的默认值分别为1.0和4.0。这意味

着 PostgreSQL 假 设 随 机 扫 描 的 进 度 是 顺 序 扫 描 的 1/4； 显 然 ，

PostgreSQL的默认值是基于HDD（普通硬盘）设置的。

另一方面，近年来SSD得到了广泛的应用，random_page_cost的默认值

就显得太大了。使用SSD时如果仍然采用random_page_cost的默认值，

则 计 划 器 有 可 能 会 选 择 低 效 的 计 划 。 因 此 当 使 用 SSD 时 最 好 将

random_page_cost的值设为1.0。

https://amplitude.engineering/how-a-single-postgresql-config-change-improved-slow-query-p erformance-by-50x-85593b8991b0 这

篇文章报告了使用random_page_cost默认值导致的问题。

3.2.3 排序

排序路径会在排序操作中被使用。排序操作包括 ORDER BY、归并连接

的预处理操作，以及其他函数。函数cost_sort()用于估计排序操作的

代价。



如果能在工作内存中放下所有元组，那么排序操作会选用快速排序算

法。否则就会创建临时文件，使用文件归并排序算法。

排序路径的启动代价就是对目标表的排序代价，因此代价就是O(N sort

)×log (N

)，这里N

就是待排序的元组数。排序路径的运行代

2

sort

sort

价就是读取已经排好序的元组的代价，因而代价就是O(N

)。

sort

本节将研究以下查询排序代价的估计过程。假设该查询只使用工作内

存，不使用临时文件。

在本例中，启动代价由以下公式定义：

start-up_cost=C+comparison_cost× N

×log

(N

)

sort

2

sort

这里的C就是上一次扫描的总代价，即上次索引扫描的总代价。由

（ 15 ） 可 得 C 等 于 13.485,N

=240,comparison_cost 定 义 为 2 ×

sort

cpu_operator_cost。因此：

start-up_cost=13.485+(2×0.0025)×240.0×log2(240.0)=22.973

运行代价是在内存中读取排好序的元组的代价，即：

run_cost=cpu_operator_cost×N

= 0.0025 × 240 = 0.6

sort

综上：

total_cost=22.973+0.6=23.573

作为确认，以上SELECT查询的EXPLAIN命令结果如下：





在第4行可以看到启动代价和运行代价分别为22.97和23.57。

3.3 创建单表查询的计划树

计划器非常复杂，故本节仅描述最简单的情况，即单表查询的计划树

创建过程。更复杂的查询，换而言之即多表查询，其计划树创建过程

将在第3.6节中阐述。

PostgreSQL中的计划器会执行三个处理步骤：

1.执行预处理。

2.在所有可能的访问路径中，找出代价最小的访问路径。

3.按照代价最小的路径，创建计划树。

访问路径是估算代价时的处理单元。比如顺序扫描、索引扫描、排

序，以及各种连接操作都有其对应的路径。访问路径只在计划器创建

查询计划树的时候使用。最基本的访问路径数据结构就是relation.h 中定义的Path结构体，相当于顺序扫描。所有其他的访问路径都基于

该结构，下面会介绍细节。

计划器为了处理上述步骤，会在内部创建一个 PlannerInfo 数据结

构。该数据结构中包含查询树，可查询所涉及的关系信息、访问路径

等。





接下来会通过一个具体的例子，来描述如何基于查询树创建计划树。

3.3.1 预处理

在创建计划树之前，计划器将先对PlannerInfo中的查询树进行一些预

处理。

预处理有很多步骤，本节只讨论和单表查询处理相关的主要步骤。其

他预处理操作将在3.6节中描述。

1.简化目标列表，LIMIT子句等

例 如 ， 表 达 式 2+2 会 被 重 写 为 4 ， 这 是 由 clauses.c 中

eval_const_expressions()函数负责的。

2.布尔表达式的规范化

例如，NOT(NOT a)会被重写为a

3.压平与/或表达式

SQL标准中的 AND/OR是二元操作符，但它们在 PostgreSQL内部是多元

操作符。而计划器总是会假设所有的嵌套AND/OR都应当被压平。

这里有一个具体的例子。考虑这样一个布尔表达式(id = 1) OR (id =

2) OR (id = 3)，图3.9（1）展示了使用二元表达式时的查询树，预

处理会将这些二元算子简化压平为一个三元算子，如图3.9（2）所

示。





图3.9 压平布尔表达式的例子

3.3.2 找出代价最小的访问路径

计划器对所有可能的访问路径进行代价估计，然后选择代价最小的那

个。具体来说，计划器会执行以下几个步骤：

1.创建一个RelOptInfo数据结构，存储访问路径及其代价。

RelOptInfo 结 构 体 是 通 过 make_one_rel() 函 数 创 建 的 ， 并 存 储 于

PlannerInfo 结构体的 simple_rel_array 字段中，如图3.10所示。

在初始状态时 RelOptInfo 持有着baserestrictinfo 变量，如果存在

相应索引，还会持有 indexlist 变量。baserestrictinfo存储着查询

的WHERE子句，而indexlist存储着目标表上相关的索引。





2.估计所有可能访问路径的代价，并将访问路径添加至 RelOptInfo 结构中。这一处理过程的细节如下：

（1）创建一条路径，估计该路径中顺序扫描的代价，并将其写入路径

中。将该路径添加到RelOptInfo结构的pathlist变量中。



（2）如果目标表上存在相关的索引，则为每个索引创建相应的索引访

问路径。估计所有索引扫描的代价，并将代价写入相应路径中。然后

将索引访问路径添加到pathlist变量中。

（3）如果可以进行位图扫描，则创建一条位图扫描访问路径。估计所

有位图扫描的代价，并将代价写入路径中，然后将位图扫描路径添加

到pathlist变量中。

3.从RelOptInfo的pathlist中，找出代价最小的访问路径。

4.如有必要，估计LIMIT、ORDER BY和AGGREGATE操作的代价。

为了更加清晰地理解计划器的执行过程，下面给出了两个具体的例

子。

3.3.2.1 例1

首先来研究一个不带索引的简单单表查询，该查询同时包含WHERE和

ORDER BY子句。

图3.10和图3.11展示了本例中计划器的处理过程。





图3.10 如何得到例1中代价最小的路径

图3.11 如何得到例1中代价最小的路径（接图3.10）

（ 1 ） 创 建 一 个 RelOptInfo 结 构 ， 将 其 保 存 在 PlannerInfo 结 构 的

simple_rel_array字段中。

（2）在RelOptInfo结构的baserestrictinfo字段中，添加一条WHERE

子句。

WHERE 子 句 id<300 会 经 由 initsplan.c 中 定 义 的

distribute_restrictinfo_to_rels() 函 数 ， 添 加 至 列 表 变 量

baserestrictinfo 中。另外由于目标表上没有相关索引，RelOptInfo 的indexlist字段为空。

（3）为了满足排序要求，planner.c 中的 standard_qp_callback() 函数会在PlannerInfo的sor_pathkeys字段中添加一个pathkey。

Pathkey是表示路径排序顺序的数据结构。本例因为查询包含一条

ORDER BY子句，且该子句中的列为data，故data会被包装为pathkey，

放入列表变量sort_pathkeys中。

（4）创建一个Path结构，并使用cost_seqscan函数估计顺序扫描的代

价，并将代价写入Path中。然后使用pathnode.c中定义的add_path() 函数，将该路径添加至RelOptInfo中。

如 前 所 述 ， Path 中 同 时 包 含 启 动 代 价 和 总 代 价 ， 两 者 都 是 由

cost_seqscan 函数所估计的。

在本例中，因为目标表上没有索引，计划器只估计了顺序扫描的代

价，因此最小代价是自动确定的。

（5）创建一个新的RelOptInfo结构，用于处理ORDER BY子句。

注 意 ， 新 的 RelOptInfo 没 有 baserestrictinfo 字 段 ， 该 信 息 已 经 被

WHERE子句所持有。

（ 6 ） 创 建 一 个 排 序 路 径 ， 并 添 加 到 新 的 RelOptInfo 中 ， 然 后 让

SortPath 的subpath字段指向顺序扫描的路径。



SortPath结构包含path与subpath两个Path结构，path中存储了排序算

子本身的相关信息，subpath则指向之前得到的代价最小的路径。

注意顺序扫描路径中的parent字段，该字段指向之前的RelOptInfo结

构 体 （ 也 就 是 在 baserestrictinfo 中 存 储 着 WHERE 子 句 的 那 个

RelOptInfo ） 。 因 此 在 下 一 步 创 建 计 划 树 的 过 程 中 ， 尽 管 新 的

RelOptInfo结构并未包含baserestrictinfo，但是计划器可以创建一

个包含Filter的顺序扫描节点，将WHERE子句作为过滤条件。

这里已经获得了代价最小的访问路径，然后就可以基于此生成一棵计

划树。第3.3.3节描述了相关的细节。

3.3.2.2 例2

下面我们将研究另一个单表查询的例子，这一次表上有两个索引，而

查询带有一个WHERE子句。



图3.12～图3.14展示了本例中计划器的处理过程。



图3.12 如何得到例2中代价最小的路径

（1）创建一个RelOptInfo结构体。

（2）在 baserestrictinfo 中添加一个 WHERE 子句，并将目标表上

的索引添加到indexlist中。

在本例中，WHERE 子句 id <240会被添加到 baserestrictinfo 中，

而 tbl_2_pkey和tbl_2_data_idx两个索引会被添加到RelOptInfo的列

表变量indexlist中。

（3）创建一条路径，估计其顺序扫描代价，并添加到RelOptInfo的

pathlist中。





（4）创建一个IndexPath，估计索引扫描的代价，并通过add_path() 函数将IndexPath添加到RelOptInfo的pathlist中。

在本例中有tbl_2_pkey 与tbl_2_data_index 两个索引，这些索引会

按先后顺序依次处理。

一条针对tbl_2_pkey的IndexPath会先被创建出来，并进行启动代价与

总代价的评估。在本例中，tbl_2_pkey是id列上的索引，而WHERE子句

也包含该id列，因此WHERE子句会被存储在IndexPath的indexclauses 字段中。

（5）创建另一个 IndexPath，估计另一种索引扫描的代价，并将该

IndexPath 添加到RelOptInfo的pathlist中。

接下来，与tbl_2_data_idx相应的IndexPath会被创建出来，并进行代

价 估 计 。 本 例 中 tbl_2_data_idx 并 没 有 相 关 的 WHERE 子 句 ， 因 此 其

indexclauses为空。

注意，add_path()函数并不总是真的会将路径添加到路径列表中。这

一 操 作 相 当 复 杂 ， 故 此 处 省 去 了 具 体 描 述 。 详 细 细 节 可 以 参 考

add_path()函数的注释。





图3.13 如何得到例2中代价最小的路径（接图3.12）

图3.14 如何得到例2中代价最小的路径（接图3.13）

（6）创建一个新的RelOptInfo结构。

（7）将代价最小的路径，添加到新RelOptInfo的pathlist中。





本例中代价最小的路径使用 tbl_2_pkey 的索引路径，故将该路径添

加到新的RelOptInfo中。

3.3.3 创建计划树

在最后一步中，计划器按照代价最小的路径生成一棵计划树。

计划树的根节点是定义在plannodes.h中的PlannedStmt结构，包含19

个字段，其中有4个代表性字段：

● commandType存储操作的类型，诸如SELECT、UPDATE和INSERT。

● rtable存储范围表的列表（RangeTblEntry的列表）。

● relationOids存储与查询相关表的oid。

● plantree存储着一棵由计划节点组成的计划树，每个计划节点对应

着一种特定操作，诸如顺序扫描、排序和索引扫描。



如上所述，计划树包含各式各样的计划节点。PlanNode 是所有计划节

点的基类，其他计划节点都会包含PlanNode结构。比如顺序扫描节点

SeqScanNode包含一个PlanNode和一个整型变量scanrelid。PlanNode 包含14个字段，下面是7个代表性字段：



● startup_cost和total_cost是该节点对应操作的预估代价。

● rows是计划器预计扫描的行数。

● targetlist保存了该查询树中目标项的列表。

● qual储存了限定条件的列表。

● lefttree和righttree用于添加子节点。





下面是两棵计划树，分别与前一小节中的两个例子对应。

3.3.3.1 例1

第一个例子是第3.3.2.1节例1对应的计划树。图3.11所示的代价最小

的路径，由一个排序路径和一个顺序扫描路径组合而成。根路径是排

序路径，而其子路径为顺序扫描路径。尽管这里忽略了大量细节，但

是从代价最小的路径中生成计划树的过程是显而易见的。在本例中，

一个SortNode被添加到PlannedStmt结构中，而SortNode的左子树上挂

载了一个SeqScanNode，如图3.15（1）所示。

在SortNode中，左子树lefttree指向SeqScanNode。

在SeqScanNode中，qual保存了WHERE子句id<300。





图3.15 计划树的例子

3.3.3.2 例2

第二个例子是第3.3.2.2节例2对应的计划树。其代价最小的路径为索

引扫描路径，如图3.14所示。因此计划树由单个IndexScanNode独立组

成，如图3.15（2）所示。





在 本 例 中 ， WHERE 子 句 id < 240 是 一 个 访 问 谓 词 ， 它 储 存 在

IndexScanNode 的indexqual字段中。

3.4 执行器如何工作

在单表查询的例子中，执行器从计划树中取出计划节点，按照自底向

上的顺序进行处理，并调用节点相应的处理函数。



每个计划节点都有相应的函数，用于执行节点对应的操作。这些函数

在 src/backend/executor 目 录 中 。 例 如 ， 执 行 顺 序 扫 描 的 函 数

（ SeqScan ） 定 义 在 nodeSeqscan.c 中 ， 执 行 索 引 扫 描 的 函 数

（IndexScanNode）定义在nodeIndexScan.c中，SortNode节点对应的

排序函数定义在nodeSort.c中，诸如此类。

当然，理解执行器如何工作的最好方式，就是阅读EXPLAIN命令的输

出。因为PostgreSQL的EXPLAIN命令几乎就是照着计划树输出的。下面

以第3.3.3.1节的例1为例。

我们可以自底向上阅读EXPLAIN的结果，来看一看执行器是如何工作

的。

第6行：首先，执行器通过nodeSeqscan.c中定义的函数执行顺序扫描

操作。

第4行：然后，执行器通过nodeSort.c中定义的函数，对顺序扫描的结

果进行排序。

临时文件

执行器在处理查询时会使用工作内存和临时缓冲区，两者都在内存中

分配。如果查询无法在内存中完成，就会用到临时文件。





使用带有Analyze选项的EXPLAIN，待解释的命令会真正执行，并显示

实际结果行数、实际执行时间和实际内存用量。下面是一个具体的例

子：

在第6行，EXPLAIN命令显示执行器使用了10000KB的临时文件。

临时文件会被临时创建在base/pg_tmp子目录中，并遵循如下命名规

则：

{"pgsql_tmp"} + {创建本文件的Postgres进程PID} .{从0开始的序列

号}

比如，临时文件pgsql_tmp8903.5是pid为8903的postgres进程创建的

第6个临时文件。

3.5 连接





PostgreSQL 中支持三种连接操作，分别是嵌套循环连接、归并连接和

散列连接。在PostgreSQL中，嵌套循环连接与归并连接有几种变体。

在下文中，我们会假设读者已经对这三种操作的基本行为有所了解。

如 果 读 者 对 这 些 概 念 不 熟 悉 ， 可 以 参 阅

https://www.amazon.com/dp/0073523321

和

https://www.amazon.com/dp/032152 3067。PostgreSQL支持一种针对

数据倾斜的混合散列连接，这方面的资料不多，因此这里会详细描述

该操作。

需要注意的是，这三种连接方法都支持PostgreSQL中所有的连接操

作 ， 诸 如 INNER JOIN 、 LEFT/RIGHT OUTER JOIN 、 FULL OUTER JOIN

等，为了简单起见，这里只关注NATURAL INNER JOIN。

3.5.1 嵌套循环连接

嵌套循环连接是最基础的连接操作，任何连接条件都可以使用这种连

接方式，如图3.16所示。PostgreSQL支持嵌套循环连接及其5种变体。

3.5.1.1 嵌套循环连接

嵌套循环连接不用任何启动代价，因此：

start-up_cost=0

运行代价与内外表尺寸的乘积成比例，即run_cost是O(N

× N

outer

inner

),N

和N

分 别 是 外 表 和 内 表 的 元 组 条 数 。 更 准 确 地 说 ，

outer

inner

run_cost的定义如下：

run_cost=cpu_operator_cost+cpu_tuple_cost× N

× N

+ C

outer

inner

× N

+C

inner

outer

outer

C

和C

分别是内表和外表顺序扫描的代价。

outer

inner



图3.16 嵌套循环连接

嵌套循环连接的代价总会被估计，但实际中很少会使用这种连接操

作，因为它有几种更高效的变体，下面将会介绍。

3.5.1.2 物化嵌套循环连接

在上面描述的嵌套循环连接中，每当读取一条外表中的元组时，都需

要扫描内表中的所有元组。为每条外表元组对内表做全表扫描，这一

过程代价高昂，PostgreSQL支持一种物化嵌套循环连接，可以减少内

表全表扫描的代价。

在运行嵌套循环连接之前，执行器会使用临时元组存储模块对内表进

行一次扫描，将内表元组加载到工作内存或临时文件中。在处理内表

元组时，临时元组存储比缓冲区管理器更为高效，特别是当所有的元

组都能放入工作内存中时。

图3.17说明了物化嵌套循环连接的处理过程。扫描物化元组在内部被

称为重扫描。





图3.17 物化嵌套循环连接

临时元组存储

PostgreSQL内部提供了临时元组存储的模块，可用于各种操作，如物

化表、创建混合散列连接的批次等。该模块包含一系列函数，都在

tuplestore.c中。这些函数用于从工作内存或临时文件读写元组。使

用工作内存还是临时文件取决于待存储元组的总数。

下面给出一个具体的例子，并研究一下执行器是如何处理物化嵌套循

环连接的计划树并估计其代价的。

上面显示了执行器要进行的操作，执行器对这些计划节点的处理过程

如下：

第7行：执行器使用顺序扫描，物化内部表tbl_b。

第4行：执行器执行嵌套循环连接操作，外表是tbl_a，内表是物化的

tbl_b。

下面来估算“物化”操作（第7行）与“嵌套循环”（第4行）的代

价。假设物化的内部表元组都在工作内存中。

物化：

物化操作没有启动代价，因此，

start-up_cost=0

其运行代价定义如下：

run_cost =2×cpu_operator_cost×N inner 因此，

run_cost =2×0.0025×5000=25.0

此外，

total_cost=start-up_cost+total_cost_of_seq_scan) + run_cost 因此，

total_cost = (0.0+73.0) +25.0 = 98.0

（物化）嵌套循环：

嵌套循环没有启动代价，因此，

start-up_cost = 0





在估计运行代价之前，先来看一下重扫描的代价，重扫描的代价定义

如下：

rescan_cost = cpu_operator_cost×N inner 在本例中，

rescan_cost = (0.0025)×5000=12.5

运行代价由以下公式定义：

这 里

代 表 外 部 表 的 全 部 扫 描 代 价 ，

代表物化代价，因此，

run_cost = (0.0025+0.01) ×5000×10000+12.5× (10000−1)

+145.0+98.0 = 750230.5

3.5.1.3 索引嵌套循环连接

如果内表上有索引，且该索引能用于搜索满足连接条件的元组，那么

计划器在为外表的每条元组搜索内表中的匹配元组时，会考虑使用索

引进行直接搜索，以替代顺序扫描。这种变体叫作索引嵌套循环连

接，如图3.18所示。虽然这种变体叫作“索引嵌套循环连接”，但是

该算法基本上只需要在外表上循环一次，因此连接操作的执行非常高

效。





图3.18 索引嵌套循环连接

下面是索引嵌套循环连接的一个具体例子。

第6行展示了访问内表中元组的代价，即在内表中查找满足第7行连接

条件(id = b.id)的元组的代价。

在第7行的索引条件(id = b.id)中，b.id 是连接条件中的外表属性的

值。每当顺序扫描外表取回一条元组时，就会依第6行所示的索引搜索

路径，查找内表中需要与之连接的元组。换而言之，外表元组的值作

为参数传入内表的索引扫描中，索引扫描路径会查找满足连接条件的





内 表 元 组 。 这 种 索 引 路 径 被 称 为 参 数 化 （ 索 引 ） 路 径 ， 细 节 见

PostgreSQL 源码backend/optimizer/README。

该嵌套循环连接的启动代价，等于第6行中索引扫描的代价，因此，

start-up_cost=0.285

索引嵌套循环扫描的总代价由下列公式所定义：

这里

是参数化内表索引扫描的整体代

价，在本例中：

total_cost=(0.01+0.3625)×5000+73.0=1935.5

运行代价为：

run_cos=1935.5 0.285=1935.215

如上所示，索引嵌套扫描的整体代价是O(N

)。

outer

3.5.1.4 其他变体

如果在外表上存在一个与连接条件相关的索引，那么在外表上也可以

以索引扫描替代顺序扫描。特别是当WHERE子句中的访问谓词可以使用

该索引时，能缩小外表上的搜索范围，嵌套循环连接的代价可能会急

剧减少。

当使用外表索引扫描时，PostgreSQL支持三种嵌套循环连接的变体，

如图3.19所示。





图3.19 嵌套循环连接的三种变体，使用外表索引扫描

这些连接的EXPLAIN结果如下：

（1）使用外表索引扫描的嵌套循环连接。





（2）使用外表索引扫描的物化嵌套循环连接。

（3）使用外表索引扫描的索引嵌套循环连接。





3.5.2 归并连接

与嵌套循环连接不同的是，归并连接只能用于自然连接与等值连接。

函数 initial_cost_mergejoin()和final_cost_mergejoin()用于估计

归并连接的代价。

因为精确估计归并连接的代价非常复杂，所以这里略过不提，只会说

明归并连接算法的工作流程。归并连接的启动成本是内表与外表排序

成本之和，因此其启动成本为：

O(N

log

(N

)+N

log (N

)

outer

2

outer

inner

2

inner

这里N

和N

分别是外表和内表的元组条数，而运行代价是O(N

outer

inner

+ N

)。

outer

inner

与嵌套循环连接类似，归并连接在PostgreSQL中有4种变体。



3.5.2.1 归并连接

图3.20是归并连接的示意图。

图3.20 归并连接

如果所有元组都可以存储在内存中，那么排序操作就能在内存中进

行，否则就使用临时文件。

下面是一个具体的例子，一个归并连接的EXPLAIN输出结果如下所示。



第9行：执行器对内表tbl_b进行排序，使用顺序扫描（第11行）。

第6行：执行器对外表tbl_a进行排序，使用顺序扫描（第8行）。

第4行：执行器执行归并连接操作，外表是排好序的tbl_a，内表是排

好序的tbl_b。

3.5.2.2 物化归并连接

与嵌套循环连接类似，归并连接还支持物化归并连接，物化内表，使

内表扫描更为高效。图3.21是物化归并连接的示意图。





图3.21 物化归并连接

下面是物化归并连接的 EXPLAIN 结果，很容易发现，与普通归并连接

的差异是第9行：Materialize。

第10行：执行器对内表tbl_b进行排序，使用顺序扫描（第12行）。

第9行：执行器对tbl_b排好序的结果进行物化。



第6行：执行器对外表tbl_a进行排序，使用顺序扫描（第8行）。

第4行：执行器执行归并连接操作，外表是排好序的tbl_a，内表是物

化的排好序的tbl_b。

3.5.2.3 其他变体

与嵌套循环连接类似，当外表上可以进行索引扫描时，归并连接也存

在相应的变体，如图3.22所示。

图3.22 归并连接的三种变体，使用外表索引扫描

这些连接的EXPLAIN结果如下。

（1）使用外表索引扫描的归并连接。



（2）使用外表索引扫描的物化归并连接。





（3）使用外表索引扫描的索引归并连接。





3.5.3 散列连接

与归并连接类似，散列连接只能用于自然连接与等值连接。

PostgreSQL中的散列连接的行为因表的大小而异。如果目标表足够小

（确切地说，内表大小不超过工作内存的25%），那么散列连接就是简

单的两阶段内存散列连接，否则将会使用带倾斜批次的混合散列连

接。

本节将介绍PostgreSQL中这两种散列连接的执行过程。

这里省略了代价估算的部分，因为它很复杂。粗略来说，假设向散列

表插入与搜索时没有遇到冲突，那么启动和运行成本复杂度都是O(N

+ N

)。

outer

inner

3.5.3.1 内存散列连接

下面将描述内存中的散列连接。

内存中的散列连接是在work_mem中处理的，在PostgreSQL中，散列表

区域被称作处理批次。一个处理批次会有多个散列槽，内部称其为

桶，桶的数量由 nodeHash.c 中定义的ExecChooseHashTableSize()函

数所确定。桶的数量总是2的整数次幂。

内存散列连接有两个阶段，分别是构建阶段和探测阶段。在构建阶

段，内表中的所有元组都会被插入到处理批次中；在探测阶段，每条





外表元组都会与处理批次中的内表元组比较，如果满足连接条件，则

将两条元组连接起来。

为了理解该操作的过程，下面是一个具体的例子。假设该查询中的连

接操作使用散列连接。

散列连接的过程如图3.23和图3.24所示。

（1）在工作内存上创建一个处理批次。

在本例中，处理批次有8个桶，即桶的数量是2的3次方。

图3.23 内存散列连接的构建阶段

（2）将内表的第一个元组插入批次的相应的桶中。

具体过程如下：

首先，找出元组中涉及连接条件的属性，计算其散列键。

在本例中，因为WHERE 子句是inner.attr1 = outer.attr2，所以内置

的散列函数会对第一条元组的属性attr1取散列值，用作散列键。



其次，将第一条元组插入散列键相应的桶中。

假设第一条元组的散列键以二进制记法表示为0x000 ...001，即其末

三个比特位为001。在这种情况下，该元组会被插入到键为001的桶

中。

在本文中，构建处理批次的插入操作会用运算符 ⊕ 表示。

（3）插入内表中的其余元组。

图3.24 内存散列连接的探测阶段

（4）依外表的第一条元组进行探测。

详情如下：

首先，找出第一条外表元组中涉及连接条件的属性，计算其散列键。

在 这 个 例 子 中 ， 假 设 第 一 条 元 组 的 属 性 attr2 的 散 列 键 是 0x000

...100，即其末三个比特位为100。

其次，将外表中第一条元组与批次中的内表元组进行比较。如果满足

连接条件，则连接内外表元组。

因为第一个元组的散列键的末三位为100，执行器找出键为100的桶中

的所有内表元组，并对内外表元组两侧相应的属性进行比较。这些属

性由连接条件（在WHERE子句中）所指明。

如果满足连接条件，执行器会连接外表中的第一条元组与内表中的相

应元组。如果不满足，则执行器不做任何事情。

在本例中，键为100的桶中有Tuple_C。如果Tuple_C的attr1等于第一

条元组Tuple_W的attr2，则Tuple_C和Tuple_W将被连接，并保存至内

存或临时文件中。

在本文中，处理批次的探测操作用运算符 ⊗ 表示。

（5）依次对外表中的其他元组执行探测。

3.5.3.2 带倾斜的混合散列连接

当 内 表 的 元 组 无 法 全 部 存 储 在 工 作 内 存 中 的 单 个 处 理 批 次 时 ，

PostgreSQL使用带倾斜批次的混合散列连接算法，该算法是混合散列

连接的一种变体。

首先，这里会描述混合散列连接的基本概念。在第一个构建和探测阶

段，PostgreSQL准备多个批次。与桶的数目类似，处理批次的数目由

函数ExecChooseHashTableSize()决定，也就是2的整数次幂。工作内

存中只会分配一个处理批次，而其他批次都以临时文件的形式创建。

属于这些批次的元组将通过临时元组存储功能被写入到相应的文件

中。

图3.25说明了如何将元组存储在4个（2 2 ）处理批次中。在本例中，

元组散列键的最后，5个比特位决定了元组所属的批次与桶，因为处理

批次的数量为2 2 ，而桶的数量为2 3 ，因此需要5个比特位来表示，其

中前两位决定了元组所属的批次，而后三位决定了元组在该批次中所

属的桶。例如，Batch_0存储着散列键介于00000与00111的元组，而

Batch_1存储着散列键介于01000与01111的元组，以此类推。



图3.25 混合散列连接中的多个处理批次

在混合散列连接中，构建与探测阶段的执行次数与处理批次的数目相

同，因为内外表元组都被存至相同数量的处理批次中。在第一轮构建

与探测阶段中，除了处理第一个处理批次，还会创建所有的处理批

次。另一方面，第二轮及后续的处理批次都需要读写临时文件，这属

于代价巨大的操作。因此PostgreSQL还准备了一个名为skew的特殊处

理批次，即倾斜批次，以便在第一轮中高效处理尽可能多的元组。

这个特殊的倾斜批次中的内表元组在连接条件内表一侧属性上的取

值，会选用外表连接属性上的高频值（MCV）。因此在第一轮处理中能

与外表中尽可能多的元组相连接。这种解释不太好理解，因此下面给

出了一个具体的例子。





假设有客户表customers 与购买历史表purchase_history 两个表。

customers 由两个属性组成：name和address; purchase_history由两

个属性组成：customer_name和buying_item。customers有10 000行，

而purchase_history表有1 000 000行。前10%的客户进行了70%的购

买。

理解了这些假设后，让我们考虑当执行以下查询时，带倾斜的混合散

列连接的第一轮是如何执行的。

如 果 customers 是 内 表 ， 而 purchase_history 是 外 表 ， 则

PostgreSQL 将 使 用 purchase_history 表 的 高 频 值 ， 将 前 10% 的

customers元组存储于倾斜批次中。请注意这里引用的是外表上的高频

值 ， 而 插 入 倾 斜 批 次 的 是 内 表 元 组 。 在 第 一 轮 的 探 测 阶 段 ， 外 表

purchase_history中70%的元组将与倾斜批次中存储的元组相连接。因

此，外表分布越是不均匀，第一轮中越是可以处理尽可能多的元组。

接下来会介绍带倾斜批次的混合散列连接的工作原理，如图3.26～图

3.29所示。

图3.26 混合散列连接构建阶段的第一轮



（1）在工作内存中创建一个处理批次，以及一个倾斜批次。

（2）创建处理批次相应的临时文件，用于存储排好序的内表元组。

在本例中，内表被分割为4个批次，因此创建了3个批次文件。

（3）为内表的第一条元组执行构建操作。

细节如下：

第一，如果第一条元组应当插入倾斜批次中，则将其插入倾斜批次，

否则继续下一步。

在本例中，如果第一条元组属于前10%的客户，则将其插入倾斜批次

中。

第二，计算第一条元组的散列键，然后将其插入相应的处理批次。

（4）对内表其余元组依次执行构建操作。

图3.27 混合散列连接探测阶段第一轮

（5）创建临时处理批次文件，用于外表排序。

（6）为外表的第一条元组执行探测操作，如果外表第一条元组上相应

字段取值为MCV，则在倾斜批次上进行探测，否则进行第7步。



在本例中，如果第一条元组是前10%客户的购买数据，则它会与倾斜批

次中的内表元组进行比较。

（7）为外表的第一条元组执行探测操作。

操作的内容取决于该元组散列键的取值。如果该元组属于Batch_0，则

直接完成探测操作，否则将其插入相应的外表处理批次中。

（8）为外表的其余元组执行探测操作。

注意，在本例中，外表中70%的元组已经在第一轮中的倾斜批次中处理

了。

图3.28 构建阶段与探测阶段第二轮

（9）移除倾斜批次与Batch_0，为下一轮处理批次腾地方。

（10）为批次文件batch_1_in中的内表元组执行构建操作。

（11）为批次文件batch_1_out中的外表元组依次执行探测操作。





图3.29 构建阶段与探测阶段第三轮及后续

（12）为批次文件batch_2_in与batch_2_out执行构建操作与探测操

作。

（13）为批次文件batch_3_in与batch_3_out执行构建操作与探测操

作。

3.5.4 连接访问路径与连接节点

本节将介绍所有的连接访问路径与几种连接节点。

3.5.4.1 连接访问路径

嵌套循环连接的访问路径由 JoinPath 结构表示，其他连接访问路

径，诸如 MergePath与HashPath都基于其实现。

图3.30列出了所有的连接访问路径，细节在此略过。



图3.30 连接访问路径





3.5.4.2 连接节点

本节列出了三种连接节点，分别是NestedLoopNode、MergeJoinNode和

HashJoinNode，它们都基于JoinNode实现，具体细节在此略过。





3.6 创建多表查询计划树

本节将说明多表查询计划树的创建过程。

3.6.1 预处理





预 处 理 由 planner.c 中 定 义 的 subquery_planner() 函 数 执 行 。 第

3.3.1节已经描述了单表查询的预处理。本节将描述多表查询的预处

理，这块内容很多，这里只挑其中一部分来讲。

1.对CTE进行计划与转换

如果存在WITH列表，计划器就会通过SS_process_ctes()函数对每个

WITH查询进行处理。

2.上拉子查询

如 果 FROM 子 句 带 有 一 个 子 查 询 ， 且 该 子 查 询 没 有 用 到 GROUP BY 、

HAVING、ORDER BY、LIMIT和DISTINCT、INTERSECT或EXCEPT，那么计

划器就会使用pull_up_subqueries()函数将其转换为连接形式。例如

下面一个 FROM 子句含子查询的查询就可以被转换为自然连接查询。

自不必说，这种转换是在查询树上进行的。

3.将外连接转为内连接

如果可能的话，计划器会将OUTER JOIN查询转换为INNER JOIN查询。

3.6.2 获取代价最小的路径

为了获取最佳计划树，计划器必须考虑各个索引与各种连接方法之间

的所有可能组合。如果表的数量超过某个水平，该过程的代价就会因

为组合爆炸而变得非常昂贵，以至于根本不可行。

幸运的是，如果表的数量小于12张，计划器可以使用动态规划来获取

最佳计划，否则计划器会使用遗传算法。详情如下：

基因查询优化器

当执行一个多表连接查询时，大量时间耗费在了优化查询计划上。为

了应对这种情况，PostgreSQL实现了一个有趣的功能：基因查询优化

器。这种近似算法能在合理时间内确定一个合理的计划。因此在查询

优化阶段，如果参与连接的表数量超过参数geqo_threshold指定的阈

值（默认值为12）,PostgreSQL将使用遗传算法来生成查询计划。

以下是使用动态规划确定最佳计划树的过程，其步骤如下：

● 第一层

获 得 每 张 表 上 代 价 最 小 的 路 径 ， 代 价 最 小 的 路 径 存 储 在 表 相 应 的

RelOptInfo结构中。

● 第二层

从所有表中选择两个表，为每种组合找出代价最低的路径。

举个例子，如果共有两张表，表A与表B，则表A和表B连接的各种路径

中 ， 代 价 最 小 的 那 条 即 为 最 终 想 要 的 答 案 。 在 下 文 中 ， 两 个 表 的

RelOptInfo记作 A,B 。

如果有三个表，则需要获取 A,B 、 A,C 、 B,C 三种组合里各自

代价最小的路径。

● 第三层及其后

继续进行同样的处理，直到层级等于表数量。

通过这种方式，在每个层级都能解决最小代价问题的一部分，且其结

果能被更高层级的计算复用，从而使代价最小的计划树能够被高效地

计算出来。

图3.31展示了使用动态规划获取代价最小的访问路径的方式。



图3.31 如何使用动态规划获取代价最小的访问路径

接下来会针对下面的查询，解释计划器是如何获取代价最小的计划

的。



3.6.2.1 第一层的处理

在第一层中，计划器会为查询中涉及的关系创建相应的RelOptInfo结

构，并估计每个关系上的最小代价。在这一步中，RelOptInfo 结构会

被添加至该查询对应 PlannerInfo 的simple_rel_arrey数组字段中，

如图3.32所示。



图3.32 第一层处理后的PlannerInfo与RelOptInfo 表tbl_a的RelOptInfo有三条访问路径，它们被添加至RelOptInfo的路

径列表中。这三条路径分别被三个指针所连接，即三个指向代价最小

路径的指针，分别是启动代价最小的路径、总代价最小的路径和参数

化代价最小的路径。启动代价最小的路径与总代价最小的路径含义显

而易见，因此，这里只介绍参数化索引扫描代价最小的路径。

如第3.5.1.3节所述，计划器会考虑为索引嵌套循环连接使用参数化路

径（极少数情况下也会用于带外表索引扫描的索引化归并连接）。参

数化索引扫描代价最小的路径，就是所有参数化路径中代价最小的那

个。

表tbl_b的RelOptInfo仅有顺序扫描访问路径，因为tbl_b上没有相关

索引。

3.6.2.2 第二层的处理

在第二层中，计划器会在PlannerInfo的join_rel_list字段中创建一

个RelOptInfo结构。然后估计所有可能连接路径的代价，并且选择代

价最小的那条访问路径。RelOptInfo会将最佳访问路径作为总代价最

小的路径，如图3.33所示。



表3.1~表3.3展示了本例中连接访问路径的所有组合。本例中查询的连

接类型为等值连接，并对全部三种连接算法进行评估。为方便起见，

这里引入了一些有关访问路径的符号：

● SeqScanPath(table)表示表table上的顺序扫描路径。

● Materialized -> SeqScanPath(table)表示表table上的物化顺序

扫描路径。

图3.33 第二层处理后的PlannerInfo和RelOptInfo

● IndexScanPath(table,attribute)表示按表table中属性attribute 上的索引扫描路径。

● ParameterizedIndexScanPath(table,attribute1,attribute2) 表

示表 table中属性attribute1上的参数化索引路径，并使用外表上的

属性attribute2参数化。

表3.1 嵌套循环连接





表3.2 归并连接

表3.3 哈希连接





例如在嵌套循环连接的部分总共评估了7条连接路径。第一条表示在外

表 tbl_a和内表tbl_b上都使用顺序扫描路径；第二条表示在外表

tbl_a上使用路径顺序扫描路径，而在内表tbl_b上使用物化顺序扫描

路径，诸如此类。

计划器最终从估计的连接访问路径中选择代价最小的那条，并且将其

添加到RelOptInfo{tbl_a,tbl_b}的路径列表中，如图3.33所示。

在本例中，如下面EXPLAIN的结果所示，计划器选择了在内表tbl_b和

外表tbl_c上进行散列连接。

3.6.3 获取三表查询代价最小的路径

涉及三表的查询，其代价最小的路径的获取过程如下所示：





● 第一层

计划器估计所有表上各自开销最小的路径，并将该信息存储在表相应

的 RelOptInfos 结构{tbl_a}、{tbl_b}和{tbl_c}中。

● 第二层

计划器从三个表中选出两个，列出所有组合，分别评估每种组合里代

价最小的路径。然后，规划器将信息存储在组合相应的 RelOptInfos 结构{tbl_a,tbl_b}、{tbl_b,tbl_c}和{tbl_a,tbl_c}中。

● 第三层



计划器根据所有已获取的RelOptInfos，选择代价最小的路径。更确切

地 说 ， 计 划 器 会 考 虑 三 种 RelOptInfos 组 合 ， 即 {tbl_a,

{tbl_b,tbl_c}}

、

{tbl_b,{tbl_a,tbl_c}}

和

{tbl_c,

{tbl_a,tbl_b}}，而{tbl_a,tbl_b,tbl_c}如下所示：

{tbl_a,tbl_b,tbl_c}

=

min({tbl_a,{tbl_b,tbl_c}},{tbl_b,{

tbl_a,tbl_c}},{tbl_c,{ tbl_a,tbl_b}}).

计划器会估算这里面所有可能连接路径的代价。

在处理{tbl_c,{tbl_a,tbl_b}}对应的 RelOptInfo 时，计划器会估计

tbl_c和{tbl_a,tbl_b}连接代价最小的路径。本例中{tbl_a,tbl_b}已

经选定内表为tbl_a且外表为tbl_b的散列连接。如第3.6.2.2节所述，

在估计时三种连接算法及其变体都会被评估，即嵌套循环连接及其变

体，归并连接及其变体，散列连接及其变体。

计 划 器 以 同 样 的 方 式 处 理 {tbl_a,{tbl_b,tbl_c}} 与 {tbl_b,

{tbl_a,tbl_c}}对应的RelOptInfo，并最终从所有估好的路径中选择

代价最小的访问路径。

该查询的EXPLAIN命令结果如下所示：





最外层的连接是索引嵌套循环连接（第5行），第13行显示了内表上的

参数化索引扫描，外表则是一个散列连接的结果，该散列连接的内表

是 tbl_a，外表是 tbl_b（第7～12行）。因此，执行程序首先执行

tbl_a和tbl_b上的散列连接，再执行索引嵌套循环连接。

参考文献

[1]Abraham Silberschatz Henry F.Korth·S Sudarshan.Database System

Concepts,.McGraw-Hill

Education,ISBN-13:978-

0073523323.

[2]Thomas

M.Connolly,Carolyn

E.Begg,Database

Systems.Pearson,ISBN-13:978-0321523068.

第4章 外部数据包装器

外部数据包装器（Foreign Data Wrapper ,FDW）相当实用且有趣，图

4.1是FDW涉及的基本概念。

图4.1 FDW的基本概念





2003年，SQL标准中添加了一个访问远程数据的规范，称为SQL外部数

据管理。PostgreSQL的9.1版本开发出了FDW，实现了一部分SQL/MED中

的特性。

在SQL/MED中，远程服务器上的表被称为外部表。PostgreSQL的外部数

据包装器使用与本地表类似的方式，通过SQL/MED来管理外部表。

安装完必要的扩展并配置妥当后，就可以访问远程服务器上的外部表

了。例如假设有两个远程服务器分别命名为 postgresql和mysql，它

们上面分别有 foreign_pg_tbl和foreign_my_tbl两张表。在本例中，

可以在本地服务器上执行SELECT查询以访问外部表，如下所示。

此外，还可以在本地连接来自不同服务器中的外部表。





Postgres wiki中列出了很多现有的FDW扩展，但只有postgres_fdw 与

file_fdw是由官方PostgreSQL全球开发组维护的。postgres_fdw可用

于访问远程PostgreSQL服务器。

以下部分将详细介绍PostgreSQL的FDW。第4.1节是概述，第4.2节介绍

了postgres_fdw扩展的工作方式。

Citus

Citus 是由citusdata.com 开发的开源PostgreSQL扩展，它能创建用

于并行化查询的分布式PostgreSQL服务器集群。Citus是PostgreSQL生

态中机制上最为复杂且商业上最成功的扩展之一，它也是一种FDW。

4.1 概述

使用 FDW 特性需要先安装相应的扩展，并执行一些设置命令，例如

CREATE FOREIGN TABLE、CREATE SERVER和CREATE USER MAPPING（具

体细节请参阅官方文档）。

配置妥当之后，在查询处理期间，执行器将会调用扩展中定义的相应

函数来访问外部表。

图4.2展示了FDW的执行过程。



图4.2 FDW的执行过程

（1）分析器为输入的SQL创建一棵查询树。

（2）计划器（或执行器）连接到远程服务器。

（3）如果启用了use_remote_estimate选项（默认关闭），那么计划

器将执行EXPLAIN命令以估计每条计划路径的代价。

（4）计划器按照计划树创建出纯文本SQL语句，在内部称该过程为逆

解析。

（5）执行器将纯文本SQL语句发送到远程服务器并接收结果。

如有必要，执行器会进一步处理接收到的结果。例如执行多表查询

时，执行器会将接收到的数据与其他表进行连接。





以下各节介绍了每一步的具体细节。

4.1.1 创建一棵查询树

分析器会根据输入的 SQL 创建一棵查询树，并使用外部表的定义。当

执行命令 CREATE FOREIGN TABLE和IMPORT FOREIGN SCHEMA 时，外部

表 的 定 义 会 被 存 储 至 系 统 目 录 pg_catalog.pg_class 和

pg_catalog.pg_foreign_table中。

4.1.2 连接至远程服务器

计划器（或执行器）会使用特定的库连接至远程数据库服务器。例如

要连接至远程PostgreSQL服务器时，postgres_fdw会使用libpq。而连

接 至 MySQL 服 务 器 时 ， 由 EnterpriseDB 开 发 的 mysql_fdw 会 使 用

libmysqlclient。

当执行CREATE USER MAPPING和CREATE SERVER命令时，诸如用户名、

服 务 器 IP 地 址 和 端 口 号 等 连 接 参 数 会 被 存 储 至 系 统 目 录

pg_catalog.pg_user_mapping和pg_catalog.pg_foreign_server中。

4.1.3 使用EXPLAIN命令创建计划树（可选）

PostgreSQL的 FDW机制支持一种特性：获取外部表上的统计信息，用

于估计查询代价。一些FDW扩展使用了该特性，例如postgres_fdw、

mysql_fdw、tds_fdw和jdbc2_fdw。

如果使用ALTER SERVER命令将use_remote_estimate选项设置为on，则

计划器会向远程服务器发起查询，执行EXPLAIN命令获取执行计划的代

价。否则在默认情况下，会使用默认内置常量值作为代价。

尽管一些扩展也会执行EXPLAIN命令，但是目前只有postgres_fdw才能

忠于EXPLAIN命令的真正意图，因为 PostgreSQL 的 EXPLAIN 命令会

同时返回启动代价和总代价。而其他DBMS的FDW扩展一般无法使用

EXPLAIN命令的结果进行规划。例如MySQL的EXPLAIN命令仅仅返回估计





的行数，但如第3章所述，PostgreSQL的计划器需要更多的信息来估算

代价。

4.1.4 逆解析

在生成执行计划树的过程中，计划器会为执行计划树上外部表的扫描

路径创建相应的纯文本SQL语句。图4.3展示了下列SELECT语句对应的

计划树。

图4.3展示了一个存储着纯文本形式SELECT 语句的ForeignScan 节

点 ， PlannedStmt 是 执 行 计 划 树 对 应 的 数 据 结 构 ， 包 含 指 向

ForeignScan 节点的链接。这里，postgres_fdw从查询树中重新创建

出SELECT纯文本语句，该过程在PostgreSQL中被称为逆解析。

使用mysql_fdw时，会从查询树中重新创建MySQL相应的SELECT语句。

使用redis_fdw或rw_redis_fdw会创建一条Redis中的SELECT命令。

图4.3 扫描外部表的计划树示例

4.1.5 发送SQL命令并接收结果





在进行逆解析之后，执行器将逆解析得到的SQL语句发送到远程服务器

并接收结果。

扩展的开发者决定了将SQL语句发送至远程服务器的具体方法。例如

mysql_fdw 在 发 送 多 条 SQL 语 句 时 不 使 用 事 务 。 在 mysql_fdw 中 执 行

SELECT查询的典型SQL语句序列如图4.4所示。

图4.4 mysql_fdw执行一个典型SELECT查询时的SQL语句序列

●（5-1）将SQL_MODE设置为ANSI_QUOTES。

●（5-2）将SELECT语句发送到远程服务器。

●（5-3）从远程服务器接收结果。这里mysql_fdw 会将结果转换为

PostgreSQL 可 读 的 格 式 。 所 有 FDW 扩 展 都 实 现 了 将 结 果 转 换 为

PostgreSQL可读数据的功能。

下面是远程服务器的日志，列出了实际接收到的语句。



postgres_fdw中的SQL命令顺序更复杂。在postgres_fdw中执行一个典

型的SELECT查询，实际的语句序列如图4.5所示。



图4.5 postgres_fdw执行一个典型SELECT查询时的SQL语句序列

●（5-1）启动远程事务。远程事务的默认隔离级别是 REPEATABLE

READ，如果本地事务的隔离级别设置为 SERIALIZABLE，则远程事务的

隔离级别也会设置为SERIALIZABLE。

●（5-2）～（5-4）声明一个游标，SQL语句基本上以游标的方式来执

行。

●（5-5）执行FETCH命令获取结果。默认情况下FETCH命令一次获取

100行。





●（5-6）从远程服务器接收结果。

●（5-7）关闭游标。

●（5-8）提交远程事务。

下面是远程服务器的实际日志。

postgres_fdw中远程事务的默认隔离级别

远程事务的默认隔离级别为REPEATABLE READ，官方文档给出了原因和

说明：

当 本 地 事 务 使 用 SERIALIZABLE 隔 离 级 别 时 ， 远 程 事 务 也 会 使 用

SERIALIZABLE隔离级别，否则使用REPEATABLE READ隔离级别。这样可

以确保在远程服务器上执行多次扫表时，每次的结果都能保持一致。

因此，即使其他活动在远程服务器上进行了并发更新，单个事务中的

连续查询也将看到远程服务器上的一致性快照。

4.2 postgres_fdw的工作原理

postgres_fdw扩展是一个由PostgreSQL全球开发组官方维护的特殊模

块，其源码包含在PostgreSQL源码树中。

postgres_fdw正处于不断改善的过程中。表4.1列出了官方文档中与

postgres_fdw有关的发布说明。



表4.1 与postgres_fdw有关的发布说明（摘自官方文档）

第 4.1 节 描 述 了 postgres_fdw 如 何 处 理 单 表 查 询 ， 接 下 来 将 介 绍

postgres_fdw如何处理多表查询、排序操作和聚合函数。

本 节 重 点 介 绍 了 SELECT 语 句 ， 但 postgres_fdw 还 可 以 处 理 其 他

DML（INSERT、UPDATE和DELETE）语句。

PostgreSQL的FDW不会检测死锁

postgres_fdw与 FDW功能并不支持分布式锁管理器与分布式死锁检测

功 能 ， 因 此 很 容 易 产 生 死 锁 。 例 如 某 客 户 端 A 更 新 了 一 个 本 地 表

tbl_local与一个外部表tbl_remote，而另一个客户端 B 以相反的顺

序 更 新 tbl_remote 和 tbl_local ， 那 么 这 两 个 事 务 陷 入 死 锁 。 但

PostgreSQL无法检测到这种情况，因而无法提交这些事务。





4.2.1 多表查询

当执行多表查询时，postgres_fdw使用单表SELECT语句依次拉取每个

外部表，并在本地服务器上执行连接操作。

在9.5或更低版本中，即使所有外部表都存储在同一个远程服务器中，

postgres_fdw 也会单独拉取每个表再连接。

在9.6或更高版本中，postgres_fdw 已经有所改进，当外部表位于同

一服务器上且use_remote_estimate选项打开时，可以在远程服务器上

执行远程连接操作。

执行细节如下所述。

9.5及更低版本：

我们研究一下PostgreSQL如何处理以下查询：tbl_a和tbl_b两个外部

表的连接。

EXPLAIN的执行结果如下：





结果显示，执行器选择了归并连接，并按以下步骤处理：

● 第8行：执行器使用外部表扫描拉取表tbl_a。

● 第6行：执行器在本地服务器上对拉取的tbl_a行进行排序。

● 第11行：执行器使用外表扫描拉取表tbl_b。

● 第9行：执行器在本地服务器上对拉取的tbl_b行进行排序。

● 第4行：执行器在本地服务器上执行归并连接操作。

图4.6描述了执行器如何拉取行集。

●（5-1）启动远程事务。

●（5-2）声明游标c1，其SELECT语句如下所示：



●（5-3）执行FETCH命令以拉取游标c1的结果。

●（5-4）声明游标c2，其SELECT语句如下所示：

图4.6是在9.5及更低版本中执行多表查询时的SQL语句序列。



图4.6 在9.5及更低版本中执行多表查询时的SQL语句序列

注 意 ， 原 来 双 表 查 询 中 的 WHERE 子 句 是 tbl_a.id = tbl_b.id AND

tbl_a.id <200，因而从逻辑上讲这条 SELECT 语句也可以添加上一条

WHERE 子句 tbl_b.id <200。但postgres_fdw 没有办法执行这样的推

理，因此执行器必须执行不包含任何 WHERE 子句的SELECT语句，获取

外部表tbl_b中的所有行。

这种处理方式效率很差，因为必须通过网络从远程服务器读取不必要

的行。此外，执行归并连接还需要先对所接收的行进行排序。

●（5-5）执行FETCH命令，拉取游标c2的结果。

●（5-6）关闭游标c1。

●（5-7）关闭游标c2。

●（5-8）提交事务。

下面是远程服务器的实际日志。





在接收到行之后，执行器对接收到的tbl_a和tbl_b 行进行排序，然后

对已排序的行执行合并连接操作。

9.6或更高版本：

如 果 启 用 了 use_remote_estimate 选 项 （ 默 认 为 关 闭 ） ， 则

postgres_fdw会发送几条EXPLAIN命令，用于获取与外部表相关的所有

计划的代价。

当 发 送 EXPLAIN 命 令 时 ， postgres_fdw 将 为 每 个 单 表 查 询 执 行

EXPLAIN，也为执行远程连接操作时的SELECT语句执行EXPLAIN 。在本

例中，以下7个EXPLAIN命令会被发送至远程服务器，用于估算每个

SELECT语句的开销，从而选择开销最小的执行计划。

让我们在本地服务器上执行EXPLAIN命令，并观察计划器选择了哪一个

计划。





结果显示，计划器选择了在远程服务器上进行INNER JOIN处理的执行

计划，也是最有效率的执行计划。

下面讲述postgres_fdw是如何执行这一过程的，如图4.7所示。

●（3-1）启动远程事务。

●（3-2）执行EXPLAIN命令，估计每条计划路径的代价。在本例中执

行了7条EXPLAIN命令，然后计划器根据EXPLAIN命令的结果，选取具有

最低开销的SELECT查询。

●（5-1）声明游标c1，其SELECT语句如下所示：

●（5-2）从远程服务器接收结果。

●（5-3）关闭游标c1。

●（5-4）提交事务。



图4.7 执行远程连接操作时的SQL语句序列，9.6及更高版本

下面是远程服务器的实际日志。





注意，如果禁用 use_remote_estimate 选项（默认情况），则远程连

接查询很少会被选择，因为这种情况下其代价会使用一个很大的预置

值进行估计。

4.2.2 排序操作

在9.5或更低版本中，排序操作（如ORDER BY）都是在本地服务器上处

理的，即本地服务器在排序操作之前从远程服务器拉取所有的目标

行。让我们通过EXPLAIN来看一个包含ORDER BY子句的简单查询是如何

被处理的。

第6行：执行器将以下查询发送到远程服务器，然后获取查询结果。





第4行：执行器在本地服务器上对拉取的tbl_a中的行进行排序。

下面是远程服务器的实际日志。

在9.6或更高版本中，如果可行，postgres_fdw能在远程服务器上直接

执行带ORDER BY子句的SELECT语句。

第4行：执行器将以下带ORDER BY子句的查询发送至远程服务器，然后

拉取已排序的查询结果。





下面是远程服务器的实际日志。

4.2.3 聚合函数

在9.6及更低版本中，类似于第4.2.2节中提到的排序操作，AVG()和

COUNT()这类聚合函数会在本地服务器上进行处理，如下所示。





第5行：执行器将以下查询发送到远程服务器，然后拉取查询结果。

第4行：执行器在本地服务器上对拉取的tbl_a行集求均值。

这一过程开销很大，因为发送大量的行会产生大量网络流量，而且需

要很长时间。

下面是远程服务器的实际日志。

在10.0或更高版本中，如果可行的话，postgres_fdw将在远程服务器

上执行带聚合函数的SELECT语句。





第4行：执行器将以下包含AVG()函数的查询发送至远程服务器，然后

获取查询结果。

这种处理方式显然更为高效，因为远程服务器会负责计算均值，仅发

送单行结果。

下面是远程服务器的实际日志。





下推

与上面的例子类似，下推指的是本地服务器允许一些操作在远程服务

器上执行，例如聚合函数。

第5章 并发控制

当多个事务同时在数据库中运行时，并发控制是一种用于维持一致性

与隔离性的技术，一致性与隔离性是ACID的两个属性。

译者注：ACID指数据库事务正确执行的四个基本要素的缩写，包含原

子 性 （ Atomicity ） 、 一 致 性 （ Consistency ） 、 隔 离 性

（Isolation）、持久性（Durability）。

从宽泛的意义上来讲，有三种并发控制技术，分别是多版本并发控制

（ Multi-Version Concurrency Control,MVCC ） 、 严 格 两 阶 段 锁 定

（ Strict Two-Phase Locking,S2PL ） 和 乐 观 并 发 控 制 （ Optimistic Concurrency Control,OCC），每种技术都有多种变体。在MVCC中，每

个写操作都会创建一个新版本的数据项，并保留其旧版本。当事务读

取数据对象时，系统会选择其中的一个版本，通过这种方式来确保各

个事务间相互隔离。MVCC的主要优势在于“读不会阻塞写，写也不会

阻塞读”，相反的例子是，基于S2PL的系统在写操作发生时会阻塞相

应对象上的读操作，因为写入者获取了对象上的排他锁。PostgreSQL

和一些关系型数据库使用一种MVCC的变体，叫作快照隔离（Snapshot Isolation,SI）。

一些关系型数据库（例如Oracle）使用回滚段来实现快照隔离SI。当

写入新数据对象时，旧版本对象先被写入回滚段，随后用新对象覆写

至数据区域。PostgreSQL使用更简单的方法，即新数据对象被直接插

入相关表页中。读取对象时，PostgreSQL根据可见性检查规则，为每

个事务选择合适的对象版本作为响应。

SI中不会出现在ANSI SQL-92标准中定义的三种异常，分别是脏读、不

可重复读和幻读。但 SI无法实现真正的可串行化，因为在 SI中可能

会出现串行化异常，例如写偏差和只读事务偏差。需要注意的是，

ANSI SQL-92标准中可串行化的定义与现代理论中的定义并不相同。为

了解决这个问题，PostgreSQL 从9.1版本之后添加了可串行化快照隔

离（Serializable Snapshot Isolation,SSI）,SSI可以检测串行化异

常，并解决这种异常导致的冲突。因此，9.1版本之后的PostgreSQL提

供了真正的SERIALIZABLE隔离等级（SQL Server也使用SSI，而Oracle 仍然使用SI）。

本章包括以下4个部分：

● 第1部分：第5.1~5.3节。

这部分介绍了理解后续部分所需的基本信息。第5.1节描述了事务标

识，第5.2节描述了元组结构，第5.3节展示了如何插入、删除和更新

元组。

● 第2部分：第5.4~5.6节。

这部分说明了实现并发控制机制所需的关键功能。第5.4～5.6节描述

了提交日志，分别介绍了事务状态、事务快照和可见性检查规则。

● 第3部分：第5.7~5.9节。

这部分使用具体的例子来介绍PostgreSQL中的并发控制。说明了如何

防止ANSI SQL标准中定义的三种异常。第5.7节描述了可见性检查，第

5.8节介绍了如何防止丢失更新，第5.9节简要描述了可串行化快照隔

离（SSI）。

● 第4部分：第5.10节。

这一部分描述了并发控制机制持久运行所需的几个维护过程。维护过

程主要通过清理过程进行，清理过程将在第6章详细阐述。

并发控制包含着很多主题，本章重点介绍PostgreSQL独有的内容。故

此处省略了锁模式与死锁处理的内容（相关信息请参阅官方文档）。

PostgreSQL中的事务隔离等级

PostgreSQL实现的事务隔离等级如下表所示：





[1]：在9.0及更低版本中，该级别被当作SERIALIZABLE，因为它不会出现ANSI SQL-92标准中定义的三种

异常。但9.1版中SSI的实现引入了真正的SERIALIZABLE级别，该级别已被改称为REPEATABLE READ。

PostgreSQL对DML（SELECT、UPDATE、INSERT、DELETE等命令）使用

SSI，对DDL（CREATE TABLE等命令）使用2PL。

5.1 事务标识

每 当 事 务 开 始 时 ， 事 务 管 理 器 就 会 为 其 分 配 一 个 称 为 事 务 标 识

（transaction id,txid）的唯一标识符。PostgreSQL的txid 是一个

32位无符号整数，取值空间大小约为42亿。在事务启动后执行内置的

txid_current()函数，即可获取当前事务的txid，如下所示。

PostgreSQL保留以下三个特殊txid：

● 0表示无效的txid。



● 1表示初始启动的txid，仅用于数据库集群的初始化过程。

● 2表示冻结的txid，详情参考第5.10节。

txid 可以相互比较大小。例如对于txid=100的事务，大于100的txid 属于“未来”，且对于txid=100的事务而言都是不可见的，小于100的

txid属于“过去”，且对该事务可见，如图5.1（1）所示。

因为txid在逻辑上是无限的，而实际系统中的txid空间不足（4B整型

的取值空间大小约42亿），因此PostgreSQL将txid空间视为一个环。

对于某个特定的txid，其前约21亿个txid属于过去，其后约21亿个

txid属于未来，如图5.1（2）所示。

txid回卷问题将在第5.10节中介绍。

注意，txid并非是在BEGIN命令执行时分配的。在PostgreSQL中，当执

行BEGIN命令后的第一条命令时，事务管理器才会分配txid，并真正启

动其事务。





图5.1 PostgreSQL中的事务标识

5.2 元组结构

我们可以将表页中的堆元组分为普通数据元组与TOAST元组两类。本节

只介绍普通元组。

堆元组由三个部分组成，即 HeapTupleHeaderData 结构、空值位图及

用户数据，如图5.2所示。

图5.2 元组结构

HeapTupleHeaderData 结 构 在 src/include/access/htup_details.h 中

定义。





虽然HeapTupleHeaderData结构包含7个字段，但是后续部分中只需要

了解4个字段即可。

● t_xmin保存插入此元组的事务的txid。

● t_xmax 保存删除或更新此元组的事务的 txid。如果尚未删除或更

新此元组，则t_xmax设置为0，即无效。

● t_cid 保存命令标识（command id,cid）,cid 的意思是在当前事

务中，执行当前命令之前执行了多少SQL命令，从零开始计数。例如，

假 设 我 们 在 单 个 事 务 中 执 行 了 3 条 INSERT 命 令

BEGIN;INSERT;INSERT;INSERT;COMMIT; 。 如 果 第 一 条 命 令 插 入 此 元

组，则该元组的t_cid会被设置为0。如果第二条命令插入此元组，则

其t_cid会被设置为1，以此类推。

● t_ctid保存着指向自身或新元组的元组标识符（tid）。如第1.3节

中所述，tid用于标识表中的元组。在更新该元组时，t_ctid 会指向

新版本的元组，否则 t_ctid 会指向自己。

5.3 元组的增、删、改

本节会介绍元组的增、删、改过程，并简要描述用于插入与更新元组

的自由空间映射（Free Space Map,FSM）。

这里主要关注元组，页首部与行指针不会在这里画出来，元组的具体

表示如图5.3所示。

图5.3 元组的表示



5.3.1 插入

在插入操作中，新元组将直接插入目标表的页面中，如图5.4所示。

图5.4 插入元组

假设元组是由txid=99的事务插入页面中的，在这种情况下，被插入元

组的首部字段会依以下步骤设置。

Tuple_1：

● t_xmin设置为99，因为此元组由txid=99的事务所插入。

● t_xmax设置为0，因为此元组尚未被删除或更新。

● t_cid设置为0，因为此元组是由txid=99的事务所执行的第一条命

令插入的。

● t_ctid设置为(0,1)，指向自身，因为这是该元组的最新版本。

pageinspect

PostgreSQL自带了一个第三方贡献的扩展模块pageinspect，可用于检

查数据库页面的具体内容。





5.3.2 删除

在删除操作中，目标元组只是在逻辑上被标记为删除。目标元组的

t_xmax 字段将被设置为执行DELETE命令事务的txid，如图5.5所示。

图5.5 删除元组

假设Tuple_1被txid=111的事务删除。在这种情况下，Tuple_1的首部

字段t_xmax被设为111。





如果txid=111的事务已经提交，就不一定要Tuple_1。通常不需要的元

组在PostgreSQL中被称为死元组（dead tuple）。

死 元 组 最 终 将 从 页 面 中 被 移 除 。 清 除 死 元 组 的 过 程 被 称 为 清 理

（VACUUM）过程，第6章将介绍清理过程。

5.3.3 更新

在更新操作中，PostgreSQL在逻辑上实际执行的是删除最新的元组，

并插入一条新的元组，如图5.6所示。

图5.6 两次更新同一行

假设由txid=99的事务插入的行，被txid=100的事务更新两次。

当执行第一条UPDATE命令时，Tuple_1的t_xmax被设为txid 100，在逻

辑上被删除，然后Tuple_2被插入，接下来重写Tuple_1的t_ctid以指

向Tuple_2。Tuple_1和Tuple_2的头部字段设置如下。

Tuple_1：





● t_xmax被设置为100。

● t_ctid从(0,1)被改写为(0,2)。

Tuple_2：

● t_xmin被设置为100。

● t_xmax被设置为0。

● t_cid被设置为0。

● t_ctid被设置为(0,2)。

当执行第二条UPDATE命令时，和第一条UPDATE命令类似，Tuple_2被逻

辑删除，Tuple_3被插入。Tuple_2和Tuple_3的首部字段设置如下。

Tuple_2：

● t_xmax被设置为100。

● t_ctid从(0,2)被改写为(0,3)。

Tuple_3：

● t_xmin被设置为100。

● t_xmax被设置为0。

● t_cid被设置为1。

● t_ctid被设置为(0,3)。

与 删 除 操 作 类 似 ， 如 果 txid=100 的 事 务 已 经 提 交 ， 那 么 Tuple_1 和

Tuple_2 就 成 了 死 元 组 ， 而 如 果 txid=100 的 事 务 中 止 ， Tuple_2 和

Tuple_3就成了死元组。

5.3.4 空闲空间映射





插入堆或索引元组时，PostgreSQL使用表与索引相应的FSM来选择可供

插入的页面。

如第1.2.3节所述，表和索引都有各自的FSM。每个FSM存储着相应表或

索引文件中每个页面可用空间容量的信息。

所有FSM都以后缀fsm存储，在需要时它们会被加载到共享内存中。

pg_freespacemap

扩展 pg_freespacemap能提供特定表或索引上的空闲空间信息。以下

查询列出了特定表中每个页面的空闲率。

5.4 提交日志





PostgreSQL在提交日志（Commit Log,CLOG）中保存事务的状态。提交

日志分配于共享内存中，并用于事务处理过程的全过程。

本节将介绍PostgreSQL中事务的状态，CLOG的工作方式与维护过程。

5.4.1 事务状态

PostgreSQL 定 义 了 4 种 事 务 状 态 ， 即 IN_PROGRESS 、 COMMITTED 、

ABORTED和SUB_COMMITTED。

前 三 种 状 态 显 而 易 见 。 例 如 当 事 务 正 在 进 行 时 ， 其 状 态 为

IN_PROGRESS，以此类推。

SUB_COMMITTED状态用于子事务，本文省略了与子事务相关的描述。

5.4.2 提交日志如何工作

提交日志（下称CLOG）在逻辑上是一个数组，由共享内存中一系列8KB

页面组成。数组的序号索引对应着相应事务的标识，其内容则是相应

事务的状态。CLOG的工作方式如图5.7所示。

图5.7 CLOG的工作方式

T1:txid 200提交；txid 200的状态从IN_PROGRESS变为COMMITTED。

T2:txid 201中止；txid 201的状态从IN_PROGRESS变为ABORTED。

txid 不断前进，当 CLOG空间耗尽无法存储新的事务状态时，就会追

加分配一个新的页面。





当 需 要 获 取 事 务 的 状 态 时 ， PostgreSQL 将 调 用 相 应 内 部 函 数 读 取

CLOG，并返回所请求事务的状态，参见第5.7.1节中的提示位。

5.4.3 提交日志的维护

当PostgreSQL关机或执行存档过程时，CLOG数据会写入pg_clog子目录

下的文件中（注意，在10.0版本中，pg_clog被重命名为pg_xact）。

这些文件被命名为0000,0001等。文件的最大尺寸为256 KB。例如当

CLOG使用8个页面时，从第1页到第8页的总大小为64 KB，这些数据会

写入文件0000（64 KB）中，而当CLOG使用37个页面时（296 KB），数

据则会写入0000和0001两个文件中，其大小分别为256 KB和40 KB。

当PostgreSQL启动时会加载存储在pg_clog（pg_xact）中的文件，用

其数据初始化CLOG。

CLOG的大小会不断增长，因为只要CLOG一填满就会追加新的页面。但

并非所有数据都是必要的。第6章中描述的清理过程会定期删除这些不

需要的旧数据（CLOG页面和文件），有关删除CLOG数据的详情请参见

第6.4节。

5.5 事务快照

事务快照是一个数据集，存储着某个特定事务在某个特定时间点所看

到的事务状态信息：哪些事务处于活跃状态。活跃状态意味着事务正

在进行中或还没有开始。

事务快照在 PostgreSQL内部的文本表示格式定义为100:100:。举个例

子，100:100：意味着 txid < 100的事务处于非活跃状态，而 txid 100的事务处于活跃状态。下面都将使用这种便利形式来表示。如果读

者还不熟悉这种形式，请参阅下文。

内置函数txid_current_snapshot及其文本表示

函数txid_current_snapshot显示当前事务的快照。



txid_current_snapshot的文本表示是xmin:xmax:xip_list，各部分描

述如下。

● xmin

最早仍然活跃的事务的txid。所有比它更早的事务（txid < xmin），

要么已经提交并可见，要么已经回滚并生成死元组。

● xmax

第一个尚未分配的txid。所有txid ≥ xmax的事务在获取快照时尚未

启动，因此其结果对当前事务不可见。

● xip_list

获取快照时活跃事务的txid列表。该列表仅包括xmin与xmax之间的

txid。

例 如 ， 在 快 照 100:104:100,102 中 ， xmin 是 100,xmax 是 104 ， 而

xip_list为100,102。

以下是两个具体的示例：



图5.8 事务快照的示例

第一个例子是100:100:，如图5.8（1）所示，此快照表示：

● 因为xmin为100，所以txid < 100的事务不活跃。

● 因为xmax为100，所以txid ≥ 100的事务是活跃的。

第二个例子是100:104:100,102，如图5.8（2）所示，此快照表示：

● txid < 100的事务不活跃。

● txid ≥ 104的事务是活跃的。

● txid等于100和102的事务是活跃的，因为它们在xip_list中，而

txid等于101和103的事务不活跃。

事务快照是由事务管理器提供的。在 READ COMMITTED 隔离级别，事

务在执行每条 SQL时都会获取快照，在其他情况下（REPEATABLE READ

或 SERIALIZABLE 隔离级别），事务只会在执行第一条 SQL命令时获

取一次快照。获取的事务快照用于元组的可见性检查，如第5.7节所

述。

使用获取的快照进行可见性检查时，所有活跃的事务都必须被当成 IN

PROGRESS 的事务等同对待，无论它们实际上是否已经提交或中止。这

条 规 则 非 常 重 要 ， 因 为 它 正 是 READ COMMITTED 和 REPEATABLE



READ/SERIALIZABLE 隔离级别中表现差异的根本来源，我们将在接下

来几节中频繁回到这条规则上来。

在本节的剩余部分中，我们会通过一个具体的场景来描述事务与事务

管理器，如图5.9所示。

图5.9 事务与事务管理器

事务管理器始终保存着当前运行的事务的有关信息。假设三个事务一

个接一个地开始，并且 Transaction_A和Transaction_B 的隔离级别

是 READ COMMITTED,Transaction_C的隔离级别是REPEATABLE READ。

● T1:Transaction_A 启动并执行第一条 SELECT 命令。执行第一条

命令时，Transaction_A 请求此刻的 txid和快照。在这种情况下，事

务管理器分配txid=200，并返回事务快照200:200:。

● T2:Transaction_B启动并执行第一条SELECT命令。事务管理器分配

txid=201，并返回事务快照200:200:，因为Transaction_A(txid=200) 正在进行中。因此无法从Transaction_B中看到Transaction_A。





● T3:Transaction_C启动并执行第一条SELECT命令。事务管理器分配

txid=202，并返回事务快照200:200:，因此不能从 Transaction_C 中

看到 Transaction_A和Transaction_B。

● T4:Transaction_A已提交。事务管理器删除有关此事务的信息。

● T5:Transaction_B和Transaction_C执行它们各自的SELECT命令。

Transaction_B需要一个新的事务快照，因为它使用了READ COMMITTED

隔离等级。在这种情况下，Transaction_B 获取新快照201:201:，因

为 Transaction_A(txid=200) 已 提 交 ， 所 以 Transaction_A 的 变 更 对

Transaction_B可见。

Transaction_C 不需要新的事务快照，因为它处于 REPEATABLE READ

隔 离 等 级 ， 并 继 续 使 用 已 获 取 的 快 照 ， 即 200:200: ， 所 以

Transaction_A 的变更仍然对 Transaction_C不可见。

5.6 可见性检查规则

可见性检查规则是一组规则，用于确定一条元组是否对一个事务可

见，可见性检查规则会用到元组的t_xmin和t_xmax，提交日志CLOG，

以及已获取的事务快照。这些规则太复杂，无法详细解释，故本书只

列出了理解后续内容所需的最小规则子集。在下文中省略了与子事务

相关的规则，并忽略了关于t_ctid 的讨论，比如我们不会考虑在同一

个事务中对一条元组多次重复更新的情况。

所选规则有10条，可以分为三种情况。

5.6.1 t_xmin的状态为ABORTED

t_xmin状态为ABORTED的元组始终不可见（规则1），因为插入此元组

的事务已中止。





该规则明确表示为以下数学表达式。

规则1:If Status(t_xmin) = ABORTED ⇒ Invisible

5.6.2 t_xmin的状态为IN_PROGRESS

t_xmin状态为IN_PROGRESS的元组基本上是不可见的（规则3和规则

4），但在一个条件下除外。



如果该元组被另一个进行中的事务插入（t_xmin 对应事务状态为

IN_PROGRESS），则该元组显然是不可见的（规则4）。

如果t_xmin 等于当前事务的txid（即，是当前事务插入了该元组），

且t_xmax ≠ 0，则该元组是不可见的，因为它已被当前事务更新或删

除（规则3）。

有个例外是，当前事务插入此元组且 t_xmax 无效（t_xmax = 0）的

情况。在这种情况下，此元组对当前事务可见（规则2）。

规 则 2:If Status(t_xmin) = IN_PROGRESS ∧ t_xmin =

current_txid ∧ t_xmax= INVAILD ⇒ Visible





规 则 3:If Status(t_xmin) = IN_PROGRESS ∧ t_xmin =

current_txid ∧ t_xmax≠ INVAILD ⇒ Invisible 规 则 4:If Status(t_xmin) = IN_PROGRESS ∧ t_xmin ≠

current_txid ⇒ Invisible

5.6.3 t_xmin的状态为COMMITTED

t_xmin状态为COMMITTED的元组是可见的（规则 6、规则8和规则9），

但在三个条件下除外。





规则6是显而易见的，因为t_xmax为INVALID，或者t_xmax对应事务已

经中止，相应元组可见。三个例外条件及规则8与规则9的描述如下。

第一个例外情况是t_xmin在获取的事务快照中处于活跃状态（规则

5）。在这种情况下，这条元组是不可见的，因为t_xmin 应该被视为

正 在 进 行 中 （ 取 快 照 时 创 建 该 元 组 的 事 务 尚 未 提 交 ， 因 此 对 于

REPEATABLE READ以及更高隔离等级而言，即使在判断时创建该元组的

事务已经提交，但其结果仍然不可见）。

第二个例外情况是t_xmax 是当前的txid（规则7）。这种情况与规则3

类似，此元组是不可见的，因为它已经被此事务本身更新或删除。

相 反 ， 如 果 t_xmax 的 状 态 是 IN_PROGRESS 并 且 t_xmax 不 是 当 前 的

txid（规则8），则元组是可见的，因为它尚未被删除（因为删除该元

组的事务尚未提交）。

第三个例外情况是t_xmax的状态为COMMITTED，且t_xmax在获取的事务

快照中是非活跃的（规则10）。在这种情况下该元组不可见，因为它

已被另一个事务更新或删除。

相反，如果t_xmax的状态为COMMITTED，但t_xmax在获取的事务快照中

处于活跃状态（规则9），则元组可见，因为t_xmax对应的事务应被视

为正在进行中，删除尚未提交生效。

规 则 5:If Status(t_xmin) = COMMITTED ∧ Snapshot(t_xmin) =

active ⇒Invisible

规 则 6:If Status(t_xmin) = COMMITTED ∧ (t_xmax = INVALID ∨

Status(t_xmax)= ABORTED) ⇒ Visible 规 则 7:If Status(t_xmin) = COMMITTED ∧ Status(t_xmax) =

IN_PROGRESS ∧t_xmax = current_txid ⇒ Invisible





规 则 8:If Status(t_xmin) = COMMITTED ∧ Status(t_xmax) =

IN_PROGRESS ∧t_xmax ≠ current_txid ⇒ Visible 规 则 9:If Status(t_xmin) = COMMITTED ∧ Status(t_xmax) =

COMMITTED ∧Snapshot(t_xmax) = active ⇒ Visible 规 则 10:If Status(t_xmin) = COMMITTED ∧ Status(t_xmax) =

COMMITTED ∧Snapshot(t_xmax) ≠ active ⇒ Invisible

5.7 可见性检查

本节描述了PostgreSQL执行可见性检查的过程。可见性检查即如何为

给定事务挑选堆元组的恰当版本。本节还介绍了PostgreSQL如何防止

ANSI SQL-92标准中定义的异常，分别是脏读、可重读和幻读。

5.7.1 可见性检查的过程

图5.10中的场景描述了可见性检查的过程。

在图5.10所示的场景中，SQL命令按以下时序执行。

T1：启动事务(txid=200)

T2：启动事务(txid=201)

T3：执行txid=200和200的事务的SELECT命令

T4：执行txid=200的事务的UPDATE命令

T5：执行txid=200和200的事务的SELECT命令

T6：提交txid=200的事务

T7：执行txid=201的事务的SELECT命令



图5.10 可见性检查场景一例

为了简化描述，假设这里只有两个事务，即txid=200和201的事务。

txid=200的事务的隔离级别是 READ COMMITTED，而 txid=201的事务

的隔离级别是 READ COMMITTED 或REPEATABLE READ。

我们将研究SELECT命令是如何为每条元组执行可见性检查的。

1.T3的SELECT命令。

在T3时间点，表tbl 中只有一条元组Tuple_1，按照规则6，这条元组

是可见的，因此两个事务中的SELECT命令都返回"Jekyll"。

规 则 6(Tuple_1) ⇒ Status(t_xmin:199) = COMMITTED ∧ t_xmax =

INVALID ⇒Visible





2.T5的SELECT命令。

首 先 来 看 一 下 由 txid=200 的 事 务 所 执 行 的 SELECT 命 令 。 根 据 规 则

7,Tuple_1不可见，根据规则2,Tuple_2可见，因此该SELECT命令返

回"Hyde"。

● 规 则 7(Tuple_1):Status(t_xmin:199) = COMMITTED ∧

Status(t_xmax:200)=

IN_PROGRESS

∧

t_xmax:200

=

current_txid:200 ⇒ Invisible

● 规 则 2(Tuple_2):Status(t_xmin:200) = IN_PROGRESS ∧

t_xmin:200 =current_txid:200 ∧ t_xmax = INVAILD ⇒ Visible 另一方面，在由txid=201的事务所执行的SELECT命令中，根据规则

8,Tuple_1可见，根据规则4,Tuple_2不可见，因此该SELECT命令返

回"Jekyll"。



● 规 则 8(Tuple_1):Status(t_xmin:199) = COMMITTED ∧

Status(t_xmax:200)=

IN_PROGRESS

∧

t_xmax:200

≠

current_txid:201 ⇒ Visible

● 规 则 4(Tuple_2):Status(t_xmin:200) = IN_PROGRESS ∧

t_xmin:200 ≠current_txid:201 ⇒ Invisible 如果更新的元组在本事务提交之前被其他事务看见，这种现象被称为

脏读，也称为写-读冲突。但如上所示，PostgreSQL中任何隔离级别都

不会出现脏读。

3.T7的SELECT命令。

下文描述了T7的SELECT命令在两个隔离级别中的行为。

首先来研究txid=201的事务处于READ COMMITTED隔离级别时的情况。

在这种情况下，txid=200的事务被视为已提交，因为在这个时间点获

取的事务快照是201:201:。因此Tuple_1根据规则10不可见，Tuple_2

根据规则6可见，SELECT命令返回"Hyde"。

● 规 则 10(Tuple_1):Status(t_xmin:199) = COMMITTED ∧

Status(t_xmax:200)= COMMITTED ∧ Snapshot(t_xmax:200) ≠

active ⇒ Invisible

● 规则6(Tuple_2):Status(t_xmin:200) = COMMITTED ∧ t_xmax =

INVALID ⇒Visible





这里需要注意，事务201中的SELECT命令，在txid=200的事务提交前后

中三个时段的执行结果是不一样的，这种现象通常被称作不可重复

读。

相反的是，当txid=201的事务处于REPEATABLE READ级别时，即使在T7

时刻，txid=200的事务实际上已经提交，它也必须被视作仍在进行，

因而获取到的事务快照是‘200:200:'。根据规则9,Tuple_1可见，根

据规则5,Tuple_2不可见，所以最后 SELECT 命令会返回"Jekyll"。请

注意，在REPEATABLE READ和SERIALIZABLE级别中不会发生不可重复

读。

● 规 则 9(Tuple_1):Status(t_xmin:199) = COMMITTED ∧

Status(t_xmax:200)= COMMITTED ∧ Snapshot(t_xmax:200) =

active ⇒ Visible

● 规 则 5(Tuple_2):Status(t_xmin:200) = COMMITTED ∧

Snapshot(t_xmin:200) = active ⇒ Invisible





提示位（Hint Bits）

PostgreSQL 在 内 部 提 供 了 三 个 函 数 TransactionIdIsInProgress 、

TransactionIdDidCommit和TransactionIdDidAbort，用于获取事务的

状态。这些函数被设计为尽可能减少对CLOG的频繁访问。尽管如此，

如果在检查每条元组时都执行这些函数，那么这里很可能会成为一个

性能瓶颈。

为了解决这个问题，PostgreSQL使用了提示位（hint bits），如下所

示。

在 读 取 或 写 入 元 组 时 ， PostgreSQL 会 择 机 将 提 示 位 设 置 到 元 组 的

t_informask字段中。举个例子，假设PostgreSQL检查了元组的t_xmin 对应事务的状态，结果为COMMITTED。在这种情况下，PostgreSQL会在

元组的t_infomask中置位一个HEAP_XMIN_COMMITTED标记，表示创建这

条元组的事务已经提交了。如果已经设置了提示位，则不再需要调用

TransactionIdDidCommit和TransactionIdDidAbort来获取事务状态。

因此PostgreSQL能高效地检查每个元组t_xmin和t_xmax对应事务的状

态。

5.7.2 PostgreSQL可重复读等级中的幻读

ANSI SQL-92标准中定义的REPEATABLE READ隔离等级允许出现幻读，

但PostgreSQL实现的REPEATABLE READ隔离等级不允许发生幻读。在原

则上，快照隔离中不允许出现幻读。

假设两个事务 Tx_A和Tx_B 同时运行。它们的隔离级别分别为 READ

COMMITTED和REPEATABLE READ，它们的txid分别为100和101。两个事

务一前一后接连开始，首先Tx_A插入一条元组，并提交。插入的元组

的t_xmin为100。接着，Tx_B执行SELECT命令，但根据规则5,Tx_A插入

的元组对Tx_B是不可见的，因此不会发生幻读。





规 则 5(new tuple):Status(t_xmin:100) = COMMITTED ∧

Snapshot(t_xmin:100) = active ⇒ Invisible 新元组由已提交的事务Tx_A创建，但Tx_A在Tx_B的事务快照中处于活

跃状态，因此根据规则5，新元组对Tx_B不可见。

5.8 防止丢失更新

丢失更新，又被称作写-写冲突，是事务并发更新同一行时所发生的异

常，REPEATABLE READ和SERIALIZABLE隔离等级必须阻止该异常的出

现。本节将会介绍PostgreSQL是如何防止丢失更新的，并举一些例子

来说明。





5.8.1 并发UPDATE命令的行为

执行UPDATE命令时，内部实际上调用了ExecUpdate函数。ExecUpdate 的伪代码如下所示：

伪代码：ExecUpdate



（1）获取被本UPDATE命令更新的每一行，并对每一行依次执行下列操

作。

（2）重复以下过程，直到目标行更新完成或本事务中止。

（ 3 ） 如 果 目 标 行 正 在 被 更 新 ， 则 进 入 步 骤 （ 4 ） ， 否 则 进 入 步 骤

（8）。

（4）等待正在更新目标行的事务结束，因为PostgreSQL在SI中使用了

以先更新者为准的方案。

（5）如果更新目标行的事务已经提交，且当前事务的隔离等级为可重

复读或可串行化则进入步骤（6），否则进入步骤（7）。

（6）中止本事务，以防止丢失更新。（因为另一个事务已经对目标行

进行了更新并提交。）

（7）跳转回步骤（2），并对目标行进行新一轮的更新尝试。

（8）如果目标行已被另一个并发事务所更新则进入步骤（9），否则

进入步骤（12）。

（9）如果当前事务的隔离级别为读已提交则进入步骤（10），否则进

入步骤（11）。

（10）更新目标行，并回到步骤（1），处理下一条目标行。

（11）中止当前事务，以防止丢失更新。

（12）更新目标行，并回到步骤（1），因为目标行尚未被修改，或者

虽然已经被更新，但更新它的事务已经结束。已中止的事务更新，即

存在写-写冲突。

此函数依次为每个待更新的目标行执行更新操作。它有一个外层循环

来更新每一行，而内部while循环则包含了三个分支，分支条件如图

5.11所示。



图5.11 ExecUpdate内部的三个分支

1.目标行正在被更新，如图5.11（1）所示。

“正在被更新”意味着该行正在被另一个事务同时更新，且另一个事

务尚未结束。在这种情况下，当前事务必须等待更新目标行的事务结

束，因为 PostgreSQL的 SI实现采用以先更新者为准的方案。例如，

假设事务Tx_A和Tx_B同时运行，且Tx_B尝试更新某一行，但Tx_A已更

新了这一行，且仍在进行中，在这种情况下Tx_B会等待Tx_A结束。

在更新目标行的事务提交后，当前事务的更新操作将完成等待继续进

行。如果当前事务处于READ COMMITTED隔离等级，则会更新目标行，

若处于REPEATABLE READ或SERIALIZABLE隔离等级时，当前事务则会立

即中止，以防止丢失更新。

2.目标行已经被另一个并发事务所更新，如图5.11（2）所示。

当前事务尝试更新目标元组，但另一个并发事务已经更新了目标行并

提交。在这种情况下，如果当前事务处于READ COMMITTED级别，则会

更新目标行，否则会立即中止以防止丢失更新。

3.没有冲突，如图5.11（3）所示。

当没有冲突时，当前事务可以直接更新目标行。





以先更新者为准/以先提交者为准

PostgreSQL基于SI的并发控制机制采用以先更新者为准的方案。相

反，如第5.9节所述，PostgreSQL的SSI实现使用以先提交者为准的方

案。

5.8.2 例子

以下是三个例子。第一个和第二个例子展示了目标行正在被更新时的

行为，第三个例子展示了目标行已经被更新的行为。

例1

事务Tx_A和Tx_B更新同一张表中的同一行，它们的隔离等级均为READ

COMMITTED。

Tx_B的执行过程如下：



1.在执行UPDATE命令之后，Tx_B应该等待Tx_A结束，因为目标元组正

在被Tx_A更新（ExecUpdate步骤4）。

2.在Tx_A提交后，Tx_B尝试更新目标行（ExecUpdate步骤7）。

3.在ExecUpdate内循环第二轮中，目标行被Tx_B更新（ExecUpdate步

骤2、步骤8、步骤9和步骤10）。

例2

Tx_A和Tx_B更新同一张表中的同一行，它们的隔离等级分别为读已提

交和可重复读。

Tx_B的执行过程如下：

1.Tx_B在执行UPDATE命令后阻塞，等待Tx_A终止（ExecUpdate的步骤

4）。





2.当Tx_A提交后，Tx_B会中止以解决冲突。因为目标行已经被更新，

且 当 前 事 务 Tx_B 的 隔 离 级 别 为 可 重 复 读 （ ExecUpdate 步 骤 5 、 步 骤

6）。

例3

Tx_B（可重复读）尝试更新已经被Tx_A 更新的目标行，且Tx_A 已经

提交。在这种情况下，Tx_B会中止（ExecUpdate中的步骤2、步骤8、

步骤9和步骤11）。





5.9 可串行化快照隔离

从 版 本 9.1 开 始 ， 可 串 行 化 快 照 隔 离 （ SSI ） 已 经 嵌 入 到 快 照 隔 离

（SI）中，用以实现真正的可串行化隔离等级。SSI解释起来过于复

杂，本书仅解释其概要，详细信息请参阅文献[2]。

下文使用了以下技术术语而未加定义。如果读者不熟悉这些术语，请

参阅文献[1、3]。

● 前趋图，亦称作依赖图或串行化图

● 串行化异常，例如写偏差

5.9.1 SSI实现的基本策略

如果前趋图中存在由某些冲突构成的环，则会出现串行化异常。这里

使用一种最简单的异常来解释，即写偏差。

图 5.12 （ 1 ） 展 示 了 一 种 调 度 方 式 。 Transaction_A 读 取 了

Tuple_B,Transaction_B 读 取 了 Tuple_A 。 然 后 Transaction_A 写

Tuple_A,Transaction_B写Tuple_B。在这种情况下存在两个读-写冲

突，它们在该调度的前趋图中构成了一个环，如图5.12（2）所示。故

该调度存在串行化异常，即写偏差。

图5.12 存在写偏差的调度及其前趋图





从概念上讲，存在三种类型的冲突，分别是写-读冲突（脏读）、写-写冲突（丢失更新）及读-写冲突。这里不用考虑写-读冲突与写-写冲

突，因为 PostgreSQL可以防止这两类冲突，所以PostgreSQL中的SSI 实现只需要考虑读-写冲突。

PostgreSQL在SSI实现中采用以下策略：

1.使用SIREAD锁记录事务访问的所有对象（元组、页面和关系）。

2.当写入任何堆元组/索引元组时，使用SIREAD锁检测读-写冲突。

3.如果从读-写冲突中检测出串行化异常，则中止事务。

5.9.2 PostgreSQL的SSI实现

为了实现上述策略，PostgreSQL实现了很多数据结构与函数。但这里

我们只会使用两种数据结构：SIREAD锁与读-写冲突来描述SSI机制。

它们都存储在共享内存中。

为 简 单 起 见 ， 本 文 省 略 了 一 些 重 要 的 数 据 结 构 ， 例 如

SERIALIZABLEXACT 。 因 此 对 CheckTargetForConflictOut 、

CheckTargetForConflictIn

和

PreCommit_CheckForSerialization

Failure等函数的解释也极为简化。比如本文虽然指出哪些函数能检测

到冲突，但并没有详细解释如何检测冲突。如果读者想了解详细信

息，请参阅源代码：predicate.c。

SIREAD锁

SIREAD 锁，在内部又被称为谓词锁，是一个由对象与（虚拟）事务标

识构成的二元组；这个二元组存储着哪个事务访问了哪个对象的相关

信息。注意，这里省略了对虚拟事务标识的描述，使用txid而非虚拟

txid能大幅简化说明。

在 SERIALIZABLE 模 式 下 只 要 执 行 DML 命 令 ， 就 会 通 过

CheckTargetForConflicts Out函数创建出SIREAD锁。举个例子，如果

txid=100 的 事 务 读 取 给 定 表 的 Tuple_1 ， 则 会 创 建 一 个 SIREAD 锁

{Tuple_1,{100}}。如果是其他事务，例如txid=101读取了Tuple_1，

则SIREAD锁会更新为{Tuple_1,{100,101}}。注意，读取索引页时也会





创建SIREAD锁，因为在使用了第7.2节中将描述的仅索引扫描时，数据

库只会读取索引页而不读取表页。

SIREAD锁有元组、页面及关系三个级别。如果单个页面内所有元组的

SIREAD锁都被创建，那么它们会聚合为该页上的单个SIREAD锁，原有

相关元组上的SIREAD锁都会被释放（删除），以减少内存空间占用。

对读取的页面也是如此。

当为索引创建SIREAD锁时，一开始会创建页级别的SIREAD锁。当使用

顺序扫描时，无论是否存在索引，是否存在WHERE子句，一开始都会创

建关系级别的SIREAD锁。注意，在某些情况下，这种实现可能会导致

串行化异常的误报，即假阳性，具体细节将在第5.9.4节中描述。

读-写冲突

读-写冲突是一个三元组，由SIREAD锁及两个分别读写该SIREAD锁的事

务txid构成。

当在可串行化模式下执行INSERT、UPDATE 或DELETE 命令时，函数

CheckTargetFor ConflictsIn 会被调用，并检查SIREAD锁来检测是否

存在冲突，如果有就创建一个读-写冲突。

举个例子，假设txid=100的事务读取了Tuple_1，然后txid=101的事务

更新了Tuple_1。在这种情况下，txid=101的事务中的 UPDATE 命令会

调用 CheckTargetForConflictsIn函数，并检测到在Tuple_1上存在

txid=100,101 之 间 的 读 - 写 冲 突 ， 并 创 建 rw-conflict {r= 100,w =

101,{Tuple_1}}。

CheckTargetForConflictOut、CheckTargetForConflictIn函数，以及

在 可 串 行 化 模 式 中 执 行 COMMIT 命 令 会 触 发 的

PreCommit_CheckForSerializationFailure函数，都会使用创建的读-写冲突来检查串行化异常。如果它们检测到异常，则只有先提交的事

务会真正提交，其他事务才会中止。

5.9.3 SSI的原理

本节将描述SSI如何解决写偏差异常，下面将使用一个简单的表tbl为

例。





事务Tx_A和Tx_B执行以下命令，如图5.13所示。

图5.13 写偏差场景一例

假设所有命令都使用索引扫描。当执行命令时，它们会同时读取堆元

组与索引页，每个索引页都包含指向相应堆元组的索引元组，如图

5.14所示。



图5.14 上述例子中索引与表的关系

索引和表的关系如下：

T1:Tx_A 执行 SELECT 命令，该命令读取堆元组 Tuple_2000，以及包

含主键的索引页Pkey_2。

T2:Tx_B执行SELECT命令，该命令读取堆元组Tuple_1，以及包含主键

的索引页Pkey_1。

T3:Tx_A执行UPDATE命令，更新Tuple_1。

T4:Tx_B执行UPDATE命令，更新Tuple_2000。

T5:Tx_A提交。

T6:Tx_B提交，然而由于写偏差异常而被中止。

图5.15展示了PostgreSQL如何检测和解决上述场景中描述的写偏差异

常。



图5.15 SIREAD锁与读-写冲突及图5.13场景中的调度

T1：执行Tx_A的SELECT命令时，CheckTargetForConflictsOut会创建

SIREAD锁。在本例中该函数会创建两个SIREAD锁：L1与L2。L1和L2分

别与Pkey_2和Tuple_2000相关联。

T2：执行Tx_B的SELECT命令时，CheckTargetForConflictsOut会创建

两个SIREAD锁：L3和L4。L3和L4分别与Pkey_1和Tuple_1相关联。

T3：执行 Tx_A 的 UPDATE 命令时，CheckTargetForConflictsOut和

CheckTarg etForConflictsIN 会 分 别 在 ExecUpdate 执 行 前 后 被 调

用 。 在 本 例 中 ， CheckTarget ForConflictsOut 什 么 都 不 做 。

CheckTargetForConflictsIn则会创建读-写冲突C1，这是Tx_B和Tx_A 在Pkey_1和Tuple_1上的冲突，因为Pkey_1和Tuple_1都由Tx_B读取并

被Tx_A写入。

T4：执行Tx_B的UPDATE命令时，CheckTargetForConflictsIn会创建

读-写冲突C2，这是Tx_A与Tx_B在Pkey_2和Tuple_2000上的冲突。

在这种情况下，C1和C2在前趋图中构成一个环，因此Tx_A和Tx_B 处于

不 可 串 行 化 状 态 。 但 事 务 Tx_A 和 Tx_B 都 尚 未 提 交 ， 因 此



CheckTargetForConflictsIn 不 会 中 止 Tx_B 。 注 意 ， 这 是 因 为

PostgreSQL的SSI实现采用先提交者为准方案。

T5

：

当

Tx_A

尝

试

提

交

时

，

将

调

用

PreCommit_CheckForSerializationFailure。此函数可以检测串行化

异常，并在允许的情况下执行提交操作。因为Tx_B仍在进行中，所以

Tx_A成功提交。

T6：当Tx_B 尝试提交时，PreCommit_CheckForSerializationFailure 检测到串行化异常，且Tx_A已经提交，因此Tx_B被中止。

此外，如果在Tx_A提交之后（T5时刻）,Tx_B执行了UPDATE命令，则

Tx_B 会 立 即 中 止 。 因 为 Tx_B 的 UPDATE 命 令 会 调 用

CheckTargetForConflictsIn，并检测到串行化异常，如图5.16（1）

所示。

如果Tx_B在T6时刻执行SELECT命令而不是COMMIT命令，则Tx_B也会立

即 中 止 。 因 为 Tx_B 的 SELECT 命 令 调 用 的

CheckTargetForConflictsOut 会检测到串行化异常，如图5.16（2）

所示。

图5.16 其他写偏差场景





www.wiki.postgresql.org解释了几种更为复杂的异常。

5.9.4 假阳性的串行化异常

在可串行化模式下，因为永远不会检测到假阴性（发生异常但未检测

到）串行化异常，PostgreSQL能始终完全保证并发事务的可串行性。

但是在某些情况下，可能会检测到假阳性异常（没有发生异常但误报

发生），用户在使用 SERIALIZABLE 模式时应牢记这一点。下文会描

述PostgreSQL检测到假阳性异常的情况。

图5.17展示了发生假阳性串行化异常的场景。

图5.17 发生假阳性串行化异常的场景

当使用顺序扫描时，如SIREAD锁的解释中所述，PostgreSQL创建了一

个关系级的SIREAD锁。图5.18（1）展示了PostgreSQL使用顺序扫描时

的SIREAD锁和读-写冲突。在这种情况下，产生了与tbl表上SIREAD锁



相关联的读-写冲突：C1和C2，它们在前趋图中构成了一个环。因此会

检测到假阳性的写偏差异常，如图5.18（2）所示。虽然实际上没有冲

突，但是Tx_A与Tx_B两者之一也将被中止。

图5.18 假阳性异常（1）——使用顺序扫描

即使使用索引扫描，如果事务Tx_A和Tx_B都获取了相同的索引SIREAD

锁，PostgreSQL也会误报假阳性异常。图5.19展示了这种情况。假设

索引页Pkey_1包含两条索引项，其中一条指向Tuple_1，另一条指向

Tuple_2。当Tx_A和Tx_B执行相应的SELECT和UPDATE命令时，Pkey_1同

时被Tx_A和Tx_B读取与写入。这时候会产生与Pkey_1相关联的读-写冲

突：C1和C2，并在前趋图中构成一个环，因而检测到假阳性写偏差异

常。如果Tx_A和Tx_B获取不同索引页上的SIREAD锁，则不会误报，并

且两个事务都可以提交。





图5.19 假阳性异常（2）——使用相同索引页的索引扫描

5.10 需要的维护进程

PostgreSQL的并发控制机制需要以下维护过程。

1.删除死元组及指向死元组的索引元组。

2.移除提交日志中非必要的部分。

3.冻结旧的事务标识。

4.更新FSM、VM及统计信息。

第5.3.2、5.4.3节分别解释了为什么需要第一个和第二个过程。第三

个过程与事务标识回卷问题有关，本小节将概述事务标识回卷问题。

在PostgreSQL中，清理过程负责这些过程。清理过程将在第6章中介

绍。



接下来将介绍事务标识回卷问题。

假设元组Tuple_1是由txid = 100事务创建的，即Tuple_1的t_xmin =

100。服务器运行了很长时间，但Tuple_1一直未曾被修改。假设txid 已经前进到了2 31 +100，这时候正好执行了一条SELECT命令。此时，因

为对当前事务而言txid = 100的事务属于过去的事务，所以Tuple_1对

当前事务可见。然后再执行相同的SELECT命令，此时txid步进至2 31

+101。但对当前事务而言，txid = 100的事务是属于未来的，因此

Tuple_1不再可见，如图5.20所示。这就是PostgreSQL中所谓的事务回

卷问题。

图5.20 回卷问题

为了解决这个问题，PostgreSQL 引入了一个冻结事务标识的概念，并

实现了一个名为FREEZE的过程。

在 PostgreSQL中定义了一个冻结的 txid，它是一个特殊的保留值

txid = 2，在参与事务标识大小比较时，它总是比所有其他 txid 都

旧。换句话说，冻结的 txid 始终处于非活跃状态，且其结果对其他

事务始终可见。





清理过程会调用冻结过程。冻结过程将扫描所有表文件，如果元组的

t_xmin比当前txid- vacuum_freeze_min_age（默认值为5000万）更

旧，则将该元组的t_xmin重写为冻结事务标识。在第6章中会有更详细

的解释。

举 个 例 子 ， 如 图 5.21 （ 1 ） 所 示 ， 当 前 txid 为 5000 万 ， 此 时 通 过

VACUUM 命 令 调 用 冻 结 过 程 。 在 这 种 情 况 下 ， Tuple_1 和 Tuple_2 的

t_xmin都被重写为2。

在版本9.4或更高版本中使用元组t_infomask 字段中的XMIN_FROZEN

标记位来标识冻结元组，而不是将元组的t_xmin重写为冻结的txid，

如图5.21（2）所示。

图5.21 冻结过程

参考文献

[1]Abraham

Silberschatz,Henry

F.Korth,and

S.Sudarshan,"Database

System

Concepts",McGraw-Hill

Education,ISBN-13:978-0073523323





[2]Dan R.K.Ports,and Kevin Grittner,"Serializable Snapshot Isolation in PostgreSQL",VDBL 2012

[3]Thomas

M.Connolly,and

Carolyn

E.Begg,"Database

Systems",Pearson,ISBN-13:978-0321523068

第6章 清理过程

清理过程（通常简称为VACUUM）是一种维护过程，有助于PostgreSQL

的持久运行。它的两个主要任务是删除死元组，以及冻结事务标识，

两者都在第5.10节中简要提及。

为了移除死元组，清理过程有两种模式，分别是并发清理与完整清

理。清理过程会删除表文件每个页面中的死元组，而其他事务可以在

其运行时继续读取该表。相反，完整清理不仅会移除整个文件中所有

的死元组，还会对整个文件中所有的活元组进行碎片整理。其他事务

在完整清理运行时无法访问该表。

尽管清理过程对PostgreSQL至关重要，但与其他功能相比，它的改进

相对其他功能而言要慢一些。例如在8.0版本之前，清理过程必须手动

执行（通过psql实用程序或使用cron守护进程）。直到2005年实现了

autovacuum守护进程时，这一过程才实现了自动化。

由 于 清 理 过 程 涉 及 全 表 扫 描 ， 因 此 该 过 程 代 价 高 昂 。 在 版 本

8.4（2009）中引入了可见性映射（Visibility Map,VM）来提高移除

死元组的效率。在版本9.6（2016）中增强了VM，从而改善了冻结过程

的表现。

第6.1节概述了并发清理的过程，后续部分的内容如下所示：

● 可见性映射

● 冻结过程

● 移除不必要的CLOG文件

● 自动清理守护进程





● 完整清理

6.1 并发清理概述

清理过程为指定的表或数据库中的所有表执行以下任务。

1.移除死元组。

● 移除每一页中的死元组，并对每一页内的活元组进行碎片整理。●

移除指向死元组的索引元组。

2.冻结旧的事务标识。

● 如有必要，冻结旧元组的事务标识。

● 更 新 与 冻 结 事 务 标 识 相 关 的 系 统 视 图 （ pg_database 与

pg_class）。

● 如果可能，移除不必要的提交日志文件。

3.其他。

● 更新已处理表的空闲空间映射（FSM）和可见性映射（VM）。

● 更新一些统计信息（pg_stat_all_tables等）。

这里假设读者已经熟悉以下术语：死元组、冻结事务标识、FSM、

CLOG。如果读者不熟悉这些术语的含义，请参阅第5章。VM将在第6.2

节中介绍。

以下伪代码描述了清理的过程。

伪码：并发清理





上面的伪代码意思分别为：

（1）从指定的表集中依次处理每一张表。





（2）获取表上的ShareUpdateExclusiveLock锁，此锁允许其他事务对

该表进行读取。

（3）扫描表中所有的页面，以获取所有的死元组，并在必要时冻结旧

元组。

（4）删除指向相应死元组的索引元组（如果存在）。

（5）对表的每个页面执行步骤（6）和（7）中的操作。

（6）移除死元组，并重新分配页面中的活元组。

（7）更新目标表对应的FSM与VM。

（8）如果最后一个页面没有任何元组，则截断最后一页。

（9）更新与目标表清理过程相关的统计数据和系统视图。

（10）更新与清理过程相关的统计数据和系统视图。

（11）如果可能，移除CLOG中非必要的文件与页面。

该伪码分为两大块：一块是依次处理表的循环，一块是后处理逻辑。

而循环块又分为三个部分，每一个部分都有各自的任务。接下来会描

述这三个部分及后处理的逻辑。

6.1.1 第一部分

这一部分执行冻结处理，并删除指向死元组的索引元组。

首先，PostgreSQL扫描目标表以构建死元组列表，如果可能的话，还

会冻结旧元组。该列表存储在本地内存中的 maintenance_work_mem 里（维护用的工作内存）。冻结过程将在第6.3节中介绍。

扫描完成后，PostgreSQL根据构建得到的死元组列表来删除索引元

组。该过程在内部被称为“清除阶段”。不用说，该过程代价高昂。

在10.0或更低版本中始终会执行清除阶段。在11.0或更高版本中，如

果 目 标 索 引 是 B 树 ， 是 否 执 行 清 除 阶 段 由 配 置 参 数





vacuum_cleanup_index_scale_factor决定。详细信息请参考此参数的

说明。

当maintenance_work_mem已满，且未完成全部扫描时，PostgreSQL继

续进行后续任务，即步骤（4）到（7），完成后再重新返回步骤（3）

并继续扫描。

6.1.2 第二部分

这一部分会移除死元组，并逐页更新FSM和VM。图6.1展示了一个例

子：

图6.1 删除死元组

假设该表包含三个页面，首先关注0号页面（即第一个页面），该页面

包含三条元组，其中Tuple_2是一条死元组，如图6.1（1）所示。在这

里PostgreSQL移除了Tuple_2，并重排剩余元组来整理碎片空间，然后

更新该页面的FSM和VM，如图6.1（2）所示。PostgreSQL不断重复该过

程直至最后一页。

注意，非必要的行指针是不会被移除的，它们会在将来被重用。因为

如果移除了行指针，就必须同时更新所有相关索引中的索引元组。





6.1.3 第三部分

第三部分会针对每个表，更新与清理过程相关的统计信息和系统视

图。

此外，如果最后一页中没有元组，则该页会从表文件中被截断。

6.1.4 后续处理

当处理完成后，PostgreSQL会更新与清理过程相关的几个统计数据，

以及相关的系统视图；如果可能的话，它还会移除部分不必要的CLOG

文件，见第6.4节。

清理过程将使用在第8.5节中描述的环形缓冲区，因此处理过的页面不

会缓存在共享缓冲区中。

6.2 可见性映射

清理过程的代价高昂，因此PostgreSQL在8.4版中引入了可见性映射

（VM），用于减少清理的开销。

VM 的基本概念很简单。每个表都拥有各自的可见性映射，用于保存表

文件中每个页面的可见性。页面的可见性确定了每个页面是否包含死

元组。清理过程可以跳过没有死元组的页面。

图6.2展示了VM的使用方式。假设该表包含三个页面，第0页和第2页包

含死元组，而第1页不包含死元组。表的可见性映射中保存着那些页面

包含死元组的信息。在这种情况下，清理过程可以参考VM中的信息，

跳过第一个页面。





图6.2 VM的使用方式

每个 VM 由一个或多个8 KB 页面组成，文件以后缀_vm 保存。例如，

一 个 表 文 件 的 relfilenode 是 18751 ， 其 FSM （ 18751_fsm ） 和

VM（18751_vm）文件如下所示。

可见性映射在9.6版中进行了加强，以提高冻结处理的效率。新的 VM

除了显示页面可见性之外，还包含了页面中元组是否全部冻结的信

息，参见第6.3.3节。

6.3 冻结过程





冻结过程有两种模式，依特定条件而择其一执行。为方便起见，我们

将这两种模式分别称为惰性模式和迫切模式。

并发清理通常在内部被称为“惰性清理”。但是，本文中定义的惰性

模式是冻结过程执行的模式。

冻结过程通常以惰性模式运行，但当满足特定条件时，也会以迫切模

式运行。在惰性模式下，冻结过程仅使用目标表对应的VM扫描包含死

元组的页面。迫切模式相则反，它会扫描所有的页面，无论其是否包

含死元组，都会更新与冻结过程相关的系统视图，并在可能的情况下

删除不必要的CLOG文件。

第6.3.1、6.3.2节分别描述了这两种模式，第6.3.3节描述了改进后的

迫切模式冻结过程。

6.3.1 惰性模式

当 开 始 冻 结 处 理 时 ， PostgreSQL 计 算 freezeLimit_txid ， 并 冻 结

t_xmin 小于freezeLimit_txid的元组。

freezeLimit_txid定义如下：

freezeLimit_txid=(OldestXmin-vacuum_freeze_min_age) OldestXmin 是当前正在运行的事务中最早的事务标识。举个例子，如

果在执行 VACUUM命令时，还有其他三个事务正在运行，且其txid分别

为100、101和102，那么OldestXmin就是100。如果不存在其他事务，

OldestXmin 就 是 执 行 此 VACUUM 命 令 的 事 务 标 识 。 这 里

vacuum_freeze_min_age是一个配置参数（默认值为50 000 000）。

图6.3给出了一个具体的例子。Table_1由三个页面组成，每个页面包

含三条元组。执行VACUUM命令时，当前txid为50 002 500且没有其他

事 务 。 在 这 种 情 况 下 ， OldestXmin 就 是 50 002 500 ， 因 此

freezeLimit_txid为2500。冻结过程按照如下步骤执行。





图6.3 冻结元组——惰性模式

第0页：

三 条 元 组 被 冻 结 ， 因 为 所 有 元 组 的 t_xmin 值 都 小 于

freezeLimit_txid。此外，因为Tuple_1是一条死元组，所以在该清理

过程中被移除。

第1页：

通过引用可见性映射（从VM中发现该页面所有元组都可见），清理过

程跳过了对该页面的清理。

第2页：

Tuple_7和Tuple_8被冻结，且Tuple_7被移除。

在 完 成 清 理 过 程 之 前 ， 与 清 理 相 关 的 统 计 数 据 会 被 更 新 ， 例 如

pg_stat_all_tables 视 图 中 的 n_live_tup 、 n_dead_tup 、

last_vacuum、vacuum_count等字段。

如上例所示，因为惰性模式可能会跳过页面，它可能无法冻结所有需

要冻结的元组。

6.3.2 迫切模式

迫切模式弥补了惰性模式的缺陷。它会扫描所有页面，检查表中的所

有元组，更新相关的系统视图，并在可能时删除不必要的CLOG文件与

页面。

当满足以下条件时，会执行迫切模式。

pg_database.datfrozenxid<(OldestXmin-vacuum_freeze_table_age)

在 上 面 的 条 件 中 ， pg_database.datfrozenxid 是 系 统 视 图

pg_database 中的列，并保存着每个数据库中最老的已冻结的事务标

识 ， 细 节 将 在 后 面 描 述 。 这 里 我 们 假 设 所 有

pg_database.datfrozenxid的值都是1821（这是在9.5版本中安装新数

据库集群之后的初始值）。vacuum_freeze_table_age是配置参数（默

认为150 000 000）。

图6.4给出了一个具体的例子。在表1中，Tuple_1和Tuple_7都已经被

删除，Tuple_10和Tuple_11则已经插入第2页中。执行VACUUM 命令时

的事务标识为150 002 000，且没有其他事务。因此，OldestXmin=150

002 000,freezeLimit_txid=100 002 000。在这种情况下满足了上述

条件：因为1821 < (150 002 000 - 150 000 000)，所以冻结过程会

以迫切模式执行，如下所示。

注意，这里是9.5或更低版本的行为，最新版本的行为将在第6.3.3节

中描述。



图6.4 冻结旧元组——迫切模式（9.5或更低版本）

第0页：

即使所有元组都被冻结，也会检查Tuple_2和Tuple_3。

第1页：

此页面中的三条元组都会被冻结，因为所有元组的 t_xmin 值都小于

freezeLimit_txid。注意，在惰性模式下会跳过此页面。

第2页：

将Tuple_10冻结，而Tuple_11没有冻结。

冻结一张表后，目标表的pg_class.relfrozenxid将被更新。pg_class 是一个系统视图，每个pg_class.relfrozenxid列都保存着相应表的最

近冻结的事务标识。本例中表1的pg_class.relfrozenxid会被更新为

当前的freezeLimit_txid（即100 002 000），这意味着表1中t_xmin 小于100 002 000的所有元组都已被冻结。



在完成清理过程之前，必要时会更新pg_database.datfrozenxid。每

个 pg_database.datfrozenxid 列 都 包 含 相 应 数 据 库 中 的 最 小

pg_class.relfrozenxid。如果在迫切模式下仅仅对表1做冻结处理，

则不会更新该数据库的pg_database.datfrozenxid，因为其他关系的

pg_class.relfrozenxid（当前数据库可见的其他表和系统视图）还没

有发生变化，如图6.5（1）所示。如果当前数据库中的所有关系都以

迫切模式冻结，则数据库的pg_database.datfrozenxid 就会被更新，

因为此数据库的所有关系的 pg_class.relfrozenxid 都被更新为当前

的freezeLimit txid，如图6.5（2）所示。

图6.5 pg_database.datfrozenxid与pg_class.relfrozenxid之间的关系



如何显示pg_class.relfrozenxid与pg_database.datfrozenxid 如 下 所 示 ， 第 一 个 查 询 显 示 testdb 数 据 库 中 所 有 可 见 关 系 的

relfrozenxid ， 第 二 个 查 询 显 示 testdb 数 据 库 的

pg_database.datfrozenxld。





FREEZE选项

带有FREEZE选项的VACUUM命令会强制冻结指定表中的所有事务标识。

虽然这是在迫切模式下执行的，但是这里 freezeLimit 会被设置为

OldestXmin 而不是 OldestXmin vacuum_freeze_min_age。例如，当

txid=5000的事务执行VACUUM FULL命令，且没有其他正在运行的事务

时，OldesXmin会被设置为5000，而t_xmin小于5000的元组将会被冻

结。

6.3.3 改进迫切模式中的冻结过程

9.5或更低版本中的迫切模式效率不高，因为它始终会扫描所有页面。

比如在第6.3.2节的例子中，尽管第0页中所有元组都被冻结，但还是

会被扫描。

为了解决这一问题，9.6版本改进了可见性映射VM与冻结过程。如第

6.2.1节所述，新VM包含着每个页面中所有元组是否都已被冻结的信

息。在迫切模式下进行冻结处理时，可以跳过仅包含冻结元组的页

面。

图6.6给出了一个例子。根据VM中的信息，冻结此表时会跳过第0页。

在更新完1号页面后，相关的VM信息会被更新，因为该页中所有的元组

都已经被冻结了。

图6.6 冻结旧元组——迫切模式（9.6或更高版本）



6.4 移除不必要的CLOG文件

如5.4节中所述，CLOG存储着事务的状态。当更新pg_database.datfro zenxid时，PostgreSQL会尝试删除不必要的CLOG文件。注意，相应的

CLOG页面也会被删除。

图 6.7 给 出 了 一 个 例 子 。 如 果 CLOG 文 件 0002 中 包 含 最 小 的

pg_database.datfro zenxid，则可以删除旧文件（0000和0001），因

为存储在这些文件中的所有事务在整个数据库集簇中已经被视为冻结

了。

图6.7 删除不必要的CLOG文件和页面

pg_database.datfrozenxid与CLOG文件

下面展示了pg_database.datfrozenxid与CLOG文件的实际输出：





6.5 自动清理守护进程

自动清理守护进程已经将清理过程自动化，因此PostgreSQL运维起来

非常简单。

自动清理守护程序周期性地唤起几个autovacuum_worker进程，默认情

况下每分钟唤醒一次（由参数autovacuum_naptime定义），每次唤起

三个工作进程（由autovacuum_max_works定义）。

自动清理守护进程唤起的autovacuum工作进程会依次对各个表执行并

发清理，从而将对数据库活动的影响降至最低。

关于如何维护AUTOVACUUM





参考文章：“PostgreSQL中的Autovacuum调参和Autovacuum内幕”

6.6 完整清理

虽然并发清理对于运维至关重要，但光有它还不够。比如，即使删除

了许多死元组，也无法压缩表大小的情况。

图6.8给出了一个极端的例子。假设一个表由三个页面组成，每个页面

包含6条元组。执行以下DELETE命令以删除元组，并执行VACUUM命令以

移除死元组。

图6.8 并发清理的缺陷示例

死元组虽然都被移除了，但表的尺寸没有减小。这种情况既浪费了磁

盘空间，又会对数据库性能产生负面影响。例如在上面的例子中，当



读取表中的三条元组时，必须从磁盘加载三个页面。

为了解决这种问题，PostgreSQL提供了完整清理模式。图6.9概述了该

模式。

图6.9 完整清理模式概述

1.创建新的表文件：见图6.9（1）。

当 对 表 执 行 VACUUM FULL 命 令 时 ， PostgreSQL 首 先 获 取 表 上 的

AccessExclusiveLock 锁 ， 并 创 建 一 个 大 小 为 8 KB 的 新 的 表 文 件 。

AccessExclusiveLock 锁不允许其他的任何访问。

2.将活元组复制到新表：见图6.9（2）。

PostgreSQL只将旧表文件中的活元组复制到新表中。

3.删除旧文件，重建索引并更新统计信息FSM和VM，见图6.9（3）。



复制完所有活元组后，PostgreSQL将删除旧文件，重建所有相关的表

索引，更新表的FSM和VM，并更新相关的统计信息和系统视图。

完整清理的伪代码如下所示。

伪代码：完整清理

使用VACUUM FULL命令时，应当考虑两点。

1.当执行完整清理时，没有人可以访问（读/写）表。

2.最多会临时使用两倍于表的磁盘空间；因此在处理大表时，有必要

检查剩余磁盘容量。

什么时候该使用VACUUM FULL



不幸的是，并没有关于什么时候该执行 VACUUM FULL 的最佳实践。但

是扩展pg_freespacemap可能会给出很好的建议。

以下查询给出了表的平均空间空闲率。

从上面的结果可以看出，没有多少空闲空间。

如果删除几乎所有的元组，并执行VACUUM命令，则可以发现每个页面

几乎都是空的。





以下查询检查特定表中每个页面的自由空间占比。





执行VACUUM FULL后会发现表被压实了。

第7章 堆内元组和仅索引扫描

本章将介绍两个和索引扫描有关的特性，分别是堆内元组（heap only tuple,HOT）和仅索引扫描。

7.1 堆内元组





在8.3版本中实现的HOT特性，使得更新行的时候，可以将新行放置在

旧行所处的同一个数据页中，从而高效地利用索引与表的数据页。HOT

特性减少了不必要的清理过程。

在源码的README.HOT中有关于HOT的详细介绍，本章只是简单地介绍

HOT。首先，第7.1.1节描述了在没有HOT特性的时候，更新一行是一个

怎样的过程，以阐明要解决的问题。接下来，在第7.1.2中将介绍HOT

做了什么。

7.1.1 没有HOT时的行更新

假设表tbl有两个列：id和data,id是tbl的主键。

表tbl有1000条元组，最后一个元组的id是1000，存储在第5个数据页

中。最后一条元组被相应的索引元组所引用，索引元组的key是1000，

且tid是(5,1)，如图7.1（1）所示。





图7.1 没有HOT的行更新

我们考虑一下，没有HOT特性时，最后一个元组是如何更新的。

在该场景中，PostgreSQL不仅要插入一条新的表元组，还需要在索引

页中插入新的索引元组，如图7.1（2）所示。索引元组的插入消耗了

索引页的空间，而且索引元组的插入和清理都是开销很大的操作。HOT

的目的，就是降低这种影响。

7.1.2 HOT如何工作

当使用 HOT 特性更新行时，如果被更新的元组存储在老元组所在的页

面中，PostgreSQL就不会再插入相应的索引元组，而是分别设置新元

组的HEAP_ONLY_TUPLE标记位与老元组的HEAP_HOT_UPDATED 标记位，

两个标记位都保存在元组的 t_informask2字段中，如图7.2和图7.3所

示。





比 如 在 这 个 例 子 中 ， Tuple_1 和 Tuple_2 分 别 被 设 置 成

HEAP_HOT_UPDATED和HEAP_ONLY_TUPLE。

另 外 ， 在 修 剪 和 碎 片 整 理 处 理 过 程 中 ， 都 会 使 用 下 面 介 绍 的

HEAP_HOT_UPDATED和HEAP_ONLY_TUPLE标记位。

图7.2 HOT的行更新



图7.3 HEAP_HOT_UPDATED和HEAP_ONLY_TUPLE标记位

接下来会介绍，当基于HOT更新一个元组后，PostgreSQL是如何在索引

扫描中访问这些被HOT更新的元组的，如图7.4（1）所示。

图7.4 行指针修剪

（1）找到指向目标数据元组的索引元组。

（2）按所获索引元组指向的位置访问行指针数组，找到行指针1。

（3）读取Tuple_1。

（4）经由Tuple_1的t_ctid字段，读取Tuple_2。

在 这 种 情 况 下 ， PostgreSQL 会 读 取 两 条 元 组 ， 分 别 是 Tuple_1 和

Tuple_2，并通过第5章所述的并发控制机制来判断哪条元组是可见

的。但如果数据页中的死元组已经被清理，就有问题了。比如在图

7.4（1）中，如果 Tuple_1由于是死元组而被清理，就无法通过索引

访问Tuple_2了。



为了解决这个问题，PostgreSQL会在合适的时候进行行指针重定向，

将指向老元组的行指针重新指向新元组的行指针。在PostgreSQL中，

这个过程称为修剪。图7.4（2）说明了PostgreSQL在修剪之后如何访

问更新的元组。

1.找到索引元组。

2.通过索引元组，找到行指针1。

3.通过重定向的行指针1，找到行指针2。

4.通过行指针2，读取Tuple_2。

可能的话，剪枝任何时候都有可能会发生，比如 SELECT 、UPDATE、

INSERT 、DELETE这类SQL命令执行的时候，确切的执行时机不会在本

章中描述，因为它太复杂了。具体细节可以在README.HOT文件中找

到。

在 PostgreSQL 执行剪枝时，如果可能，会挑选合适的时机来清理死

元组。在 PostgreSQL中，这种操作称为碎片整理，图7.5描述了HOT中

死元组的碎片整理过程。

图7.5 死元组的碎片整理

需要注意的是，因为碎片整理的工作并不涉及索引元组的移除，所以

碎片整理比起常规的清理开销要少得多。

因此，HOT特性降低了索引和表的空间消耗，同样减少了清理过程需要

处理的元组数量。由于减少了更新操作需要插入的索引元组数量，并

减少了清理操作需要处理的元组数量，HOT对于性能提高有良好的促进

作用。

HOT不可用的场景

为了清晰地理解HOT的工作，下面介绍一些HOT不可用的场景。

1.当更新的元组在其他的页面时，即和老元组不在同一个数据页中

时，指向该元组的索引元组也会被添加至索引页中，如图7.6（1）所

示。

2.当索引的键更新时，会在索引页中插入一条新的索引元组，如图

7.6（2）所示。





图7.6 HOT不适用的情况

pg_stat_all_tables视图提供了每个表的统计信息视图，也可以参考

这个扩展。

7.2 仅索引扫描

当SELECT 语句的所有目标列都在索引键中时，为了减少I/O代价，仅

索引扫描（又叫仅索引访问）会直接使用索引中的键值。所有商业关

系型数据库中都提供这个技术，比如DB2和Oracle。PostgreSQL在9.2

版本中引入这个特性。

接下来我们会基于一个特殊的例子，介绍PostgreSQL中仅索引扫描的

工作过程。



首先是关于这个例子的假设。

● 表定义

我们有一个tbl表，其定义如下所示：

● 索引

表tbl有一个索引tbl_idx，包含id和name两列。

● 元组

tbl已经插入了一些元组。

id=18,name = 'Queen’的Tuple_18存储在0号数据页中。

id=19,name = 'BOSTON’的Tuple_19存储在1号数据页中。

● 可见性

所有在0号页面中的元组永远可见，1号页面中的元组并不总是可见

的。注意，每个页的可见性信息都存储在相应的可见性映射中，关于

可见性映射的描述可以参考第6.2节。



我们来研究一下，当下面的SELECT语句执行时，PostgreSQL是如何读

取元组的。

查询需要从表中读取id和name两列，索引tbl_idx包含了这些列。因此

在使用索引扫描时，第一眼看上去好像访问表的页面是没有必要的，

因为索引中已经包含了必要的数据。然而原则上，PostgreSQL有必要

检查这些元组的可见性，索引元组中并没有任何关于堆元组的事务相

关信息，比如t_xmin和t_xmax，详细参考第5章。因此，PostgreSQL需

要访问表数据来检查索引元组中数据的可见性，这就有点本末倒置

了。

面对这种困境，PostgreSQL使用目标数据表对应的可见性映射表来解

决此问题。如果某一页中存储所有的元组都是可见的，PostgreSQL就

会使用索引元组，而不去访问索引元组指向的数据页去检查可见性，

否则，PostgreSQL读取索引元组指向的数据元组并检查元组可见性，

而这就跟原来设想的一样。

在这个例子中，因为的0号页面被标记为可见，因此0号页面中存储的

包 括 Tuple_18 在 内 的 所 有 元 组 都 是 可 见 的 ， 所 以 就 不 用 再 去 访 问

Tuple_18了。相应地，因为1号页面并没有被标记为可见，此时为了检

查并发控制的可见性，需要访问Tuple_19，如图7.7所示。





图7.7 仅索引扫描的工作过程

第8章 缓冲区管理器

缓冲区管理器管理着共享内存和持久存储之间的数据传输，对于数据

库管理系统的性能有着重要的影响。PostgreSQL的缓冲区管理器十分

高效。





本章介绍了PostgreSQL的缓冲区管理器。图8.1展示了缓冲区管理器存

储和后端进程之间的关系，后续的章节分别介绍以下内容：

● 缓冲区管理器的结构

● 缓冲区管理器的锁

● 缓冲区管理器的工作原理

● 环形缓冲区

● 脏页刷盘

图8.1 缓冲区管理器存储和后端进程之间的关系

8.1 概览

接下来介绍一些关键概念，以助于读者理解后续章节。

1.缓冲区管理器的结构

PostgreSQL缓冲区管理器由缓冲表、缓冲区描述符和缓冲池组成，这

几个组件将在接下来的小节中介绍。缓冲池层存储着数据文件页面，

诸如表页与索引页，以及其相应的自由空间映射和可见性映射的页

面。缓冲池是一个数组，数据的每个槽中存储数据文件的一页。缓冲

池数组的序号索引称为buffer_id。第8.2、8.3节描述了缓冲区管理器

的内部细节。

2.缓冲区标签

PostgreSQL中的每个数据文件页面都可以分配到唯一的标签，即缓冲

区标签。当缓冲区管理器收到请求时，PostgreSQL会用到目标页面的

缓冲区标签。

其中，关系文件节点用于定位页面所属的关系，关系分支编号用于定

位关系文件的具体分支文件，页面块号则在具体分支文件中指明相应

页面的偏移量。一个关系可能有三种分支，分别是关系主体（main分

支，编号为0）、空闲空间映射（fsm分支，编号为1）及可见性映射

（vm分支，编号为2）。

缓冲区标签由三个值组成，分别是关系文件节点、关系分支编号和页

面块号。第一个值分别代表了表空间、数据库和表的oid；第二个值代

表关系表的分支号；最后一个值代表页面号。那么该标签表示，在某

个 表 空 间 （ oid=16821 ） 中 ， 某 个 数 据 库 （ oid=16384) 的 某 张 表

（oid=37721）的0号分支（0代表关系表本体）的第7号页面。再比

如，缓冲区标签{(16821,16384,37721),1,3}表示该表空闲空间映射文

件的三号页面。关系本体main分支编号为0，空闲空间映射fsm分支编

号为1。





3.后端进程如何读取数据页

本节描述了后端进程如何从缓冲区管理器中读取数据页，如图8.2所

示。

图8.2 后端进程如何读取数据页

（1）当读取表或索引页时，后端进程向缓冲区管理器发送请求，请求

中带有目标页面的buffer_tag。

（2）缓冲区管理器会根据 buffer_tag 返回一个 buffer_id，即目标

页面存储在数组中的槽位的序号。如果请求的页面没有存储在缓冲池

中，那么缓冲区管理器会将页面从持久存储位置加载到其中一个缓冲

池槽位中，然后再返回该槽位的buffer_id。

（3）后端进程访问buffer_id对应的槽位（以读取所需的页面）。

当后端进程修改缓冲池中的页面时（例如向页面插入元组），这种尚

未刷新到持久存储，但已被修改的页面被称为脏页。

第8.4节将描述缓冲区管理器的工作原理。

4.页面置换算法





当所有缓冲池槽位都被占用，且其中未包含所请求的页面时，缓冲区

管理器必须在缓冲池中选择一个页面逐出，用于放置被请求的页面。

在计算机科学领域中，选择页面的算法通常被称为页面置换算法，而

所选择的页面被称为受害者页面。

自从计算机科学出现以来，针对页面置换算法的研究就一直在进行，

先前已经提出很多置换算法。从8.1版本开始，PostgreSQL使用时钟扫

描算法，比起以前版本中使用的LRU算法，更为简单高效。

第8.4.4节将描述时钟扫描的细节。

5.脏页刷盘

脏页最终应该被刷入存储，但缓冲区管理器执行这个任务需要额外帮

助。在PostgreSQL中，检查点进程和后台写入器这两个后台进程负责

此任务。

第8.6节将描述检查点进程和后台写入器。

直接I/O

PostgreSQL并不支持直接I/O，但有时会讨论它。如果你想了解更多详

细信息，可以参考https://lwn.net/Articles/580542/这篇文章，以

及pgsql-ML中的讨论，详见https://www.postgr esql.org/message-id/529E267F.4050700@agliodbs.com。

8.2 缓冲区管理器的结构

PostgreSQL缓冲区管理器由三层组成，即缓冲表层、缓冲区描述符层

和缓冲池层，如图8.3所示。

● 缓冲表层是一个散列表，它存储着页面的buffer_tag 与描述符的

buffer_id 之间的映射关系。

● 缓冲区描述符层是一个由缓冲区描述符组成的数组。每个描述符与

缓冲池槽一一对应，并保存着相应槽的元数据。请注意，术语“缓冲

区描述符层”只是在本章中为方便起见而使用的术语。





● 缓冲池层是一个数组。每个槽都存储一个数据文件页，数组槽的索

引称为buffer_id。

图8.3 缓冲区管理器的三层结构

这些层将在以下内容中详细描述。

8.2.1 缓冲表

缓冲表可以在逻辑上分为三个部分，分别是散列函数、散列桶槽及数

据项，如图8.4所示。

内置散列函数将buffer_tag映射到哈希桶槽。即使散列桶槽的数量比

缓冲池槽的数量多，冲突也可能会发生。因此缓冲表采用了使用链表

的分离链接方法来解决冲突。当数据项被映射至同一个桶槽时，该方

法会将这些数据项保存在一个链表中，如图8.4所示。





图8.4 缓冲表

数据项包括两个值，即页面的 buffer_tag和包含页面元数据的描述符

的 buffer_id。例如，数据项Tag_A,id=1 表示，在buffer_id=1对应

的缓冲区描述符中，存储着页面Tag_A的元数据。

散列函数

此处使用的散列函数由 calc_bucket()与 hash()组合而成。下面是用

伪函数表示的形式。

暂时还没有对诸如查找、插入、删除数据项的基本操作进行解释。这

些常见的操作将在后续小节详细描述。

8.2.2 缓冲区描述符

本节将描述缓冲区描述符的结构，第8.2.3节将描述缓冲区描述符层。

缓冲区描述符保存着页面的元数据，这些与缓冲区描述符相对应的页

面保存在缓冲池槽中。缓冲区描述符的结构由BufferDesc结构定义。

这个结构有很多字段，主要字段如下所示：





● tag 保存着目标页面的buffer_tag，该页面存储在相应的缓冲池槽

中，缓冲区标签的定义将在第8.1节给出。

● buffer_id 标 识 了 缓 冲 区 描 述 符 ， 亦 相 当 于 对 应 缓 冲 池 槽 的

buffer_id。

● refcount 保存当前访问相应页面的PostgreSQL进程数，也被称为

钉 数 。 当 PostgreSQL 进 程 访 问 相 应 页 面 时 ， 其 引 用 计 数 必 须 自 增

1（refcount ++）。访问结束后其引用计数必须减1（refcount--）。

当refcount为零，即页面当前并未被访问时，页面将取钉，否则它会

被钉住。

● usage_count 保存着相应页面加载至相应缓冲池槽后的访问次数。

usage_count会在页面置换算法中被用到，见第8.4.4节。

● context_lock和io_in_progress_lock 是轻量级锁，用于控制对相

关页面的访问。第8.3.2节将介绍这些字段。

● flags用于保存相应页面的状态，主要状态如下：

1.脏位指明相应页面是否为脏页。

2.有效位指明相应页面是否可以被读写（有效）。例如，如果该位被

设置为"valid"，那就意味着对应的缓冲池槽中存储着一个页面，而该

描述符中保存着该页面的元数据，因而可以对该页面进行读写。反之

如果有效位被设置为"invalid"，那就意味着该描述符中并没有保存任

何元数据，即对应的页面无法读写，缓冲区管理器可能正在将该页面

换出。

3.IO进行标记位指明缓冲区管理器是否正在从存储中读/写相应页面。

换句话说，该位指示是否有一个进程正持有此描述符上的io_in_pregr ess_lock。

● freeNext 是一个指针，指向下一个描述符，并以此构成一个空闲

列表（freelist），具体细节将在第8.2.3节中介绍。

结构BufferDesc定义于src/include/storage/buf_internals.h中。

为了简化后续章节的描述，这里定义三种描述符状态。

● 空：当相应的缓冲池槽不存储页面时，即refcount 与usage_count 都是0，该描述符的状态为空。

● 钉住：当相应缓冲池槽中存储着页面，且有 PostgreSQL 进程正在

访问的相应页面时，即refcount和usage_count都大于等于1，该缓冲

区描述符的状态为钉住。

● 未钉住：当相应的缓冲池槽存储页面，但没有PostgreSQL进程正在

访问相应页面时，即usage_count大于或等于1，但refcount为0，该缓

冲区描述符的状态为未钉住。

每个描述符都处于上述状态之一。描述符的状态会根据特定条件而改

变，这将在第8.2.3节中介绍。





缓冲区描述符的状态用方框表示。

● □空

● ■钉住

●

未钉住

此外，脏页面会带有“X”的标记。例如一个未钉住的脏描述符用

表示。

8.2.3 缓冲区描述符层

缓冲区描述符的集合构成了一个数组，本书称该数组为缓冲区描述符

层。

当 PostgreSQL服务器启动时，所有缓冲区描述符的状态都为空。在

PostgreSQL中，这些描述符构成了一个名为freelist的链表，缓冲区

管理器初始状态如图8.5所示。

图8.5 缓冲区管理器初始状态



注 意 ， PostgreSQL 中 的 freelist 完 全 不 同 于 Oracle 中 freelist 的 概

念。PostgreSQL的freelist只是空缓冲区描述符的链表。PostgreSQL

中与Oracle中的freelist相对应的对象是空闲空间映射（FSM），详见

第5.3.4节。

图8.6展示了第一个页面是如何加载的。

图8.6 加载第一页

（1）从freelist的头部取一个空描述符，并将其钉住，即将refcount 和usage_count增加1。

（2）在缓冲表中插入新项，该缓冲表项保存了页面buffer_tag与所获

描述符buffer_id之间的关系。

（3）将新页面从存储器加载至相应的缓冲池槽中。

（4）将新页面的元数据保存至所获取的描述符中。





第二页及后续页面都以类似方式加载，其他细节将在第8.4.2节中介

绍。

从freelist中摘出的描述符始终保存着页面的元数据。换言之，仍然

在使用的非空描述符不会返还到freelist中。但当下列任一情况出现

时，描述符状态将变为“空”，并被重新插入至freelist中。

1.相关表或索引已被删除。

2.相关数据库已被删除。

3.相关表或索引已经被VACUUM FULL命令清理。

为什么使用freelist来维护空描述符

保留freelist的原因是为了能立即获取一个描述符。这是内存动态分

配的常规做法，详情参阅https://en.wikipedia.org/wiki/Free_list 中的说明。

缓冲区描述符层包含着一个32位无符号整型变量 nextVictimBuffer。

此变量将用于第8.4.4节中的页面置换算法。

8.2.4 缓冲池

缓冲池只是一个用于存储关系数据文件（例如表或索引）页面的简单

数组。缓冲池数组的序号索引也就是buffer_id。

缓冲池槽的大小为8KB，等于页面大小，因而每个槽都能存储整个页

面。

8.3 缓冲区管理器锁

缓冲区管理器会出于不同的目的使用各式各样的锁，本节将介绍理解

后续部分所必备的一些锁。

注意，本节描述的锁，指的是缓冲区管理器同步机制的一部分。它们

与SQL语句和SQL操作中的锁没有任何关系。



8.3.1 缓冲表锁

BufMappingLock保护整个缓冲表的数据完整性。它是一种轻量级的

锁，有共享模式与独占模式。在缓冲表中查询条目时，后端进程会持

有共享的BufMappingLock。插入或删除条目时，后端进程会持有独占

的BufMappingLock。

BufMappingLock会被分为多个分区，以减少缓冲表中的争用（默认为

128个分区）。每个BufMappingLock分区都保护着一部分相应的散列桶

槽。

图8.7给出了一个BufMappingLock分区的典型示例。两个后端进程可以

同时持有各自分区的BufMappingLock独占锁，以插入新的数据项。如

果BufMappingLock是系统级的锁，那么其中一个进程就需要等待另一

个进程完成处理。

图8.7 两个进程同时获取相应分区的BufMappingLock独占锁，以插入新数据项





缓冲表也需要许多其他锁。例如，在缓冲表内部会使用自旋锁（spin lock）来删除数据项。不过本章不需要这些锁的其他相关知识，因此

这里省略了对其他锁的介绍。

在9.4版本之前，BufMappingLock在默认情况下被分为16个独立的锁。

8.3.2 缓冲区描述符相关的锁

每 个 缓 冲 区 描 述 符 都 会 用 到 内 容 锁 （ content_lock ） 与 IO 进 行 锁

（io_in_progress_lock）这两个轻量级锁，以控制对相应缓冲池槽页

面的访问。当检查或更改描述符本身字段的值时，就会用到自旋锁。

8.3.2.1 内容锁

内容锁（content_lock）是一个典型的强制限制访问的锁，它有共享

与独占两种模式。

当读取页面时，后端进程以共享模式获取页面相应缓冲区描述符中的

content_lock。

执行下列操作之一时，则会获取独占模式的content_lock。

● 将行（即元组）插入页面，或更改页面中元组的 t_xmin/t_xmax 字段时（t_xmin和t_xmax 在第5.2节中有过介绍，简单地说，这些字

段会在相关元组被删除或更新行时发生更改）。

● 物理移除元组，或压紧页面上的空闲空间（由清理过程和HOT执

行，分别在第6章和第7章中有过介绍）。

● 冻 结 页 面 中 的 元 组 （ 冻 结 过 程 在 第 5.10 节 与 第 6.3 节 中 有 过 介

绍）。

官方README文件包含更多的细节。

8.3.2.2 IO进行锁

IO 进行锁（io_in_progress_lock）用于等待缓冲区上的I/O完成。当

PostgreSQL进程加载/写入页面数据时，该进程在访问页面期间，持有

对应描述符上独占的 io_in_progres_lock。



8.3.2.3 自旋锁

当检查或更改标记字段与其他字段时，例如refcount和usage_count，

会用到自旋锁。下面是两个使用自旋锁的具体例子。

1.钉住缓冲区描述符。

（1）获取缓冲区描述符上的自旋锁。

（2）将其refcount和usage_count的值增加1。

（3）释放自旋锁。

2.将脏位设置为"1"。

（1）获取缓冲区描述符上的自旋锁。

（2）使用位操作将脏位置位为"1"。

（3）释放自旋锁。



其他标记位也是通过同样的方式来设置的。

用原子操作替换缓冲区管理器的自旋锁

在9.6版本中，缓冲区管理器的自旋锁被替换为原子操作，可以参考

https://commitfest.postgresql.org/9/408/中提交日志的内容。如

果

想

进

一

步

了

解

详

情

，

可

以

参

考

http://www.postgresql.org/message-id/flat/2400449.GjM57CE0Yg@dinodell#2400449.GjM57CE0Yg@dinode ll中的讨论。

附9.6版本中缓冲区描述符的数据结构定义。





8.4 缓冲区管理器的工作原理

本节介绍缓冲区管理器的工作原理。当后端进程想要访问所需页面

时，它会调用ReadBufferExtended函数。

函数 ReadBufferExtended 的行为因场景而异，在逻辑上具体可以分

为 三 种 情 况 。 每 种 情 况 都 将 用 一 小 节 介 绍 。 第 8.4.4 节 将 介 绍

PostgreSQL中基于时钟扫描的页面置换算法。

8.4.1 访问存储在缓冲池中的页面

当从缓冲池槽中的页面里读取行时，PostgreSQL 进程获取相应缓冲区

描述符的共享content_lock，因而缓冲池槽可以同时被多个进程读

取。

当向页面插入（及更新、删除）行时，该 postgres后端进程获取相应

缓冲区描述符的独占content_lock（注意，这里必须将相应页面的脏

位置设为"1"）。

访问完页面后，相应缓冲区描述符的引用计数值减1。

图8.8是访问存储在缓冲池中的页面示意图。





图8.8 访问存储在缓冲池中的页面

我们来介绍最简单的情况，即所需页面已经存储在缓冲池中。在这种

情况下，缓冲区管理器会执行以下步骤：

（ 1 ） 创 建 所 需 页 面 的 buffer_tag （ 在 本 例 中 buffer_tag 是’Tag_C'），并使用散列函数计算与描述符相对应的散列桶槽。

（2）获取相应散列桶槽分区上的BufMappingLock共享锁。

（3）查找标签为’Tag_C’的条目，并从条目中获取buffer_id。本例

中buffer_id为2。

（4）将 buffer_id=2的缓冲区描述符钉住，即将描述符的 refcount 和usage_count增加1。

（5）释放BufMappingLock。

（6）访问buffer_id=2的缓冲池槽。



8.4.2 将页面从存储加载到空槽

图8.9是将页面从存储加载到空槽的示意图。

图8.9 将页面从存储加载到空槽

在第二种情况下，假设所需页面不在缓冲池中，且freelist中有空闲

元素（空描述符）。这时，缓冲区管理器将执行以下步骤：

（1）查找缓冲区表（本节假设页面不存在，找不到对应页面）。





第一，创建所需页面的buffer_tag（本例中buffer_tag为’Tag_E'）

并计算其散列桶槽。

第二，以共享模式获取相应分区上的BufMappingLock。

第三，查找缓冲区表（根据假设，这里没找到）。

第四，释放BufMappingLock。

（2）从 freelist 中获取空缓冲区描述符，并将其钉住。在本例中所

获的描述符：buffer_id=4。

（ 3 ） 以 独 占 模 式 获 取 相 应 分 区 的 BufMappingLock （ 此 锁 将 在 步 骤

（6）中被释放）。

（

4

）

创

建

一

条

新

的

缓

冲

表

数

据

项

：

buffer_tag='Tag_E',buffer_id=4，并将其插入缓冲区表中。

（5）将页面数据从存储加载至buffer_id=4的缓冲池槽中，如下所

示：

第一，以排他模式获取相应描述符的io_in_progress_lock。

第二，将相应描述符的IO_IN_PROGRESS标记位设置为1，以防其他进程

访问。

第三，将所需的页面数据从存储加载到缓冲池插槽中。

第四，更改相应描述符的状态，将IO_IN_PROGRESS标记位设置为"0"，

且VALID标记位设置为"1"。

第五，释放io_in_progress_lock。

（6）释放相应分区的BufMappingLock。

（7）访问buffer_id=4的缓冲池槽。

8.4.3 将页面从存储加载到受害者缓冲池槽



在这种情况下，假设所有缓冲池槽位都被页面占用，且未存储所需的

页面。图8.10、图8.11是将页面从存储加载到受害者缓冲池槽的示意

图。

图8.10 将页面从存储加载到受害者缓冲池槽



图8.11 将页面从存储加载到受害者缓冲池槽（接图8.10）

缓冲区管理器将执行以下步骤：

（ 1 ） 创 建 所 需 页 面 的 buffer_tag 并 查 找 缓 冲 表 。 在 本 例 中 假 设

buffer_tag是’Tag_M'（且相应的页面在缓冲区中找不到）。

（2）使用时钟扫描算法选择一个受害者缓冲池槽位，从缓冲表中获取

包含着受害者槽位buffer_id的旧表项，并在缓冲区描述符层将受害者

槽位的缓冲区描述符钉住。本例中受害者槽的buffer_id=5，旧表项为

Tag_F,id = 5。时钟扫描将在下一节介绍。

（3）如果受害者页面是脏页，则将其刷盘（write & fsync），否则

进入步骤（4）。

在使用新数据覆盖脏页之前，必须将脏页写入存储中。脏页的刷盘步

骤如下：

第 一 ， 获 取 buffer_id=5 描 述 符 上 的 共 享 content_lock 和 独 占

io_in_progress_lock。

第 二 ， 更 改 相 应 描 述 符 的 状 态 ： 相 应 IO_IN_PROCESS 位 设 置

为"1",JUST_DIRTIED 位设置为"0"。

第三，根据具体情况，调用XLogFlush()函数将WAL缓冲区上的WAL数据

写入当前WAL段文件（WAL和XLogFlush函数将在第9章中介绍）。

第四，将受害者页面的数据刷盘至存储中。

第五，更改相应描述符的状态；将IO_IN_PROCESS位设置为"0"，将

VALID位设置为"1"。

第六，释放io_in_progress_lock和content_lock。

（ 4 ） 以 排 他 模 式 获 取 缓 冲 区 表 中 旧 表 项 所 在 分 区 上 的

BufMappingLock。

（5）获取新表项所在分区上的BufMappingLock，并将新表项插入缓冲

表：

第一，创建新表项：由buffer_tag='Tag_M’与受害者的buffer_id组

成的新表项。

第二，以独占模式获取新表项所在分区上的BufMappingLock。

第三，将新表项插入缓冲区表中。

（ 6 ） 从 缓 冲 表 中 删 除 旧 表 项 ， 并 释 放 旧 表 项 所 在 分 区 的

BufMappingLock。

（7）将目标页面数据从存储加载至受害者槽位，然后用 buffer_id=5

更新描述符的标识字段，将脏位设置为0，并按流程初始化其他标记

位。





（8）释放新表项所在分区上的BufMappingLock。

（9）访问buffer_id=5对应的缓冲区槽位。

8.4.4 页面替换算法：时钟扫描

本节的其余部分介绍了时钟扫描算法。该算法是NFU（Not Frequently Used）算法的变体，开销较少，能高效地选出较少使用的页面。

我们将缓冲区描述符想象为一个循环列表，如图8.12所示。缓冲区描

述 符 为 黑 色 或 灰 色 的 方 框 ， 框 中 的 数 字 显 示 每 个 描 述 符 的

usage_count。而 nextVictimBuffer 是一个32位的无符号整型变量，

它总是指向某个缓冲区描述符并按顺时针顺序旋转。

图8.12 时钟扫描

伪代码：时钟扫描



（1）获取nextVictimBuffer指向的候选缓冲区描述符。

（2）如果候选描述符未被钉住，则进入步骤（3），否则进入步骤

（4）。

（3）如果候选描述符的usage_count为0，则选择该描述符对应的槽作

为受害者，并进入步骤（5），否则将此描述符的usage_count减1，并

继续执行步骤（4）。

（4）将nextVictimBuffer迭代至下一个描述符（如果到末尾则回绕至

头部）并返回步骤（1），重复直到找到受害者。

（5）返回受害者的buffer_id。

该算法的伪代码与算法描述如下：

1.nextVictimBuffer 指向第一个描述符（buffer_id = 1），但因为

该描述符被钉住了，所以跳过。





2.extVictimBuffer指向第二个描述符（buffer_id = 2），该描述符

未被钉住，但其usage_count为2，因此该描述符的usage_count将减

1，而nextVictimBuffer迭代至第三个候选描述符。

3.nextVictimBuffer 指向第三个描述符（buffer_id = 3），该描述

符未被钉住，但其usage_count = 0，因而成为本轮的受害者。

当nextVictimBuffer扫过未钉住的描述符时，其usage_count会减1。

因此只要缓冲池中存在未钉住的描述符，该算法总能在旋转若干次

nextVictimBuffer 后，找到一个usage_count为0的受害者。

8.5 环形缓冲区

在读写大表时，PostgreSQL会使用环形缓冲区而不是缓冲池。环形缓

冲 器 是 一 个 很 小 的 临 时 缓 冲 区 域 。 当 满 足 下 列 任 一 条 件 时 ，

PostgreSQL将在共享内存中分配一个环形缓冲区。

1.批量读取。当扫描关系读取数据的大小超过缓冲池的四分之一时，

环形缓冲区的大小为256 KB。

2.批量写入，当执行下列SQL命令时，环形缓冲区大小为16 MB。

● COPY FROM命令。

● CREATE TABLE AS命令。

● CREATE MATERIALIZED VIEW或 REFRESH MATERIALIZED VIEW命令。

● ALTER TABLE命令。

3.清理过程，当自动清理守护进程执行清理过程时，环形缓冲区大小

为256 KB。

分配的环形缓冲区将在使用后被立即释放。

环形缓冲区的好处显而易见，如果后端进程在不使用环形缓冲区的情

况下读取大表，则所有存储在缓冲池中的页面都会被移除，这会导致

缓存命中率降低。环形缓冲区可以避免此问题。





为什么批量读取和清理过程的默认环形缓冲区大小为256 KB

源代码中缓冲区管理器目录下的README中解释了这个问题。

顺序扫描使用256KB的环形缓冲区，它足够小，因而能放入L2缓存中，

从而使得操作系统缓存到共享缓冲区的页面传输变得高效。通常更小

一点也可以，但环形缓冲区需要足够大到能同时容纳扫描中被钉住的

所有页面。

8.6 脏页刷盘

除了置换受害者页面之外，检查点进程和后台写入器进程也会将脏页

刷盘至存储中。尽管两个进程都具有相同的功能（脏页刷盘），但是

它们有着不同的角色和行为。

检查点进程将检查点记录写入WAL段文件，并在检查点开始时进行脏页

刷盘。第9.7节介绍了检查点和检查点开始的时机。

后台写入器的目的是通过少量多次的脏页刷盘，减少检查点带来的密

集写入的影响。后台写入器会一点点地将脏页落盘，尽可能减少对数

据库活动造成的影响。在默认情况下，后台写入器每200ms 被唤醒一

次 （ 由 参 数 bgwriter_delay 定 义 ） ， 且 最 多 刷 写

bgwriter_lru_maxpages个页面（默认为100个页面）。

为什么检查点进程与后台写入器相分离

在9.1及更低版本中，后台写入器会规律性地执行检查点进程。在9.2

版本中，检查点进程从后台写入被单独剥离出来。原因在一篇题为

“将检查点进程与后台写入器相分离”的提案中有介绍。下面是一些

摘录：

当前（在2011年）后台写入器进程既执行后台写入，又负责检查点，

还处理一些其他的职责。这意味着我们没法在不停止后台写入的情况

下执行检查点最终的 fsync。因此，在同一个进程中做两件事会有负

面的性能影响。

此外，在9.2版本中，我们的一个目标是通过将轮询循环替换为锁存

器，从而降低功耗。bgwriter中的循环复杂度太高了，以至于无法找





到一种简单的使用锁存器的方法。

第9章 WAL

事务日志是数据库的关键组件，因为在出现系统故障时，任何数据库

管理系统都不允许丢失数据。事务日志是数据库系统中所有变更与行

为的历史记录，当电源故障或其他服务器错误等导致服务器崩溃时，

使用它可以确保数据不会丢失。由于事务日志包含每个已执行事务的

相关信息，因此当服务器崩溃时，数据库服务器应能通过重放事务日

志中的变更与行为来恢复数据库集群。

在计算机科学领域，WAL是Write Ahead Logging的缩写，指的是将变

更 与 行 为 写 入 事 务 日 志 的 协 议 或 规 则 ， 而 在 PostgreSQL 中 ， WAL 是

Write Ahead Log的缩写，它被当成事务日志的同义词，而且也用来指

代一种将行为写入事务日志的实现机制。虽然这有些令人困惑，但是

本章将使用PostgreSQL中的定义。

WAL 机制在7.1版本中首次实现，用以减轻服务器崩溃带来的影响。它

还 是 时 间 点 恢 复 （ Point-in-Time Recovery,PITR ） 与 流 复 制

（Streaming Replication,SR）实现的基础，这两者将分别在第10章

和第11章中介绍。

理解WAL机制对于管理、集成PostgreSQL非常重要，由于它的复杂性，

不可能只是简要介绍，因此本章将会对WAL进行全面的解释。第9.1节

描绘了WAL的全貌，介绍了一些重要的概念与关键词。在接下来的章节

中会依次介绍其他主题。

● 事务日志与WAL段文件

● WAL记录的内部布局

● WAL记录的写入

● WAL写入进程

● PostgreSQL中的检查点进程

● PostgreSQL中的数据库恢复





● WAL段文件管理

● 归档日志与持续归档

9.1 概述

首先，让我们介绍一下 WAL 机制。为了阐明 WAL 要解决的问题，第

一部分展示了如果PostgreSQL在没有实现 WAL时崩溃，将会发生什

么。第二部分介绍了一些关键概念，并介绍了本章中的一些关键主

题。最后一部分总结一下WAL概述部分，并引出了一个更重要的概念。

9.1.1 没有WAL的插入操作

正如在第8章中讨论的那样，为了能高效地访问关系表的页面，几乎所

有的DBMS都实现了共享缓冲池。

假设有一个没有实现WAL机制的PostgreSQL，现在向TABLE_A中插入一

些数据元组，如图9.1所示。





图9.1 没有WAL的插入操作

（1）当发起第1条INSERT 语句时，PostgreSQL从数据库集簇文件中加

载TABLE_A的页面到内存中的共享缓冲池，然后向页面中插入一条元

组。页面并没有被立刻写回到数据库集簇文件中。正如第8章中提到

的，通常称被修改过的页面为脏页。

（2）当发起第2条INSERT语句时，PostgreSQL直接向缓冲池中的页面

添加了一条新元组，这一页面仍然没有被写回持久化存储中。

（3）如果操作系统或 PostgreSQL服务器因为各种原因失效（如电源

故障），那么所有插入的数据都会丢失。

因此，没有WAL的数据库在系统崩溃时是很脆弱的。

9.1.2 插入操作与数据库恢复

为了解决上述系统失效问题，同时又不导致性能损失，PostgreSQL选

择支持WAL。这一部分介绍了一些关键词和概念，以及WAL数据的写入

和数据库系统的恢复。

为了应对系统失效，PostgreSQL将所有修改作为历史数据写入持久化

存储中。这份历史数据被称为XLOG记录或WAL数据。

当插入、删除、提交等变更动作发生时，PostgreSQL会将 XLOG记录写

入内存中的 WAL缓冲区。当事务提交或中止时，它们会被立即写入持

久化存储的WAL段文件中（更精确地说，其他场景也可能会有XLOG记录

写入，具体细节将在第9.5节中描述）。XLOG记录的日志序列号（Log Sequence Number,LSN）标识了该记录在事务日志中的位置，记录的

LSN被用作XLOG记录的唯一标识符。

顺便一提，当我们考虑数据库系统如何恢复时，可能会想到一个问

题：PostgreSQL是从哪一点开始恢复的?答案是重做点，即最新的检查

点开始时XLOG记录写入的位置。PostgreSQL中的检查点将在第9.7节中

描述。实际上，数据库恢复过程与检查点进程紧密相连，两者是不可

分割的。

WAL与检查点进程在7.1版本中同时实现。



在介绍了主要的关键词与概念后，现在来说一下带有WAL的元组插入操

作，如图9.2所示。

表A的LSN展示的是表A页面首部中pd_lsn类型的PageXLogRecPtr字段，

与页面的LSN是一回事。

（1）检查点程序是一个后台进程，定期执行检查点。当检查点进程启

动时，它会向当前WAL段文件写入一条XLOG记录。这条记录包含了最新

的重做点位置。

图9.2 带有WAL的元组插入操作

（2）当发起第1条INSERT语句时，PostgreSQL从数据库集簇文件中加

载表A的页面至内存中的共享缓冲池，向页面中插入一条元组，然后在

LSN_1位置创建并写入一条相应的XLOG记录，再将表A的LSN从LSN_0更

新为LSN_1。在本例中，XLOG记录是由首部数据与完整元组组成的一对

值。

（3）当该事务提交时，PostgreSQL向WAL缓冲区创建并写入一条关于

该提交行为的XLOG记录，再将WAL缓冲区中的所有XLOG记录写入WAL段

文件中。

（4）当发起第2条 INSERT 语句时，PostgreSQL首先向页面中插入一

条新元组，然后在LSN_2位置创建并写入一条相应的XLOG记录，最后将

表A的LSN从LSN_1更新为LSN_2。

（5）当这条语句的事务提交时，PostgreSQL执行同第3步类似的操

作。

（6）设想当操作系统失效发生时，尽管共享缓冲区中的所有数据都丢

失了，但是所有页面修改已经作为历史记录被写入WAL段文件中。

接下来的步骤展示了如何将数据库集簇恢复到崩溃时刻前的状态。不

需要任何特殊的操作，重启PostgreSQL时会自动进入恢复模式，如图

9.3所示。PostgreSQL会从重做点开始，依序读取正确的WAL段文件并

重放XLOG记录。

（1）PostgreSQL从相关的WAL段文件中读取第1条INSERT 语句的XLOG

记录，并从硬盘上的数据库集簇目录加载表A的页面到内存中的共享缓

冲区中。



图9.3 使用WAL进行数据库恢复

（2）在重放XLOG记录前，PostgreSQL会比较XLOG记录的LSN与相应页

面的LSN。这么做的原因会在第9.8节中描述。重放XLOG记录的规则如

下。

● 如果XLOG记录的LSN比页面的LSN大，XLOG记录中的数据部分就会被

插入页面中，并将页面的LSN更新为XLOG记录的LSN。

● 如果XLOG记录的LSN比页面的LSN小，那么不用做任何事情，直接读

取后续的WAL数据即可。

（3）PostgreSQL按照同样的方式重放其余的XLOG记录。

PostgreSQL可以通过按时间顺序重放写在WAL段文件中的XLOG记录来自

我恢复，因此，PostgreSQL的XLOG记录显然是一种重做日志。

PostgreSQL不支持撤销日志。





尽管写XLOG记录肯定有一定的代价，但是这些代价和将整页刷盘相比

微不足道。所付出的代价换来了巨大的收益，比如，系统崩溃时的恢

复能力。

9.1.3 整页写入

假设后台写入进程在写入脏页的过程中出现了操作系统故障，导致磁

盘上表A的页面数据损坏，那么XLOG是无法在损坏的页面上重放的，我

们需要其他功能来确保这一点。

译者注：PostgreSQL默认使用8KB的页面，操作系统通常使用4KB的页

面，可能出现只写入一个4KB页面的情况。

PostgreSQL支持如图9.4所示的整页写入功能来处理这种失效。如果启

用，PostgreSQL会在每个检查点之后，在每个页面第一次发生变更

时，将整个页面及其首部元信息字段作为一条XLOG记录写入，这个功

能默认是开启的。在PostgreSQL中，这种包含完整页面的XLOG记录被

称为备份区块或整页镜像。



图9.4 整页写入

让我们再次描述一下启用了整页写入的元组插入。

（1）检查点程序启动检查点进程。

（2）当第1条INSERT语句执行插入操作时，PostgreSQL执行的操作几

乎同第9.1.2节所述的一样。区别在于，这里的 XLOG 记录是当前页的

备份区块（即包含了完整的页面），因为这是最近一次检查点之后该

页面的第一次写入。

（3）当事务提交时，PostgreSQL的操作同第9.1.2节所述的一样。



（4）当第2条INSERT语句进行插入操作时，PostgreSQL的操作同第

9.1.2节所述的一样，这里的XLOG记录就不是备份区块了。

（5）当这条语句的事务提交时，PostgreSQL的操作同第9.1.2节所述

的一样。

（6）为了说明整页写入的效果，我们假设后台写入进程在向磁盘写入

脏页的过程中出现了操作系统故障，导致磁盘上表A的页面数据损坏。

重启PostgreSQL即可修复损坏的集簇，如图9.5所示。

图9.5 使用备份区块进行数据库恢复

（1）PostgreSQL读取第1条INSERT语句的XLOG记录，并从数据库集簇

目录加载表A的页面至共享缓冲池中。在本例中，按照整页写入的规

则，这条XLOG记录是一个备份区块。





（2）当一条XLOG记录是备份区块时，会使用另一条重放规则：XLOG记

录的数据部分会直接覆盖当前页面，无视页面或XLOG记录中的LSN，然

后将页面的LSN更新为XLOG记录的LSN。

在本例中，PostgreSQL使用记录的数据部分覆写了损坏的页面，并将

表 A的 LSN更新为LSN_1。通过这种方式，损坏的页面可以通过它自己

的备份区块恢复。

（3）因为第2条XLOG记录不是备份区块，所以PostgreSQL的操作同第

9.1.3节所述的一样。

即使发生一些数据写入错误，PostgreSQL也能从中恢复。当然，如果

发生文件系统或物理介质失效，就不能恢复了。

9.2 事务日志与WAL段文件

PostgreSQL在逻辑上将XLOG记录写入事务日志，即一个长度用8B表示

的虚拟文件（16 EB）。

虽说事务日志的容量实际上应该是无限的，但8B 长度的地址空间已经

足够大了，目前不可能处理8B长度的单个文件。因此PostgreSQL中的

事务日志实际上默认被划分成大小为16MB的文件，这些文件被称作WAL

段，如图9.6所示。

WAL段文件尺寸

从 版 本 11.0 开 始 ， 在 使 用 initdb 创 建 数 据 库 时 ， 可 以 通 过 --wal-segsize选项来配置WAL段文件的大小。





图9.6 事务日志与WAL段文件

WAL段文件的文件名是由24个十六进制数组成的，其命名规则如下：

时间线标识

PostgreSQL的WAL有时间线标识的概念，用于第10章中所述的时间点恢

复。不过，在本章中，时间线标识将定为0x00000001，因为接下来的

几节还不需要这个概念。

第一个WAL段文件名是000000010000000000000001，如果第一个段被

XLOG记录写满了，就会创建第二个段000000010000000000000002，后

续的文件名将使用升序。在0000000100000000000000FF被填满之后，

就使用下一个文件000000010000000100000000。通过这种方式，每当

最 后 两 位 数 字 要 进 位 时 ， 中 间 8 位 数 字 就 会 加 1 。 与 之 类 似 ， 在

0000000100000001000000FF 被 填 满 后 ， 就 会 开 始 使 用

000000010000000200000000，以此类推。

WAL文件名





使 用 内 建 的 函 数 pg_xlogfile_name （ 9.6 及 更 低 版 本 ） 或

pg_walfile_name（10.0及更高版本），我们可以找出包含特定LSN的

WAL段文件。例如：

9.3 WAL段文件的内部布局

一 个 WAL 段 文 件 的 默 认 大 小 为 16MB ， 并 且 其 内 部 被 划 分 成 大 小 为

8192B （ 8KB ） 的 多 个 页 面 。 第 一 个 页 面 包 含 了 由

XLogLongPageHeaderData 定 义 的 首 部 数 据 ， 其 他 的 页 面 包 含 了 由

XLogPageHeaderData 定义的首部数据。每个页面的首部数据之后，紧

接着就是以降序写入的XLOG记录，如图9.7所示。





图9.7 WAL段文件的内部布局

XLogLongPageHeaderData 与 XLogPageHeaderData 结 构 的 定 义 在

src/include/access/xlog_internal.h中。这两个结构的具体说明在

此就不展开了，因为对于后续章节而言并非必要的内容。





9.4 WAL记录的内部布局

一条XLOG记录由通用的首部部分与特定的数据部分构成。第9.4.1节描

述了首部的结构，第9.4.2、第9.4.3节分别解释了9.5版本前后数据部

分的结构，9.5版本改变了数据格式。

9.4.1 WAL记录首部部分

所有的XLOG记录都有一个通用的首部部分，由结构XLogRecord 定义。

9.5版本中更改了首部的定义，9.4及更低版本的结构定义如下所示：





除了两个变量，大多数变量的意思非常明显，无须多言。xl_rmid 与

xl_info 都是与资源管理器相关的变量，资源管理器是一些与WAL功能

（写入、重放XLOG记录）相关的操作集合。资源管理器的数目随着

PostgreSQL版本的不断增加而增加，10.0版本包括以下内容。





下面这些有代表性的例子展示了资源管理器的工作方式。

● 如 果 发 起 的 是 INSERT 语 句 ， 则 其 相 应 XLOG 记 录 首 部 中 的 变 量

xl_rmid与xl_info会被相应地设置为RM_HEAP 与XLOG_HEAP_INSERT。

当恢复数据库集簇时，就会按照 xl_info 选用资源管理器 RM_HEAP

的函数 heap_xlog_insert()来重放当前XLOG记录。

● UPDATE 语 句 与 之 类 似 ， 首 部 变 量 中 的 xl_info 会 被 设 置 为

XLOG_HEAP_UPDATE，而在数据库恢复时则会选用资源管理器RM_HEAP的

函数heap_xlog_update()进行重放。

● 当事务提交时，相应XLOG记录首部的变量xl_rmid与xl_info会被相

应 地 设 置 为 RM_XACT 与 XLOG_XACT_COMMIT 。 当 数 据 库 恢 复 时 ，

RM_XACT 的 xact_redo_commit()就会执行本记录的重放。

在9.5及更高版本中，首部结构XLogRecord 移除了一个字段xl_len，

精简了XLOG记录的格式，节省了几个字节。





9.4版本中的XLogRecord结构定义在src/include/access/xlog.h中，

9.5

及

更

高

版

本

中

的

该

结

构

的

定

义

在

src/include/access/xlogrecord.h

中

。

heap_xlog_insert

与

heap_xlog_update 的 定 义 在 src/backend/access/heap/heapam.c 中 ；

而

函

数

xact_redo_commit

的

定

义

在

src/backend/access/transam/xact.c中。

9.4.2 XLOG记录的数据部分（9.4及更低版本）

XLOG记录的数据部分可以分为两类：备份区块（完整的页面）或非备

份区块（不同的操作对应的数据不同）。让我们通过几个具体示例来

了解XLOG记录的内部布局。

9.4.2.1 备份区块

备份区块如图9.8（1）所示，它由两个数据结构和一个数据对象组

成。



图9.8 XLOG记录的示例（9.4或更低版本）

1.XLogRecord结构（首部部分）。

2.BkpBlock结构。

3.除去空闲空间的完整页面。

BkpBlock 包括了用于在数据库集簇目录中定位该页面的变量（比如，

包含该页面的关系表的RelFileNode 与ForkNumber、文件内的区块号

BlockNumber），以及当前页面空闲空间的开始位置与长度。



9.4.2.2 非备份区块

在非备份区块中，数据部分的布局会因不同操作而异。这里举一个具

有代表性的例子：一条INSERT语句的XLOG记录。如图9.8（2）所示，

INSERT语句的XLOG记录是由两个数据结构与一个数据对象组成的。

1.XLogRecord结构体（首部部分）。

2.xl_heap_insert结构。

3.被插入的元组——更精确地说，是移除了一些字节的元组。

xl_heap_insert结构包含的变量用于在数据库集簇中定位被插入的元

组（比如，包含该元组的表的RelFileNode和该元组的tid），以及该

元组的可见性标记位。





在xl_heap_header结构的代码注释中解释了移除插入元组中若干字节

的原因：





我 们 并 没 有 在 WAL 中 存 储 被 插 入 或 被 更 新 元 组 的 固 定 部 分 （ 即

HeapTupleHeaderData，堆元组首部），我们可以在需要时从WAL的其

他部分重建这几个字段，以节省一些字节，或者根本就无须重建。

这里还有一个例子值得一提，如图9.8（3）所示，检查点的XLOG记录

相当简单，它由如下所示的两个数据结构组成：

1.XLogRecord结构（首部部分）。

2.包含检查点信息的CheckPoint结构（参见第9.7节）。

xl_heap_header 结 构 的 定 义 在 src/include/access/htup.h 中 ， 而

CheckPoint结构的定义在src/include/catalog/pg_control.h中。

9.4.3 XLOG记录的数据部分（9.5及更高版本）

在9.4及更低版本中，XLOG记录并没有通用的格式，因此每一种资源管

理器都需要定义各自的格式。在这种情况下，维护源代码及实现与

WAL 相关的新功能变得越来越困难。为了解决这个问题，9.5版本引入

了一种通用的结构化格式，不依赖于特定的资源管理器。

XLOG记录的数据部分可以被划分为首部与数据两个部分，如图9.9所

示。



图9.9 通用XLOG记录格式

首部部分包含零个或多个 XLogRecordBlockHeader，以及零个或一个

XLogRecord DataHeaderShort（或 XLogRecordDataHeaderLong），它

必 须 至 少 包 含 其 中 之 一 。 当 记 录 存 储 整 页 镜 像 时 （ 即 备 份 区

块

）

,XLogRecordBlockHeader

会

包

含

XLogRecordBlockImageHeader ， 如 果 启 用 压 缩 还 会 包 含

XLogRecordBlockCompressHeader。





数据部分则由零个或多个区块数据与零个或一个主数据组成，区块数

据 与 XLogRecordBlockHeader 对 应 ， 主 数 据 则 与

XLogRecordDataHeader对应。

WAL压缩

在9.5及更高版本中，可以通过设置wal_compression = enable启用

WAL压缩：使用LZ压缩方法对带有整页镜像的XLOG记录进行压缩。在这

种情况下，会添加XLogRecordBlockCompressHeader结构。

该功能有两个优点与一个缺点，优点是降低写入记录的 I/O开销，并

减小 WAL段文件的消耗量；缺点是会消耗更多的CPU资源来执行压缩操

作。

和第9.4.2节一样，下面通过一些示例来描述。

9.4.3.1 备份区块

由INSERT语句创建的备份区块如图9.10（1）所示，它由如下所示的4

个数据结构与1个数据对象组成：

1.XLogRecord结构（首部部分）。

2.XLogRecordBlockHeader

结

构

，

且

包

含

一

个

XLogRecordBlockImageHeader。

3.XLogRecordDataHeaderShort结构。

4.一个备份区块（区块数据）。

5.xl_heap_insert结构（主数据）。

XLogRecordBlockHeader包含了用于在数据库集簇中定位区块的变量

（关系节点、分支编号及区块号）;XLogRecordImageHeader 包含了当

前区块的长度与偏移量，这两个首部结构合起来的效果与9.4及更低版

本中的BkpBlock结构相同。

XLogRecordDataHeaderShort 存储了xl_heap_insert 结构的长度，该

结构是当前记录的主数据部分。

除了某些特例外，如逻辑解码与推测插入，包含整页镜像的XLOG记录

的主数据不会被使用。它们会在记录重放时被忽略，属于冗余数据，

未来可能会对其进行改进。

此外，备份区块记录的主数据与创建它们的语句相关。例如，UPDATE

语句会追加写入xl_heap_lock或xl_heap_updated。

9.4.3.2 非备份区块

接下来描述由INSERT语句创建的非备份区块，如图9.10（2）所示，它

由4个数据结构与1个数据对象组成：

1.XLogRecord结构（首部部分）。

2.XLogRecordBlockHeader结构。

3.XLogRecordDataHeaderShort结构。

4.一条被插入的元组（更精确地说，是一个xl_heap_header结构与完

整的插入数据）。

5.xl_heap_insert结构（主数据）。

XLogRecordBlockHeader 包 含 3 个 值 （ 关 系 节 点 、 分 支 编 号 和 区 块

号），用以指明该元组被插入哪个区块中，以及要插入数据部分的长



度 。 XLogRecordDataHeaderShort 存 储 了 xl_heap_insert 结 构 的 长

度，该结构是当前记录的主数据部分。

新版本的xl_heap_insert仅包含两个值，分别是当前元组在区块内的

偏 移 量 和 一 个 可 见 性 标 记 。 该 结 构 十 分 简 单 ， 因 为

XLogRecordBlockHeader存储了旧版本中该结构体的绝大多数数据。

最后一个例子，检查点的记录如图9.10（3）所示，它由3个数据结构

组成：

1.XLogRecord结构体（首部部分）。

2.XLogRecordDataHeaderShort结构，包含了主数据的长度。

3.结构体CheckPoint（主数据）。

xl_heap_header 的 定 义 在 src/include/access/htup.h 中 ， 而

CheckPoint结构的定义在 src/include/catalog/pg_control.h中。

尽管对我们来说新格式稍显复杂，但是它对于资源管理器的解析而

言，设计更为合理，而且许多类型的XLOG记录的大小都比先前要小。

主要的结构如图9.8和图9.10所示，你可以计算并相互比较这些记录的

大小。新版CheckPoint记录的尺寸要比旧版大一些，但它也包含了更

多的变量。





图9.10 XLOG记录示例（9.5及更高版本）

9.5 WAL记录的写入

在完成了热身练习后，现在我们已经做好理解XLOG记录写入过程的准

备了。因此在本节中，我将尽可能仔细地描述。首先，以下列语句的

执行为例，让我们来看一看PostgreSQL的内幕。

通过上述语句，内部函数exec_simple_query()会被调用，其伪代码如

下所示：



在接下来的内容中将会解释每一行伪代码，从而理解XLOG记录写入的

过程，如图9.11和图9.12所示。



图9.11 XLOG记录的写入顺序



图9.12 XLOG记录的写入顺序（接图9.11）

（1）函数ExtendCLOG()将当前事务的状态IN_PROGRESS写入内存中的

CLOG。

（2）函数heap_insert()向共享缓冲池的目标页面中插入堆元组，创

建当前页面的XLOG记录，并执行函数XLogInsert()。

（3）函数XLogInsert()会将heap_insert()创建的XLOG记录写入WAL缓

冲区LSN_1处，并将被修改页面的pd_lsn从LSN_0更新为LSN_1。

（4）函数 finish_xact_command()会在提交该事务时被调用，用于创

建该提交动作的XLOG记录，而这里的XLogInsert()函数会将该记录写

入WAL缓冲区LSN_2处。

注：图9.11中的XLOG格式是9.4版本中的格式。





（5）函数 XLogWrite()会刷写 WAL 缓冲区，并将所有内容写入 WAL

段 文 件 中 。 如 果 wal_sync_method 参 数 被 配 置 为 open_sync 或

open_datasync，记录会被同步写入，因为函数会使用带有O_SYNC或

O_DSYNC标记的open()系统调用。

译者注：不是提交才会刷写WAL缓冲区。

如果该参数被配置为fsync、fsync_writethrough或fdatasync，相应

的 系 统 调 用 就 是 fsync() 、 带 有 F_FULLSYNC 选 项 的 fcntl() 和

fdatasync()。无论哪一种情况，所有的XLOG记录都会被确保写入存储

之中。

（6）函数 TransactionIdCommitTree()将提交日志 CLOG 中当前事务

的状态从IN_PROGRESS更改为COMMITTED。

在上面的例子中，COMMIT操作导致XLOG记录写入WAL段文件。但发生下

列任一情况，都会执行这种写入操作：

1.一个运行中的事务提交或中止。

2.WAL缓冲区被写入的元组填满（WAL缓冲区的大小由参数wal_buffers 控制）。

3.WAL写入进程周期性地执行写入操作（参见第9.6节）。

如果出现上述情况之一，无论其事务是否已提交，WAL缓冲区上的所有

WAL记录都将被写入WAL段文件中。

DML操作写XLOG记录是理所当然的，但非DML操作也会产生XLOG。如上

所述，COMMIT操作会写入包含提交的事务ID的XLOG记录。另一个例子

是Checkpoint 操作会写入关于该检查点概述信息的XLOG记录。此外，

尽管不是很常见，但是SELECT语句在一些特殊情况下还会创建XLOG记

录。例如在SELECT语句的处理过程中，如果HOT需要删除不必要的元组

并拼接必要的元组，那么修改对应页面的XLOG记录就会被写入WAL缓冲

区。

9.6 WAL写入进程





WAL写入是一个后台进程，用于定期检查WAL缓冲区，并将所有未写入

的XLOG记录写入WAL段文件。这个进程的目的是避免XLOG记录的突发写

入。如果没有启用该进程，则在一次提交大量数据时，XLOG记录的写

入可能会成为瓶颈。

WAL 写 入 默 认 是 启 用 的 ， 无 法 禁 用 。 但 检 查 间 隔 可 以 通 过 参 数

wal_writer_delay 进行配置，默认值为200ms。

9.7 PostgreSQL中的检查点进程

在PostgreSQL中，检查点进程（后台）会执行检查点程序。当下列情

形之一发生时，它会启动。

1.上一个检查点已由参数checkpoint_timeout配置的时间间隔，默认

的时间间隔为300s（5min）。

2.在9.4及更低版本中，自上一次检查点以来消耗的 WAL 段文件超出

了参数checkpoint_segments设置的数量（默认值为3）。

3.在9.5及更高版本中，pg_xlog（10.0版本之后是pg_wal）中的WAL段

文件总大小超过参数max_wal_size设置的值（默认值为1GB,64个段文

件）。

4.PostgreSQL服务器以smart或fast模式关闭。

当超级用户手动执行CHECKPOINT命令时，该进程也会启动。

在9.1或更低版本中，后台写入进程（见第8.6节）同时负责脏页刷写

与检查点。

在 接 下 来 的 章 节 中 ， 会 简 要 描 述 检 查 点 进 程 与 pg_control 文 件 ，

pg_control文件保存了当前检查点的元数据。

9.7.1 检查点进程概述

检查点进程负责两个方面，分别是为数据库恢复做准备工作，以及共

享缓冲池上脏页的刷盘工作。在本节介绍其内部流程时，将重点关注

前一个方面，参见图9.13和以下描述。



图9.13 PostgreSQL检查点的内部流程

（1）当检查点进程启动时，会将重做点存储在内存中，重做点是上次

检查点开始时刻XLOG记录的写入位置，也是数据库恢复的开始位置。

（2）该检查点相应的XLOG记录（即检查点记录）会被写入WAL缓冲

区，该记录的数据部分是由CheckPoint结构体定义的，包含了一些变

量，如步骤（1）中重做点的位置。另外，写入检查点记录的位置，也

按照字面意义叫作检查点。





（3）共享内存中的所有数据（例如，CLOG的内容）都会被刷入持久化

存储中。

（4）共享缓冲池中的所有脏页都会被逐渐刷写到存储中。

（5）更新pg_control文件，该文件包含了一些基础信息，如上一次检

查点的位置，后面会介绍该文件的细节。

从数据库恢复的角度来总结上面的内容，检查点进程会创建包含重做

点的检查点，并将检查点位置与其他信息存储到 pg_control 文件

中。因此，PostgreSQL 能够通过从重做点回放WAL数据来进行恢复

（重做点是从检查点中获取的）。

9.7.2 pg_crontrol文件

由于pg_control文件包含了检查点的基本信息，因此它对数据库恢复

来说是必不可少的。如果它被破坏或不可读，系统不知道从哪里开始

恢复，恢复过程就无法启动。

尽管pg_control 文件存储了40多个数据项，但是只有如下3点与我们

接下来讨论的内容相关：

1.状态——最近检查点进程开始时数据库的状态，总共有7种状态：

start up表示系统正在启动，shut down表示系统通过关机命令正常关

闭，in production表示数据库正在运行，等等。

2.最新检查点位置——最新检查点的LSN位置。

3.上次检查点位置——前一个检查点的LSN位置，在11.0版本中已经弃

用该检查点，细节如下面的引文所示。

pg_control 文 件 存 储 在 数 据 目 录 的 global 子 目 录 内 ， 可 以 使 用

pg_controldata程序显示其内容。

PostgreSQL11.0中移除了前一个检查点

PostgreSQL 11.0及更高版本只会存储包含最新检查点或更高版本的

WAL段文件，不会再存储包含先前一个检查点的旧段文件，以节约用于

在pg_xlog（pg_wal）子目录下保存WAL段文件的磁盘空间。详细信息





请

参

见



http://www.postgresql-archive.org/Remove-secondarycheckpoint-tt5989050.html中的主题。

9.8 PostgreSQL中的数据库恢复

PostgreSQL的恢复功能基于重做日志实现。如果数据库服务器无法工

作，PostgreSQL通过从重做点依序重放WAL段文件中的XLOG记录来恢复

数据库集群。

在本节之前，我们已经多次讨论了数据库恢复，所以这里仅介绍两个

与恢复有关，但尚未介绍过的内容。

第一个是PostgreSQL如何启动恢复过程。当PostgreSQL启动时，它首

先读取pg_control文件。恢复过程的细节参见图9.14和以下描述。

（1）PostgreSQL 在启动时读取 pg_control 文件的所有项。如果

state 项是 in production,PostgreSQL将进入恢复模式，因为这意味

着数据库没有正常停止；而如果state项是shut down，它就会进入正

常的启动模式。



图9.14 恢复过程的细节

（2）PostgreSQL 从合适的 WAL 段文件中读取最近的检查点，该记录

的位置写在pg_control 文件中，并从该检查点中获得重做点。如果最

新的检查点是无效的，PostgreSQL就会读取前一个检查点。如果两个

记录都不可读，它就会放弃自我恢复。注意，在PostgreSQL 11.0中不

会存储前一个检查点。

（3）使用合适的资源管理器按顺序读取并重放XLOG记录，从重做点开

始，直到最新WAL段文件的最后位置。当遇到一条属于备份区块的XLOG

记录时，无论其LSN如何，都会覆写相应表的页面。在其他情况下，只

有当此记录的LSN大于相应页面的pd_lsn时，才会重放该（非备份区块

的）XLOG记录。

第二个是关于LSN的比较：为什么应该比较非备份区块的LSN和相应页

面的pd_lsn。与前面的示例不同，这里要用一个特定的例子来解释

它，强制两个LSN之间的比较需求，如图9.15和图9.16所示。注意，这

里省略了WAL缓冲区，以简化描述。



图9.15 当后台写入工作时的插入操作

（1）PostgreSQL将一条元组插入表A，并将一条XLOG记录写入LSN_1。

（2）后台写入进程将表A的页面写入存储。此时，此页面的pd_lsn为

LSN_1。

（3）PostgreSQL在表A中插入一条新元组，并在LSN_2处写入一条XLOG

记录。修改后的页面尚未写入存储。

与本章概述中的例子不同，在本场景中，表A的页面已经被一次性写入

存储中。

使用immediate模式关闭数据库，然后启动数据库。





图9.16 数据库恢复

（1）PostgreSQL加载第一条 XLOG记录和表 A的页面，但不重放它，

因为该记录的 LSN不大于表A的LSN（两个值都是LSN_1）。实际上一目

了然，没有重放该记录的必要性。

（ 2 ） 接 下 来 ， PostgreSQL 会 重 放 第 二 条 XLOG 记 录 ， 因 为 该 记 录 的

LSN（LSN_2）大于当前表A的LSN（LSN_1）。

从这个例子可以看出，如果非备份区块的重放顺序不正确，或者多次

重放非备份区块，数据库集群将不再一致。简而言之，非备份区块的

重做（重放）操作不是幂等的。因此，为了确保正确的重放顺序，非

备份区块中的记录当且仅当其LSN大于相应页面的pd_lsn时，才执行重

放。

另外，由于备份区块的重放操作是幂等的，不管其 LSN为何值，备份

块都可以重放任意次。

9.9 WAL段文件管理





PostgreSQL将XLOG记录写入pg_xlog子目录的WAL段文件中（10.0版本

之后是pg_wal子目录），当旧的段文件写满时就会切换至新的段文

件。WAL 文件的数量会因为几个配置参数发生变化而变化，一些服务

器的行为也会相应变化。此外，在9.5版本中，段文件的管理机制也有

了一些改善。

9.9.1 WAL段切换

当出现下列任一情况时，WAL段会发生切换：

1.WAL段已经被填满。

2.函数pg_switch_xlog()（10.0版本以后为pg_switch_wal()）被调

用。

3.启用了archive_mode，且已经超过archive_timeout配置的时间。

被切换的文件通常会被回收（重命名或重用），以供未来使用。但如

果不需要的话，也可能会被移除。

9.9.2 WAL段管理（9.5及更高版本）

每当检查点进程启动时，PostgreSQL都会估计并准备下一个检查点周

期所需的 WAL段文件数。这种估计基于前一个检查点周期中消耗的文

件数量，即从包含上一个重做点的段文件开始计数，而这个值应当在

min_wal_size（默认值为80MB,5个文件）与max_wal_size 之间（默认

值为1GB,64个文件）。如果检查点进程启动，必要的段文件就会被保

留或回收，不必要的段文件就会被移除。

具体的例子如图9.17所示，假设在检查点开始前有6个文件，WAL_3包

含 了 上 一 个 重 做 点 （ 10.0 及 更 低 版 本 ， 11.0 版 本 后 就 是 当 前 重 做

点）,PostgreSQL估计需要5个文件，在这种情况下，WAL_1被重命名为

WAL_7回收利用，而WAL_2被移除。

任何比包含上一个重做点的段文件更老的段文件都可以被移除，因为

按照第9.8节中描述的恢复机制，这些文件永远不会被用到。



图9.17 在检查点时发生的WAL段文件循环与回收

如果出现了WAL活动尖峰，导致需要更多的文件，新的文件就会被创

建，而WAL文件的总大小小于max_wal_size。例如，在图9.18中，如果

WAL_7被填满，WAL_8就会被创建出来。



图9.18 创建WAL段文件

WAL文件的数量会根据服务器活动而自动适配。如果WAL数据写入量持

续增加，则WAL段文件的估计数量以及WAL文件的总大小也会随之增

加。在相反的情况下（即WAL数据写入量减少），这些值也会减少。

如果WAL文件的总大小超过max_wal_size，则将启动检查点，图9.19说

明了这种情况。检查点将会创建一个新的重做点，最近的重做点将会

变 为 上 一 个 重 做 点 ， 不 必 要 的 文 件 将 被 回 收 。 通 过 这 种 方 式 ，

PostgreSQL将始终只保留数据库恢复所必需的WAL段文件。





图9.19 检查点与回收WAL段文件

配置参数wal_keep_segments及复制槽功能都会影响WAL段文件的数

量。





9.9.3 WAL段管理（9.4及更低版本）

WAL段文件的数量主要由下列3个参数控制：

● checkpoint_segments

● checkpoint_completion_target

● wal_keep_segments

WAL段文件的数量通常有以下几个特点。

●



比

((2

+

checkpoint_completion_target)

×checkpoint_segments + 1)大.

● 比(checkpoint_segments + wal_keep_segments + 1)大。

● 不超过(3×checkpoint_segments+1)个文件。

WAL段文件的具体数目取决于不同的服务器活动，复制槽的存在也会影

响 WAL文件的数量。

如第9.7节中所提到的，当消耗了超过checkpoint_segments个数量的

文件时，就会启动检查点进程。因此可以保证 WAL 段文件中总是包含

至少两个重做点，文件的数量始终大于2×checkpoint_segments，这

对于由超时导致的检查点同样适用。PostgreSQL总是会保留足够用于

恢复的WAL段文件数（有时候会超出必要的量）。

在9.4或更低版本中，调整参数checkpoint_segments是一个痛苦的问

题。如果设置为较小的值，则检查点频繁发生，会导致性能下降，而

如果设置为较大的值，则WAL文件总是需要巨大的磁盘空间，但其中一

些空间不是必要的。

在 9.5 版 本 中 ， WAL 文 件 的 管 理 策 略 得 到 了 改 善 ， 而

checkpoint_segments参数被弃用，因此上述的权衡问题已经得到解

决。

9.10 持续归档与归档日志





持续归档是当WAL段文件发生切换时自动将其复制至归档区域的一项功

能，如图9.20所示。持续归档是由归档后台进程执行的，复制的文件

被称为归档日志。该功能通常用于物理备份与时间点恢复，参见第10

章。

归档区域的配置取决于配置参数archieve_command，例如，在使用下

列 配 置 ， 且 发 生 段 文 件 切 换 时 ， WAL 段 文 件 会 被 复 制

到/home/postgres/archives目录下：

这里的%p是被复制的WAL段文件的路径占位符，%f是归档日志文件名的

占位符。

图9.20 持续归档

当WAL段文件WAL_7发生切换时，该文件被复制至归档区域，作为归档

日志7。

archive_command 参数可以配置为任意的UNIX命令或程序，因此你也

能用scp 将归档日志发送到其他主机上，或使用任意的文件备份工具

来替代普通的复制命令。





PostgreSQL并不会清理归档日志，所以在使用该功能时需要管理好这

些日志。如果什么都不做，那么归档日志的数量会不断增加。

pg_archivecleanup工具是一个管理归档日志的实用工具。

第10章 基础备份与时间点恢复

在线数据库备份大致可分为逻辑备份和物理备份两类，它们各自都有

优点和缺点。逻辑备份有一个缺点，即执行需要花费大量的时间。特

别是对于大型数据库而言，需要花费很长时间进行备份，而从备份数

据中恢复数据库可能需要更长的时间。相反，物理备份可以在相对较

短的时间内备份和恢复大型数据库，因此在实际系统中，其是一个非

常重要且实用的功能。

在PostgreSQL中，自8.0版本开始提供了在线的全量物理备份，整个数

据库集簇（即物理备份数据）的运行时快照被称为基础备份。

PostgreSQL 还 在 8.0 版 中 引 入 了 时 间 点 恢 复 （ Point-In-Time Recovery,PITR）。这一功能可以将数据库恢复至任意时间点，这通过

使用一个基础备份和由持续归档生成的归档日志来实现。例如，即使

你犯了一个严重的错误（如TRUNCATE所有的表），此功能还可以将数

据库恢复至错误发生之前的时刻。

本章描述了以下主题：

● 基础备份

● 时间点恢复（PITR）的工作原理

● 时间线与时间线历史文件

● 时间点恢复与时间线历史文件

在7.4或更低版本中，PostgreSQL仅支持逻辑备份（全量逻辑备份、部

分逻辑备份和数据导出）。

10.1 基础备份



使用底层命令进行基本备份的标准过程如图10.1所示，具体步骤如

下：

（1）发出pg_start_backup命令。

（2）使用你想用的归档命令获取数据库集簇的快照。

（3）发出pg_stop_backup命令。

这个简单的过程对于DBA来说很容易操作，因为它不需要特殊工具，只

需要常用工具（如复制命令或类似的归档工具）来创建基本备份。此

外，在此过程中，不需要获取表上的锁，所有用户都可以在不受备份

操作影响的情况下发起查询。相对于其他开源的关系型数据库，这是

一个巨大的优势。

更简单的方式是使用pg_basebackup 命令来做基础备份，不过在其内

部也是使用这些底层命令来工作的。

图10.1 制作基础备份





这些命令对显然是理解PITR的关键点之一，我们将在后续章节中探讨

它们。

pg_start_backup

和

pg_stop_backup

命

令

的

定

义

在

src/backend/access/transam/xlogfuncs.c中。

10.1.1 pg_start_backup

pg_start_backup开始为制作基础备份进行准备工作。如第9.8节所

述，恢复过程从重做点开始，因此pg_start_backup必须执行检查点，

以便在制作基础备份的开始时刻显式创建一个重做点。此外，这次检

查点的位置必须保存在非pg_control的其他文件中，因为在备份期间

可能会执行多次常规检查点。pg_start_backup执行下列4个操作：

1.强制进入整页写入模式。

2.切换到当前的WAL段文件（8.4或更高版本）。

3.执行检查点。

4.创建backup_label文件——该文件创建于基本目录顶层中，包含有

关该基本备份本身的关键信息，如检查点的检查点位置。

第3个和第4个操作是该命令的核心。第1和第2个操作是为了更可靠地

恢复数据库集簇。

备份标签backup_label文件包含以下7个项目：

1.检查点位置——该命令所创建检查点的LSN位置。

2.WAL开始位置——这不是给PITR用的，而是为第11章描述的流复制准

备的。它被命名为START WAL LOCATION，因为复制模式下的备用服务

器在初始启动时只读取一次该值。

3.备份方法——这是用于进行此基本备份的方法，如pg_start_backup 或pg_basebackup。

4.备份来源——说明此备份是从主库还是备库拉取。





5.开始时间——这是执行pg_start_backup时的时间戳。

6.备份标签——这是pg_start_backup中指定的标签。

7.开始时间线——这是备份开始的时间线，为了进行正常的检查，在

版本11.0中被引入。

备份标签

一个9.6版本中备份标签的实际例子如下所示：

可 以 想 象 ， 当 使 用 此 基 础 备 份 恢 复 数 据 库 时 ， PostgreSQL 从

backup_label文件中取出检查点位置CHECKPOINT LOCATION，接着从归

档日志中的合适位置读取检查点记录，然后从检查点记录中获取重做

点的位置，最后从重做点开始进行恢复，具体细节将在第10.2节介

绍。

10.1.2 pg_stop_backup

pg_stop_backup执行以下5个操作以完成备份：

1.如果pg_start_backup打开了整页写入，那么关闭整页写入。

2.写入一条备份结束的XLOG记录。

3.切换WAL段文件。





4.创建一个备份历史记录文件——此文件包含backup_label文件的内

容，以及已执行pg_stop_backup的时间戳。

5. 删 除 backup_label 文 件 —— 从 基 础 备 份 恢 复 需 要 backup_label 文

件，不过一旦被复制，原始的数据库集簇就不需要该文件了。

备份历史文件的命名方法如下所示：

10.2 时间点恢复（PITR）的工作原理

图10.2展示了PITR的基本概念。PITR模式下的PostgreSQL会在基础备

份上重放归档日志中的 WAL 数据，从 pg_start_backup 创建的重做

点开始，恢复到你想要的位置为止。在PostgreSQL中，想要恢复到的

位置被称为恢复目标。

PITR是如下这样工作的。假设你在GMT时间2018-07-16 12:05:00犯了

错误，那么就应该删掉当前的数据库集簇，并使用之前制作的基础备

份恢复一个新的，然后创建一个recovery.conf 文件，并在其中将

recovery_target_time 参数配置为犯错误的时间点，在本例中，也就

是12:05 GMT。recovery.conf文件如下所示：



图10.2 PITR的基本概念

在 PostgreSQL启动的时候，如果数据库集簇中存在 recovery.conf和

backup_label文件，就会进入恢复模式。

PITR过程几乎与第9章中描述的常规恢复过程一模一样，唯一的区别只

有以下两点：

1.从哪里读取WAL段/归档日志?

● 正常恢复模式——来自基础目录下的 pg_xlog 子目录（在10.0或

更高版本中为pg_wal子目录）。

● PITR模式——来自配置参数archive_command中设置的归档目录。

2.从哪里读取检查点位置?

● 正常恢复模式——来自pg_control文件。

● PITR模式——来自backup_label文件。

PITR流程概述如下：

1.为了找到重做点，PostgreSQL使用内部函数read_backup_label 从

backup_label文件中读取CHECKPOINT LOCATION的值。

2.PostgreSQL 从 recovery.conf 中 读 取 一 些 参 数 值 ， 在 此 例 中 为

restore_command和recovery_target_time。

3.PostgreSQL 开始从重做点重放 WAL 数据，重做点的位置可以简单

地 从 CHECKPOINT LOCATION 的 值 中 获 得 。 PostgreSQL 执 行 参 数

restore_command中配置的命令，将归档日志从归档区域复制到临时区

域，并从中读取 WAL 数据，复制到临时区域中的日志文件会在使用后

被删除。

在本例中，因为参数recovery_target_time被设置为该时间戳，所以

PostgreSQL 从 重 做 点 读 取 并 重 放 WAL 数 据 ， 直 到 时 间 戳 2018-7-16

12:05:00 为 止 。 如 果 recovery.conf 中 没 有 配 置 恢 复 目 标 ， 则

PostgreSQL将重放至归档日志的末尾。

4.当恢复过程完成时，会在pg_xlog子目录（在10.0或更高版本中为

pg_wal子目录）中创建时间线历史文件，如00000002.history。如果

启用了日志归档功能，则还会在归档目录中创建相同的命名文件。接

下来各节会介绍此文件的内容和作用。

提交和中止操作的记录包含每个操作完成时的时间戳（两个操作的

XLOG数据部分分别在xl_xact_commit和xl_xact_abort 中定义）。因

此 ， 如 果 将 目 标 时 间 设 置 为 参 数 recovery_target_time ， 只 要

PostgreSQL重放提交或中止操作的XLOG记录，就可以选择是否继续恢

复。当重放每个动作的XLOG记录时，PostgreSQL会比较目标时间和记

录中写入的每个时间戳，如果时间戳超过目标时间，PITR过程就会完

成。





函 数 read_backup_label 定 义 于 src/backend/access/transam/xlog.c 中

。

结

构

xl_xact_commit

和

xl_xact_abort

定

义

于

src/backend/access/transam/xlog.c中。

为什么可以用一般归档工具做基础备份

尽管数据库集簇可能是不一致的，但恢复过程是使数据库集簇达成一

致状态的过程。由于PITR是基于恢复过程的，所以即使基础备份是一

堆不一致的文件，它也可以恢复数据库集簇。因此，我们可以在没有

文件系统快照功能或其他特殊工具的情况下，使用一般归档工具做基

础备份。

10.3 时间线与时间线历史文件

PostgreSQL中的时间线用于区分原始数据库集簇和恢复生成的数据库

集簇，它是 PITR的核心概念。本节描述了与时间线相关的两件事，分

别是时间线标识和时间线历史文件。

10.3.1 时间线标识

每个时间线都有一个相应的时间线标识，是一个4B的无符号整型数，

从1开始计数。

每个数据库集簇都会被指定一个时间线标识。由initdb 命令创建的原

始数据库集簇，其时间线标识为1。每当数据库集簇恢复时，时间线标

识都会增加1。例如，在第10.2节的例子中，从原始集簇中恢复得到的

集簇，其时间线标识为2。

图10.3从时间线标识的角度展示了PITR过程。首先，我们删除当前的

数据库集簇，并替换为过去的基础备份，以便返回到恢复的起始点，

这一步在图中用上侧的曲线箭头标识。接下来，我们启动PostgreSQL

服 务 器 ， 它 通 过 跟 踪 初 始 时 间 线 （ 时 间 线 标 识 1 ） ， 从

pg_start_backup创建的重做点开始，重放归档日志中的 WAL 数据，

直到恢复目标达成，这一步在图中用浅色直线箭头标识。最后，恢复

得到的数据库集簇将被分配一个新的时间线标识2，而PostgreSQL将运

行在新的时间线上。





图10.3 原始数据库集簇和恢复数据库集簇之间时间线标识的关系

正如第9章中提到的，WAL段文件名的前8位数字等于创建这些段文件的

数据库集簇的时间线标识。当时间线标识发生变化时，WAL段文件名也

会发生相应的改变。

让我们从 WAL 段文件的角度重新审视恢复过程。假设我们使用两个归

档 日 志 文 件 来 恢 复 数 据 库 ， 分 别 是 000000010000000000000009 和

00000001000000000000000A。新恢复得到的数据库集簇被分配了时间

线标识2，而PostgreSQL就会从00000002000000000000000A开始创建

WAL段，如图10.4所示。

图10.4 原始数据库集簇和恢复数据库集簇之间WAL段文件的关系





10.3.2 时间线历史文件

当PITR过程完成时，会在归档目录和pg_xlog子目录（在10.0或更高版

本中为pg_wal子目录）下创建名称为00000002.history 的时间线历史

文件。该文件记录了当前时间线是从哪条时间线分叉出来的，以及分

叉的时间。

该文件的命名规则如下所示：

时间线历史文件至少包含一行，每行由以下3项组成：

● 时间线标识——曾用于恢复的归档日志的时间线。

● LSN——发生WAL段切换的LSN位置。

● 原因——可读的时间线发生变化的原因解释。

具体示例如下所示：

含义如下：

数据库集簇（时间线标识为2）基于时间线标识为1的基础备份，并在

2018-7-9 12:05:00.861324+00之前，通过重放检查点日志，恢复至

0/A000198的位置。

通过这种方式，每个时间线历史文件都会告诉我们每个恢复所得的数

据库集簇的完整历史，而且它在PITR过程中也有使用。第10.4节将描

述具体细节。

时间线历史文件的格式在9.3版本中发生了变化。9.3前后的格式如下

所示，但相对简略。





9.3及更高版本：

9.2及更低版本：

10.4 时间点恢复与时间线历史文件

时间线历史文件在第二次及后续 PITR 过程中起着重要作用。通过尝

试第二次恢复，我们将探索如何使用它。

同样，假设你在12:15:00时间点又犯了一个错误，错误发生在时间线

ID为2的数据库集簇上。在这种情况下，为了恢复数据库集簇，你需要

创建一个如下所示的recovery.conf 文件：

参 数 recovery_target_time 被 设 置 为 犯 下 新 错 误 的 时 间 ， 而

recovery_target_timeline被设置为2，以便沿着这条时间线恢复。

重启PostgreSQL服务器并进入PITR模式，数据库会沿着时间线标识2进

行恢复，如图10.5所示。



图10.5 沿着时间线2将数据库恢复至12:15:00的状态

1.PostgreSQL从backup_label文件中读取CHECKPOINT LOCATION的值。

2. 从 recovery.conf 中 读 取 一 些 参 数 值 ， 在 此 示 例 中 为

restore_command

、

recovery_target_time

和

recovery_target_timeline。

3.PostgreSQL 读取时间线历史文件00000002.history，该文件对应参

数recovery_target_timeline的值。

4.PostgreSQL通过以下步骤重放WAL数据：

（1）对于从重做点到 LSN 0/A000198（该值写在00000002.history 文件中）之间的WAL数据，PostgreSQL会（从合适的归档日志中）读取

并重放TimelineID=1的WAL数据。

（2）对于从LSN 0/A000198到时间戳2018-7-9 12:15:00之间的WAL数

据，PostgreSQL会（从合适的归档日志中）读取并重放TimelineID=2

的WAL数据。





5.当恢复过程完成时，当前的时间线标识将增加到3，并在pg_xlog子

目录（在10.0及更高版本中为pg_wal子目录）和归档目录中创建名为

00000003.history的新时间线历史文件。

当你进行过超过一次的PITR时，应明确设置时间线标识，以便使用合

适的时间线历史文件。

因此，时间线历史文件不仅是数据库集簇的历史日志，还是PITR过程

的参考恢复指令。

第11章 流复制

PostgreSQL在9.1版本中实现了流复制。它属于所谓的一主多从类型的

复制，而主和从两个术语，在PostgreSQL中通常分别被称为主和备。

译者注：存储数据库副本的每个节点被称为副本。每一次对数据库的

写入操作都需要传播到所有副本上，否则副本就会包含不一样的数

据。最常见的解决方案是基于领导者的复制，也称为主动/被动或主/

从复制。其中，副本之一被指定为领导者，也称为主库或首要。当客

户端要向数据库写入时，它必须将请求发送给领导者，领导者会将新

数据写入其本地存储。其他副本被称为追随者，也称为只读副本、从

库、次要或热备。

这种原生复制功能是基于日志传输实现的，是一种通用的复制技术：

主库不断发送 WAL数据，而每个备库接受WAL数据，并立即重放日志。

本章将介绍以下主题，重点介绍流复制的工作原理：

● 流复制的启动





● 如何实施流复制

● 管理多个备库

● 备库的故障检测

尽管在9.0版本中最初实现的复制功能只能进行异步复制，但是它很快

就在9.1版本中被新的实现（如今采用的）所替代，可以支持同步复

制。

11.1 流复制的启动

在流复制中，有3种进程协同工作。主库上的WAL发送器进程将WAL数据

发送到备库，同时，备库上的WAL接收器接收这些数据，而备库上的启

动进程可以重放这些数据。其中WAL发送器和WAL接收器之间使用单条

TCP连接进行通信。

在本节中，我们将探讨流复制的启动顺序，以了解这些进程如何启

动，以及它们之间是如何建立连接的。图11.1显示了流复制的启动顺

序。



图11.1 流复制的启动顺序

（1）启动主库服务器和备库服务器。

（2）备库服务器启动一个启动进程。

（3）备库服务器启动一个WAL接收器进程。

（4）WAL接收器向主库服务器发送连接请求。如果主库尚未启动，那

么WAL接收器会定期重发该请求。

（5）当主库服务器收到连接请求时，将启动WAL发送器进程，并建立

WAL发送器和WAL接收器之间的TCP连接。

（6）WAL接收器发送备库数据库集簇上最新的LSN。在IT领域中通常将

该阶段称作握手。

（7）如果备库最新的LSN小于主库最新的LSN，那么WAL发送器会将前

一个LSN到后一个LSN之间的WAL数据发送到WAL接收器。这些WAL数据由



存储在主库pg_xlog 子目录（10.0及更高版本的更名为pg_wal）中的

WAL段提供。最终，备库重放接收到的WAL数据。在这一阶段，备库在

追赶主库，因此其被称为追赶阶段。

（8）最终，流复制开始工作。

每个WAL发送器进程都维护了连接上的WAL接收器或其他应用程序的复

制进度状态，请注意，不是连接到WAL发送器的WAL接收器或应用程序

本身的状态。下面是其可能的状态：

● 启动——从启动WAL发送器到握手结束，如图11.1（5）和（6）所

示。

● 追赶——处于追赶阶段，如图11.1（7）所示。

● 流复制——正在运行流复制，如图11.1（8）所示。

● 备份——处于向pg_basebackup等备份工具发送整个数据库集簇文

件的过程中。

系统视图pg_stat_replication 显示了所有正在运行的WAL发送器的状

态，如下例所示：

从上述结果可看到，有两个WAL发送器正在运行，一个正在向连接的备

库发送WAL数据，另一个正在向pg_basebackup应用发送所有数据库集

簇中的文件。





在备库长时间停机后，如果重启会发生什么

在9.3及更低版本中，如果备库所需的 WAL段在主库上已经被回收，备

库就无法追上主库。这一问题并没有可靠的解决方案，只能为参数

wal_keep_segments配置一个较大的值，以减小这种情况发生的可能

性，但这只是权宜之计。

在9.4及更高版本中，可以使用复制槽来预防此问题发生。复制槽是一

项提高 WAL数据发送灵活性的功能，主要是为逻辑复制提出的，同时

也 能 解 决 这 类 问 题 —— 复 制 槽 通 过 暂 停 回 收 过 程 ， 从 而 保 留

pg_xlog（在10.0及更高版本中是pg_wal）中含有未发送数据的WAL段

文件，详情请参阅官方文档。

11.2 如何实施流复制

流复制包含日志传输和数据库同步两个方面。因为流复制基于日志，

日志传送显然是其中的一个方面——主库会在写入日志记录时，将WAL

数据发送到连接的备库。同步复制中需要数据库同步——主库与多个

备库通信，从而同步整个数据库集簇。

为准确理解流复制的工作原理，我们应该探究一下主库如何管理多个

备库。为了尽可能简化问题，本节描述了一个特例，即单主单备系

统，第11.4节将描述一般情况，即单主多备系统。

11.2.1 主从间的通信

假 设 备 库 处 于 同 步 复 制 模 式 ， 但 配 置 参 数 hot-standby 已 禁 用 且

wal_level 为'archive'。主库的主要参数如下所示：

另外，在第9.5节中提到，有三种情况触发写WAL数据，这里我们只关

注事务提交。



假设主库上的一个后端进程在自动提交模式下发出一个简单的INSERT

语句。后端启动事务，发出INSERT 语句，然后立即提交事务。让我们

进一步探讨此提交操作如何完成的，见图11.2中的序列图。

图11.2 流复制的通信序列图

（1）后端进程通过执行函数XLogInsert()和XLogFlush()，将WAL数据

写入并刷新到WAL段文件中。

（2）WAL发送器进程将写入WAL段文件的WAL数据发送到WAL接收器进

程。

（3）在发送WAL数据之后，后端进程继续等待来自备库的ACK响应。更

确切地说，后端进程通过执行内部函数SyncRepWaitForLSN()来获取锁

存器，并等待它被释放。

（4）备库上的WAL接收器通过write()系统调用，将接收到的WAL数据

写入备库的WAL段，并向WAL发送器返回ACK响应。



（5）WAL接收器通过系统调用（例如fsync()）将WAL数据刷新到WAL段

中，向WAL发送器返回另一个ACK响应，并通知启动进程相关WAL数据已

更新。

（6）启动进程重放已写入WAL段的WAL数据。

（7）WAL发送器在收到来自WAL接收器的ACK响应后释放后端进程的锁

存器，然后后端进程完成commit 或abort 动作。锁存器释放的时间取

决于参数synchronous_commit。如果它是’on'（默认），那么当接收

到步骤（5）的 ACK 时，锁存器被释放；如果它是'remote_write'，

当接收到步骤（4）的ACK时，其被释放。

如 果 配 置 参 数 wal_level 是 ’hot_standby’ 或 ’logical' ， 则

PostgreSQL会根据COMMIT或ABORT操作的记录，写入热备功能相关的

WAL 记 录 。 （ 在 这 个 例 子 中 ， PostgreSQL 不 写 那 些 记 录 ， 因 为 它

是’archive'。）

每个ACK响应将备库的内部信息通知给主库，包含以下4个项目：

● 已写入最新WAL数据的LSN位置。

● 已刷新最新WAL数据的LSN位置。

● 启动进程已经重放最新的WAL数据的LSN。

● 发送此响应的时间戳。

WAL接收器不仅在写入和刷新WAL数据时返回ACK响应，还定期发送备库

的心跳响应。因此，主库始终掌握所有连接备库的状态。

执行如下查询，可以显示所连接备库的相关LSN信息。





心跳的间隔时间由参数wal_receiver_status_interval设置，默认值

为10s。

11.2.2 发生故障时的行为

本节将介绍在同步备库发生故障时主库的行为方式，以及主库会如何

处理该情况。

即使同步备库发生故障，且不能够再返回ACK响应，主库也会继续等待

响应。因此，正在运行的事务无法提交，而后续查询也无法启动。换

言之，实际上主库的所有操作都已停止（流复制不支持发生超时时自

动降级回滚到异步模式的功能）。

有两个方法可以避免这种情况，一个是使用多个备库来提高系统可用

性，另一个是通过手动执行以下步骤从同步模式切换到异步模式。

1.将参数synchronous_standby_names的值设置为空字符串。

2.使用reload选项执行pg_ctl命令。

上述过程不会影响连接的客户端。主库继续进行事务处理，会保持客

户端与相应的后端进程之间的所有会话。





11.3 管理多个备库

本节描述了存在多个备库时，流复制是如何工作的。

11.3.1 同步优先级与同步状态

主库为自己管理的每一个备库指定一个同步优先级与同步状态。第

11.2节并没有提到这一点，即使主库只管理一个备库，也会指定这些

值。

同步优先级表示备库在同步模式下的优先级，它是一个固定值。较小

的值表示较高的优先级，而0是一个特殊值，表示“异步模式”。备库

优先级是一个有序列表，在主库配置参数synchronous_standby_names 中依序给出。例如，在以下配置中，standby1和standby2的优先级分

别为1和2。

未列于此参数中的备库处于异步模式，优先级为0。

sync_state 是备库的状态，它因所有在列备库的运行状态及其优先级

而异，以下是可能的状态：

● 同步状态是所有正在工作的备库中，具有最高优先级的同步备库的

状态（异步模式除外）。

● 潜在状态是所有工作备库（异步备库除外）中，优先级等于或低于

2的闲置同步备库的状态。如果同步状态的备库失效，那么潜在状态的

备库中有着最高优先级的那个将替换同步备库。

● 异步状态的备库是固定的。主库以与潜在备库相同的方式处理异步

备库，只是它们的sync_state永远不会是sync或potential。

执行以下查询来显示备库的优先级和状态：





最 近 有 几 个 开 发 者 尝 试 实 现 “ 多 个 同 步 备 库 ” ， 详 情 参 见

https://commitfest.postgresql.org/6/293/。

11.3.2 主库如何管理多个备库

主库仅等待来自同步备库的ACK响应。换句话说，主库仅确保同步备库

写入并刷新WAL数据。因此，在流复制中，只有同步备库的状态是与主

库始终一致且同步的。

图11.3展示了潜在备库的ACK响应早于主库ACK响应的情况。这时主库

并不会完成当前事务的COMMIT操作，而是继续等待主库的ACK响应。当

收到主库的响应时，后端进程就释放锁存器并完成当前事务的处理。





图11.3 管理多个备库

备库1与备库2的sync_state分别为同步和潜在状态。

（1）尽管从潜在备库接收到 ACK响应，但是主库的后端进程会继续等

待来自同步备库的ACK响应。

（2）主库的后端进程释放锁存器，完成当前的事务处理。

在相反的情况下（即首要备库的ACK响应返回早于潜在备库的响应），

主库会立即完成当前事务的COMMIT操作，而不会去确认潜在备库是否

已经写入和刷盘了WAL数据。

11.3.3 发生故障时的行为

我们再来看看当从库发生故障时主库的表现。

当潜在或异步备库发生故障时，主库会终止连接到故障备库的 WAL 发

送器进程，并继续进行所有处理。换而言之，主库上的事务处理不会

受到这两种备库的影响。

当同步备库发生故障时，主库将终止连接到故障备库的 WAL 发送器进

程，并使用具有最高优先级的潜在备库替换首要同步备库，如图11.4

所示。与上述的故障相反，主库将暂停从失效点到成功替换同步备库





之间的查询处理。因此备库的故障检测对于提高复制系统可用性至关

重要，故障检测将在第11.4节介绍。

在任何情况下，如果一个或多个备库在同步模式下运行，主库始终只

会保留一个同步备库，而同步备库始终与主库保持一致且同步的状

态。

图11.4 更换同步备库

11.4 备库的故障检测

流复制使用两种常见的故障检测过程，不需要任何特别的硬件。

1.备库服务器的失效检测。

当检测到WAL发送器和WAL接收器之间的连接断开时，主库立即判定备

库或WAL接收器进程出现故障。当底层网络函数由于未能成功读/写WAL

接收器的套接字接口而返回错误时，主库也会立即判定其失效。

2.硬件与网络的失效检测。

如果 WAL接收器在参数wal_sender_timeout（默认值为60s）配置的时

间段内没有返回任何结果，则主库会判定备库出现故障。相对于上面

的故障而言，尽管从库可能因为一些失效原因（例如，备库上的硬件

失效、网络失效等），已经无法发送任何响应，但是主库仍需要耗费

特定的时间——最长的时间是wal_sender_timeout，以确认备库的

“死亡”。





取决于失效的类型，一些失效可以在失效发生时被立即检测到，而有

时候则可能在出现失效与检测到失效之间存在一段时间的延迟。如果

在同步备库上出现后一种失效的情况，那么即使有多个潜在备库正常

工作，检测到同步备库失效，主库仍然可能会停止一段时间的事务处

理。

在 9.2 或 更 低 版 本 中 ， 参 数 wal_sender_timeout 被 称 为

replication_timeout。

